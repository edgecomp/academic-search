,conference,year,title,abstract
0,Conference on Computational Natural Language Learning (CoNLL),2015,Indoor skydiving in immersive virtual reality with embedded storytelling,"We describe the Virtual Jump Simulator, which allows subjects to perform an indoor parachute jump in a virtual environment. The necessity to jump physically off a platform combined with immersive virtual reality and tactile feedback creates an experience with a high amount of presence, as the evaluation of the prototype confirms. The system consists of a steel cube, a mechanical absorber system with stacked eccentric wheels and counterweights that allows subjects in the weight range from 35 to 150kg to jump without the need for individual calibration, a virtual reality setup with high-quality 3D content and tactile stimuli. In the immersive virtual jump experience, we embed a story using rich multimedia content, such as images and sound. We iteratively tested the entire system with users of different backgrounds. Thereby, we gathered user feedback from the very beginning to create a novel virtual reality system that allows for actual physical jumping and flying with free body movement. © 2015 ACM."
1,Conference on Computational Natural Language Learning (CoNLL),2015,None,None
2,Conference on Computational Natural Language Learning (CoNLL),2015,Efficient intrinsic image decomposition for RGBD images,"Intrinsic image decomposition is a longstanding problem in computer vision. In this paper, we present a novel approach for efficiently decomposing an RGBD image into its reflectance and shading components. A robust super-pixel segmentation method is employed to select piece-wise constant reflectance regions and reduce the total number of unknowns. With the use of depth information, low frequency environment light can be represented by spherical harmonics and solved with super-pixels. After that, pixels that do not belong to any super-pixel are solved based on the superpixels' shading. Compared to existing works, which often depend on the color Retinex assumption, our algorithm does not require any chromaticity-based constraints and enables us to solve many challenging cases such as color lighting environments and gray-scale textures. We also design an efficient solver for our system, and with our GPU implementation, it achieves 10-23 fps and boosts the decomposition process to real-time performance, enabling a wide range of applications such as dynamic object recoloring, re-texturing and virtual object composition. © 2015 ACM."
3,Conference on Computational Natural Language Learning (CoNLL),2015,Vector solid texture synthesis using two-scale shaping model,"Solid textures exhibit several benefits over traditional texture mapping, such as no demanding for parameterization and providing internal information. However, the difficulty in accessing and high memory consumption seriously limit the usage of solid textures. We present an efficient approach to directly synthesize vector solid textures comprising 3D particles from 2D examples. Two-scale shaping model is introduced to automatically and accurately reconstruct 3D particle outlines from 2D cross sections. Low frequency spherical harmonics are used to morph smooth outlines while high frequency ones model particle surface details. These outlines are further converted to signed distance field grids for vector representation. Particle volume color is represented by radial basis functions. We arrange particles using simplified particle proxies to improve efficiency. Particles' position offsets are calculated according to the particle itself and one-ring neighbor particles' shapes iteratively. Finally, our cell-building algorithm constructs containers and computes scale for each particle instance. Experiments show that our algorithm can generate vector solid textures with plausible 3D particles. © 2015 ACM."
4,Conference on Computational Natural Language Learning (CoNLL),2015,Direct lighting on meso-structured surfaces with area light sources,"We present a novel direct lighting rendering method for static scenes with meso-structured surfaces and multiple area light sources. We use coarse geometry models with textures bound on them as inputs. The textures contain not only color maps, but also height field maps to represent the small concave and convex details for meso-structured surfaces. We explore traditional radiosity process as the main frame of our algorithm, and extend radiosity to directional radiosity for approximating light transportation on meso-structured surfaces. In pre-processing step, first, the form factors between the triangles of coarse models and the patches of area light sources are pre-computed. Then the directional radiosity of each triangle is computed by gathering irradiance according to directions sampled uniformly on the hemi-sphere of them. At last, directional radiosity of a vertex is estimated according to the directional radiosity of triangles passing through this vertex. For each frame, we combine relief texture mapping with directional radiosity to shade meso-structured surface. The experiment results show that our method has very similar quality and better time performance for rendering the scenes with meso-structured surfaces and multiple area light sources compared with SM+RTM method. © 2015 ACM."
5,Conference on Computational Natural Language Learning (CoNLL),2015,GPU ray-traced collision detection for cloth simulation,"We propose a method to perform collision detection with cloths with ray-tracing. Our method is able to perform collision detection between cloths and volumetric objects (rigid or deformable) as well as collision detection between cloths (including auto-collision). Our method casts rays between objects to perform collision detection, and an inversion-handling algorithm is introduced to correct errors introduced by discrete simulations. GPU computing is used to improve the performances. Our implementation handles scenes containing deformable objects at an interactive frame-rate, with collision detection lasting a few milliseconds. © 2015 ACM."
6,Conference on Computational Natural Language Learning (CoNLL),2015,Head-mounted display with mid-air tactile feedback,"Virtual and physical worlds are merging. Currently users of head-mounted displays cannot have unobtrusive tactile feedback while touching virtual objects. We present a mid-air tactile feedback system for head-mounted displays. Our prototype uses the focus of a modulated ultrasonic phased array for unobtrusive mid-air tactile feedback generation. The array and the hand position sensor are mounted on the front surface of a head-mounted virtual reality display. The presented system can enhance 3D user interfaces and virtual reality in a new way. To evaluate the tactile feedback together with visuals on an Oculus Rift VR headset, we had 13 participants do a simple virtual keypad tapping task with and without tactile feedback. The results indicate that while the measured speed and accuracy differed only a little, the subjects were nearly unanimous in that they preferred to use the tactile feedback. The ""raw"" NASA TLX questionnaires conducted after use revealed that the participants felt slightly less mental, physical and temporal demand with the tactile feedback. The participants' self-assessment of their performance was also higher with the tactile feedback. © 2015 ACM."
7,Conference on Computational Natural Language Learning (CoNLL),2015,TouchSketch: A touch-based interface for 3D object manipulation and editing,"To make constrained manipulation of 3D objects in desktop 3D applications, 3D transformation widgets are commonly used. However, their performance degrades on touchscreens because of low accuracy of touch inputs and the fingertip occlusion problem. In this paper, we present TouchSketch, a touch-based interface which allows users to perform independently fine-grained object translation, rotation and scaling on mobile devices. Our manipulation technique permits using the non-dominant hand to specify the manipulation reference while the dominant hand is used to determine the operation mode and control the transformation. In addition to 3D manipulation, TouchSketch provides also a set of functions to edit the shape of 3D objects. Users can use this application to accomplish rapid sketching tasks. We have conducted a user study to evaluate the efficiency of our manipulation technique. The results show that our technique outperforms a Widget-based technique regarding both the efficiency and fluency. © 2015 ACM."
8,Conference on Computational Natural Language Learning (CoNLL),2015,Virtual reality based laparoscopic surgery simulation,"With the development of computer graphic and haptic devices, training surgeons with virtual reality technology has proven to be very effective in surgery simulation. Many successful simulators have been deployed for training medical students. However, due to the various unsolved technical issues, the laparoscopic surgery simulation has not been widely used. Such issues include modeling of complex anatomy structure, large soft tissue deformation, frequent surgical tools interactions, and the rendering of complex material under the illumination of headlight. A successful laparoscopic surgery simulator should integrate all these required components in a balanced and efficient manner to achieve both visual/haptic quality and a satisfactory refreshing rate. In this paper, we propose an efficient framework integrating a set of specially tailored and designed techniques, ranging from deformation simulation, collision detection, soft tissue dissection and rendering. We optimize all the components based on the actual requirement of laparoscopic surgery in order to achieve an improved overall performance of fidelity and responding speed. © 2015 ACM."
9,Conference on Computational Natural Language Learning (CoNLL),2015,Interactive virtual percussion instruments on mobile devices(Open Access),"We present a multimodal virtual percussion instrument system on consumer mobile devices that allows users to design and configure customizable virtual percussion instruments and interact with them in real time. Users can create virtual instruments of different materials and shapes interactively, by editing and selecting the desired characteristics. Both the visual and auditory feedback are then computed on the fly to automatically correspond to the instrument properties and user interaction. We utilize efficient 3D input processing algorithms to approximate and represent real-time multi-touch input with key meta properties and adopt fast physical modeling to synthesize sounds. Despite the relatively limited computing resources on mobile devices, we are able to achieve rich and responsive multimodal feedback based on real-time user input. A pilot study is conducted to assess the effectiveness of the system. © 2015 ACM."
10,Conference on Computational Natural Language Learning (CoNLL),2015,High quality compatible triangulations for 2D shape morphing,"We propose a new method to compute compatible triangulations of two polygons in order to create a smooth geometric transformation between them. Compared with existing methods, our approach creates triangulations of better quality, that is, triangulations with fewer long thin triangles and Steiner points. This results in visually appealing morphing when transforming the shape from one to another. Our method consists of three stages. First, we compatibly decompose the target and source polygons into a set of sub-polygons, in which each source sub-polygon is triangulated. Second, we map the triangulation of a source sub-polygon onto the corresponding sub-polygon of the target polygon using linear transformation, thereby generating the compatible meshes between the source and the target. Third, we refine the compatible meshes, which can create better quality planar shape morphing with detailed textures. Experimental results show that our method can create compatible meshes of higher quality compared with existing methods, which facilitates smoother morphing process. The proposed algorithm is robust and computationally efficient. It can be applied to produce convincing transformations such as interactive 2D animation creation and special effects in movies. © 2015 ACM."
11,Conference on Computational Natural Language Learning (CoNLL),2015,Procedural techniques for simulating the growth of plant leaves and adapting venation patterns,"This paper presents biologically-motivated a procedural method for the simulation of leaf contour growth and venation development. We use a mathematical model for simulating the growth of a plant leaf. Leaf tissue is regarded as a viscous, incompressible fluid whose 2D expansion is determined by a spatially varying growth rate. Visually realistic development is described by a growth function ℝEℝG that reacts to hormone (auxin) sources embedded in the leaf blade. The shape of the leaf is determined by a set of feature points within the leaf contour. The contour is extracted from photos by utilizing a Curvature Scale Space (CSS) Corner Detection Algorithm. Auxin transport is described by an initial auxin flux from an auxin source to an auxin sink that is gradually channelized into cells with high levels of highly polarized transporters. The leaf is presented as a triangulated double layer structure that consists of a Voronoi-Diagram that is discretised along the vein structures. © 2015 ACM."
12,Conference on Computational Natural Language Learning (CoNLL),2015,A novel integrated analysis-and-simulation approach for detail enhancement in FLIP fluid interaction,"This paper advocates a novel integrated method to tightly couple simulation with analysis for the effective modeling and enhancement of scale-aware fluid details. It brings forth a suite of innovations in a unified framework, including depth-image-based space analysis for multi-scale detail detection, time-space analysis based on the logistic regression model that integrates both geometry and physics criteria, and depth-image-based sampling for quality-efficiency tradeoff. Our method contains an intertwined two-level processing architecture at its core. At the analysis level, we propose a rigorous time-space analysis model to pinpoint complex interacting regions, which can take into account multiple detailrelevant factors based on the depth-image sequence captured from FLIP-driven simulation sequence. At the simulation level, details are enhanced by animating extra diffuse materials, and augmenting the air-fluid mixing phenomenon. Directly benefitting from the flexibility of image-space-dominant processing, our unified framework can be entirely implemented on GPU, hence interactive performance could be guaranteed. Comprehensive experiments and evaluations on various diffuse phenomena (e.g., spray, foam, and bubble) have demonstrated its superiority in high-fidelity detail enhancement during fluid simulation and its interaction with surrounding environment for VR applications. © 2015 ACM."
13,Conference on Computational Natural Language Learning (CoNLL),2015,Adaptive level set for fluid surface tracking,"We introduce an adaptive hybrid level set surface tracking for fluid simulation in this paper. To improve the accuracy of the convectional level set method, we propose a method that combines the higher accuracy interpolation and octree grid to improve the accuracy while still maintain good efficiency. Adaptive gradient-augmented level set is adopted for higher accuracy interpolation and two strategies are proposed to guide the building of the octree structure. We demonstrate our method with several level set tests, and couple it to several existing fluid simulators. The results show that our method facilitates significant improvements in accuracy and efficiency, and is effective for free surface fluid simulation in capturing fluid details. © 2015 ACM."
14,Conference on Computational Natural Language Learning (CoNLL),2015,VR system for rehabilitation based on hand gestural and olfactory interaction,"The study of new systems for supporting upper limb rehabilitation is of primary importance, due to the high number of people in need of rehabilitation and the limited effectiveness of most of the current systems. The research work described in this paper proposes a VR system for upper-limb rehabilitation that is immersive, is based on hand gestures to interact with virtual objects, and which can deliver odours when a goal is reached. © 2015 ACM."
15,Conference on Computational Natural Language Learning (CoNLL),2015,A real time haptic simulator of spine surgeries,"Spine surgeries are high risk operations which require the surgeons to have ample experiences. For young surgeons, effective and extensive training is critical. This paper presents a real time haptic spine surgical simulator that will be used to train residents, fellows and spine surgeons in a hospital training program. It provides a realistic environment for the trainees to practice spine surgeries and has the advantages of being interactive, low-cost, representative, and repeatable over conventional training approaches. Haptic Phantom offers the users force feedback, differentiating our system from other screen-based training systems. Computational efficiency was achieved by developing advanced graphical rendering methods. The volumetric data was classified into surface voxel cloud and inner voxel cloud by the adjacency graph which stored the relationship among voxels. To speed up the collision detection and real time rendering between the virtual surgical tools and the lumbar model, Octree-based algorithms and GPU technique were applied. To enhance the physical realism, three dimensional lumbar vertebrae models were reconstructed from CT images and associated with non-homogeneous bone density such that the rendered model best represents the spine anatomy and mechanics. We demonstrate system performance by conducting pedicle screw insertion. © 2015 ACM."
16,Conference on Computational Natural Language Learning (CoNLL),2015,Embodied interaction using non-planar projections in immersive virtual reality,"In this paper we evaluate the use of non-planar projections as a means to increase the Field of View (FoV) in embodied Virtual Reality (VR). Our main goal is to bring the virtual body into the user's FoV and to understand how this affects the virtual body/environment relation and quality of interaction. Subjects wore a Head Mounted Display (HMD) and were instructed to perform a selection and docking task while using either Perspective (≈ 106° vertical FoV), Hammer or Equirectangular (≈ 180° vertical FoV for both) projection. The increased FoV allowed for a shorter search time as well as less head movements. However, quality of interaction was generally inferior, requiring more time to dock, increasing docking error and producing more body/environment collisions. We also assessed cybersickness and the sense of embodiment toward the virtual body through questionnaires, for which the difference between projections seemed to be less pronounced. © 2015 ACM."
17,Conference on Computational Natural Language Learning (CoNLL),2015,Optimal camera placement for motion capture systems in the presence of dynamic occlusion(Open Access),"Optical motion capture is based on estimating the three-dimensional positions of markers by triangulation from multiple cameras. Successful performance depends on points being visible from at least two cameras and on the accuracy of the triangulation. Triangulation accuracy is strongly related to the positions and orientations of the cameras. Thus, the configuration of the camera network has a critical impact on performance. A poor camera configuration may result in a low quality three-dimensional (3D) estimation and consequently low quality of tracking. This paper proposes a camera configuration metric that is based on a probabilistic model of target point visibility from cameras with ""good"" views. An efficient algorithm, based on simulated annealing, is introduced for estimating the optimal configuration of an arbitrary set of cameras for a given distribution of target points. The accuracy and robustness of the algorithm are evaluated through both simulation and empirical measurement. An implementation of the method is available for download as a tool for the community [Rahimian and Kearney 2015] (Figure 1). © 2015 ACM."
18,Conference on Computational Natural Language Learning (CoNLL),2015,Realizing a low-latency virtual reality environment for motor learning,"Virtual Reality (VR) has the potential to support motor learning in ways exceeding beyond the possibilities provided by real world environments. New feedback mechanisms can be implemented that support motor learning during the performance of the trainee and afterwards as a performance review. As a consequence, VR environments excel in controlled evaluations, which has been proven in many other application scenarios. However, in the context of motor learning of complex tasks, including full-body movements, questions regarding the main technical parameters of such a system, in particular that of the required maximum latency, have not been addressed in depth. To fill this gap, we propose a set of requirements towards VR systems for motor learning, with a special focus on motion capturing and rendering. We then assess and evaluate state-of-the-art techniques and technologies for motion capturing and rendering, in order to provide data on latencies for different setups. We focus on the end-to-end latency of the overall system, and present an evaluation of an exemplary system that has been developed to meet these requirements. © 2015 ACM."
19,Conference on Computational Natural Language Learning (CoNLL),2015,Dynamic projection mapping onto a deformable object with occlusion based on high-speed tracking of dot marker array,"In recent years, projection mapping has attracted much attention in a variety of fields. Generally, however, the objects in projection mapping are limited to rigid and static or quasistatic objects. Dynamic projection mapping onto a deformable object could remarkably expand the possibilities. In order to achieve such a projection mapping, it is necessary to recognize the deformation of the object even when it is occluded. However, it is still a challenging problem to achieve this task in real-time with low latency. In this paper, we propose an efficient, high-speed tracking method utilizing highframe-rate imaging. Our method is able to track an array of dot markers arranged on a deformable object even when there is external occlusion caused by the user interaction and self-occlusion caused by the deformation of the object itself. Additionally, our method can be applied to a stretchable object. Dynamic projection mapping with our method showed robust and consistent display onto a sheet of paper and cloth with a tracking performance of about 0.2 ms per frame, with the result that the projected pattern appeared to be printed on the deformable object. © 2015 ACM."
20,Conference on Computational Natural Language Learning (CoNLL),2015,Simulating high-DOF human-like agents using hierarchical feedback planner,"We present a multi-agent simulation algorithm to compute the trajectories and full-body motion of human-like agents. Our formulation uses a coupled approach that combines 2D collision-free navigation with high-DOF human motion simulation using a behavioral finite state machine. In order to generate plausible pedestrian motion, we use a closed-loop hierarchical planner that satisfies dynamic stability, biomechanical, and kinematic constraints, and is tightly integrated with multi-agent navigation. Furthermore, we use motion capture data to generate natural looking human motion. The overall system is able to generate plausible motion with upper and lower body movements and avoid collisions with other human-like agents. We highlight its performance in indoor and outdoor scenarios with tens of human-like agents. © 2015 ACM."
21,Conference on Computational Natural Language Learning (CoNLL),2015,Adding sociality to virtual pedestrian groups,"We present a new method, Social Groups and Navigation (SGN), to simulate the walking behavior of small pedestrian groups in virtual environments. SGN is the first method to simulate group behavior on both global and local levels. We define quantitative metrics to measure the coherence and the sociality of a group based on existing empirical data of real crowds. SGN is designed to let groups stay in coherent and social formations without explicitly modeling such formations. For groups of four, SGN generates between 13% and 53% more socially-friendly behavior than existing methods, measured over the lifetime of a group in the simulation. For groups of three, the gain is between 15% and 31%, and for groups of two, the gain is between 1% and 4%. SGN can be used with any existing global path planner and any existing path following method. Experiments show that SGN enables the simulation of thousands of agents in real time. Due to its flexible design, it can be easily integrated into a larger crowd simulation framework. © 2015 ACM."
22,Conference on Computational Natural Language Learning (CoNLL),2015,Collaborative navigation in virtual worlds: How gender and game experience influence user behavior,"There exists a large base of evidence for gender differences in human navigation. However, there is not much research on gender differences in collaborative aspects of navigation, including the interaction of individuals during collaborative wayfinding tasks in virtual environments. In light of this, we present a study of a collaborative virtual environment, Berlin Kompass. The goal of this study was to find out the main differences between genders in collaborative wayfinding. The application was evaluated in the context of foreign language learning in schools with over 200 students, where the users navigated through cityscapes while interacting verbally with each other. We collected and analyzed interaction logs, questionnaire data and audio and video recordings to gain insights into gender-related differences in wayfinding in virtual worlds. Our findings suggest that several differences that are evident in single user systems are not present when the collaborative aspect is added. Male users were more immersed during the task than females. One of the explaining factors for this might be video game experience. Genders also communicated differently - males spoke in longer utterances whereas females had more, shorter utterances. Males referred more to relative directions and dynamic landmarks such as cars and pedestrians while navigating. Males with more video game experience also provided more positive subjective user experience feedback on the application. © 2015 ACM."
23,Conference on Computational Natural Language Learning (CoNLL),2015,Video driven pedestrian visualization with characteristic appearances,"Augmented virtual environment (AVE) could visualize plausible live views from videos by projecting dynamic imagery to the 3D environment. Static objects in a video can be rendered in new views since they are easily modeled beforehand, while moving ones that don't have exact online models will be distorted from different views without proper depth. To cope with the problem, we introduce a novel method to visualize pedestrians, which are common in outdoor surveillance. Our method detects pedestrians and produces their trajectories. Then such pedestrian characteristic appearances as geometric information, texture and walking animation are transferred to a stand-in 3D animation model in the virtual environment. Experiments show our visualization can reveal person's characteristic appearances. © 2015 ACM."
24,Conference on Computational Natural Language Learning (CoNLL),2015,Modeling spatial relations of human body parts for indexing and retrieving close character interactions,"Retrieving pre-captured human motion for analyzing and synthesizing virtual character movement have been widely used in Virtual Reality (VR) and interactive computer graphics applications. In this paper, we propose a new human pose representation, called Spatial Relations of Human Body Parts (SRBP), to represent spatial relations between body parts of the subject(s), which intuitively describes how much the body parts are interacting with each other. Since SRBP is computed from the local structure (i.e. multiple body parts in proximity) of the pose instead of the information from individual or pairwise joints as in previous approaches, the new representation is robust to minor variations of individual joint location. Experimental results show that SRBP outperforms the existing skeleton-based motion retrieval and classification approaches on benchmark databases. © 2015 ACM."
25,Conference on Computational Natural Language Learning (CoNLL),2015,Evaluating the effects of competition vs collaboration on user engagement in an immersive game using natural interaction,[No abstract available]
26,Conference on Computational Natural Language Learning (CoNLL),2015,A streaming framework for instant 3D rendering and interaction,[No abstract available]
27,Conference on Computational Natural Language Learning (CoNLL),2015,Contributing to VRPN with a new server for haptic devices,[No abstract available]
28,Conference on Computational Natural Language Learning (CoNLL),2015,The effect of vibration and low-frequency audio on full-body haptic sensations,[No abstract available]
29,Conference on Computational Natural Language Learning (CoNLL),2015,Augmented reality for collision warning and path guide in a vehicle,[No abstract available]
30,Conference on Computational Natural Language Learning (CoNLL),2015,Local context based recognition + internet of things: Complementary infrastructures for future generic mixed reality space,[No abstract available]
31,Conference on Computational Natural Language Learning (CoNLL),2015,Tele-augmentation for remote AR coaching,[No abstract available]
32,Conference on Computational Natural Language Learning (CoNLL),2015,Resolving view difference between eye and camera for proprioceptive pointing and selection in augmented reality applications,[No abstract available]
33,Conference on Computational Natural Language Learning (CoNLL),2015,None,None
34,Conference on Computational Natural Language Learning (CoNLL),2015,An imitation-based approach to represent common ground in a virtual basketball agent team mate,[No abstract available]
35,Conference on Computational Natural Language Learning (CoNLL),2015,Robust image/video super-resolution display,"This paper describes a new method to reconstruct high-resolution video sequences from several observed low-resolution images based on an adaptive Mumford-shah model which is extended by using nonlocal information and low-rank representation. In our regularization framework, joint image restoration and motion estimation are first implemented and then detailed information can be recovered by incorporating new model as a prior term."
36,Conference on Computational Natural Language Learning (CoNLL),2015,Interactive volumetric segmentation through least-squares optimization of local hessian-constrained implicits,[No abstract available]
37,Conference on Computational Natural Language Learning (CoNLL),2015,Color correspondence of image warping using plane constraints,"We demonstrate the effectiveness of our warping method on three examples, and the experiments demonstrate that color differences between meshes are effectively reduced. Our method produces better novel view synthesis results without ghost artifacts."
38,Conference on Computational Natural Language Learning (CoNLL),2015,Flexible point handles metaphor for character deformation,"Skinning using point handles has experimentally shown its effectiveness for stretching, twisting, and supple deformations [Jacobson et al. 2011] which are difficult to achieve using rigid bones. However, point handles are much less effective for limbs bending since their influence weights vary over the skin mesh. This poster presents an efficient scheme, which expands the space of deformations possible to the point handles by supporting rigid bending using a rigidity energy minimization framework. Thus, 3D points that are much easier to design while provide larger space of deformations than a skeleton can be used as alternative handles in character skinning."
39,Conference on Computational Natural Language Learning (CoNLL),2015,Evaluating warped projection cameras,[No abstract available]
40,Conference on Computational Natural Language Learning (CoNLL),2015,Evaluation of factors affecting distance perception in architectural project review in immersive virtual environments,"Distances are perceived as being more compressed in immersive virtual environments (IVEs) than in real environments. The goal of this study is to identify the most important factors that influence decision making and accuracy of distance perception in the context of architectural project reviews. Technical factors such as field of view, display devices and motion parallax were widely studied. In this paper, we have investigated other individual and contextual factors. We conducted a between-subject experiment using an immersive large screen display to examine the influence of the three factors: 1) the cognitive profile of the user (visual, auditory and kinesthetic - VAK), 2) the furnishing of the house, and 3) the locomotion speed, on distance perception. Results reveal that participants with visual profile were more accurate in distance estimation. Further, furnished houses were more suitable for virtual visits. The locomotion speed also seems to influence virtual visits which were better with a slow locomotion speed. Based on the results of our study, we finally present guidelines for setting up architectural project review tools which employ similar setup. © 2015 ACM."
41,Conference on Computational Natural Language Learning (CoNLL),2015,JackIn head: Immersive visual telepresence system with omnidirectional wearable camera for remote collaboration,"Remote collaboration to share abilities over the Internet is one of the ultimate goals of telepresence technology. In this paper, we present JackIn Head, a visual telepresence system with an omnidirectional wearable camera with image motion stabilization. Spherical omnidirectional video footage taken around the head of a local user is stabilized and then broadcast to others, allowing remote users to explore the scene independently of the local user's head direction. We describe the system design of JackIn Head and report the evaluation results of the system's motion decoupling. Then, through an exploratory observation study, we investigate how individuals can remotely interact, communicate with, and assist each other with our system. We report our observation and analysis of inter-personal communication, demonstrating the effectiveness of our system in augmenting remote collaboration. © 2015 ACM."
42,Conference on Computational Natural Language Learning (CoNLL),2015,Distortion score based pose selection for 3D Tele-immersion(Open Access),"3D Tele-Immersion (3DTI) systems capture and transmit large volumes of data per frame to enable virtual world interaction between geographically distributed people. Large delays/latencies introduced during the transmission of these large volumes of data can lead to poor quality of experience of the 3DTI systems. Such poor experiences can possibly be overcome by animating the previously received mesh using the current skeletal data (that is very small in size and hence experiences much lower communication delays). However, using just the previously transmitted mesh for animation is not ideal and could render inconsistent results. In this paper, we present a DIstortion Score based Pose SElection (DISPOSE) approach to render the person by using an appropriate mesh for a given pose. Unlike pose space animation methods that require manual or offline time consuming pose set creation, our distortion score based scheme can choose the mesh to be transmitted and update the pose set accordingly. DISPOSE works with partial meshes and does not require dense registration enabling real time pose space creation. With DISPOSE incorporated into 3DTI, the latency for rendering the mesh on the receiving side is limited by only the transmission delay of the skeletal data (which is only around 250 bytes). Our evaluations show the effectiveness of DISPOSE for generating good quality online animation faster than real time. © 2015 ACM."
43,Conference on Computational Natural Language Learning (CoNLL),2015,Augmented reality-aided tele-presence system for robot manipulation in industrial manufacturing,"This work investigates the use of a highly immersive telepresence system for industrial robotics. A Robot Operating System integrated framework is presented where a remote robot is controlled through operator's movements and muscle contractions captured with a wearable device. An augmented 3D visual feedback is sent to the user providing the remote environment scenario from the robot's point of view and additional information pertaining to the task execution. The system proposed, using robot mounted RGB-D camera, identifies known objects and relates their pose to robot arm pose and to targets relevant to the task execution. The system is preliminary validated during a pick-and-place task using a Baxter robot. The experiment shows the practicability and the effectiveness of the proposed approach. © 2015 ACM."
