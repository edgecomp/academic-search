BlueDBM: an appliance for big data analytics.
Towards sustainable in-situ server systems in the big data era.
DjiNN and Tonic: DNN as a service and its implications for future warehouse scale computers.
A case for core-assisted bottleneck acceleration in GPUs: enabling flexible data compression with assist warps.
Harmonia: balancing compute and memory power in high-performance GPUs.
Redundant memory mappings for fast access to large memories.
Page overlays: an enhanced virtual memory framework to enable fine-grained memory management.
ShiDianNao: shifting vision processing closer to the sensor.
A scalable processing-in-memory accelerator for parallel graph processing.
Efficient execution of memory access phases using dataflow specialization.
Data reorganization in memory using 3D-stacked DRAM.
Quantitative comparison of hardware transactional memory for Blue Gene/Q, zEnterprise EC12, Intel Core, and POWER8.
Profiling a warehouse-scale computer.
Computer performance microscopy with Shim.
Flexible software profiling of GPU architectures.
BEAR: techniques for mitigating bandwidth bloat in gigascale DRAM caches.
A fully associative, tagless DRAM cache.
Multiple clone row DRAM: a low latency and area optimized DRAM.
Flexible auto-refresh: enabling scalable and energy-efficient DRAM refresh reductions.
Cost-effective speculative scheduling in high performance processors.
LaZy superscalar.
The load slice core microarchitecture.
Semantic locality and context-based prefetching using reinforcement learning.
Exploring the potential of heterogeneous von neumann/dataflow execution models.
SHRINK: reducing the ISA complexity via instruction recycling.
Branch vanguard: decomposing branch functionality into prediction and resolution instructions.
PIM-enabled instructions: a low-overhead, locality-aware processing-in-memory architecture.
SLIP: reducing wire energy in the memory hierarchy.
CloudMonatt: an architecture for security health monitoring and attestation of virtual machines in cloud computing.
Reducing world switches in virtualized environment with flexible cross-world calls.
ArMOR: defending against memory consistency model mismatches in heterogeneous architectures.
Clean: a race detector with cleaner semantics.
MiSAR: minimalistic synchronization accelerator with resource overflow management.
Callback: efficient synchronization without invalidation with a directory just for spin-waiting.
Thermal time shifting: leveraging phase change materials to reduce cooling costs in warehouse-scale computers.
Heracles: improving resource efficiency at scale.
HEB: deploying and managing hybrid energy buffers for improving datacenter efficiency and economy.
Architecting to achieve a billion requests per second throughput on a single key-value store server platform.
A variable warp size architecture.
Warped-compression: enabling power efficient GPUs through register compression.
CAWA: coordinated warp scheduling and cache prioritization for critical warp acceleration of GPGPU workloads.
Dynamic thread block launch: a lightweight execution mechanism to support irregular applications on GPUs.
DynaSpAM: dynamic spatial architecture mapping using out of order instruction schedules.
Rumba: an online quality management system for approximate computing.
Manycore network interfaces for in-memory rack-scale computing.
Unified address translation for memory-mapped SSDs with FlashMap.
FASE: finding amplitude-modulated side-channel emanations.
Probable cause: the deanonymizing effects of approximate DRAM.
PrORAM: dynamic prefetcher for oblivious RAM.
MBus: an ultra-low power interconnect bus for next generation nanopower systems.
Accelerating asynchronous programs through event sneak peek.
VIP: virtualizing IP chains on handheld platforms.
FaultHound: value-locality-based soft-fault tolerance.
COP: to compress and protect main memory.
Hi-fi playback: tolerating position errors in shift operations of racetrack memory.
Stash: have your scratchpad and cache it too.
Coherence protocol for transparent management of scratchpad memories in shared memory manycore architectures.
Fusion: design tradeoffs in coherent cache hierarchies for accelerators.
