,conference,year,title,abstract
0,IEEE Symposium on Visual Analytics Science and Technology,2015,None,None
1,IEEE Symposium on Visual Analytics Science and Technology,2015,Yield forecasting in fab-to-fab production migration based on Bayesian Model Fusion,"Yield estimation is an indispensable piece of information at the onset of high-volume production of a device. It can be used to refine the process/design in time so as to guarantee high production yield. In the case of migration of production of a specific device from a source fab to a target fab, yield estimation in the target fab can be accelerated by employing information from the source fab, assuming that the process parameter distributions in the two fabs are similar, but not necessarily the same. In this paper, we employ the Bayesian Model Fusion (BMF) technique for efficient yield prediction of a device in the target fab. BMF adopts prior knowledge from the source fab and combines it intelligently with information from a limited number of early silicon wafers from the target fab. Thus, BMF allows us to obtain quick and accurate yield estimates at the onset of production in the target fab. The proposed methodology is demonstrated on an industrial RF transceiver. © 2015 IEEE."
2,IEEE Symposium on Visual Analytics Science and Technology,2015,Reduced overhead error compensation for energy efficient machine learning kernels,"Low overhead error-resiliency techniques such as RAZOR [1] and algorithmic noise-tolerance (ANT) [2] have proven effective in reducing energy consumption. ANT has been shown to be particularly effective for signal processing and machine learning kernels. In ANT, an explicit estimator block compensates for large magnitude errors in a main block. The estimator represents the overhead in ANT and can be as large as 30%. This paper presents a low overhead ANT technique referred to as ALG-ANT. In ALG-ANT, the estimator is embedded inside the main block via algorithmic reformulation and thus completely eliminates the overhead associated with ANT. However, ALG-ANT is algorithm-specific. This paper demonstrates the ALG-ANT concept in the context of a finite impulse response (FIR) filter kernel and a dot product kernel, both of which are commonly employed in signal processing and machine learning applications. The proposed ALG-ANT FIR filter and dot product kernels are applied to the feature extractor (FE) and SVM classification engine (CE) of an EEG seizure classification system. Simulation results in a commercial 45nm CMOS process show that ALG-ANT can compensate for error rates of up to 0.41 (errors in FE only), and up to 0.19 (errors in FE and CE) and maintain the true positive rate ptp > 0.9 and false positive rate pfp ≤ 0.01. This represents a greater than 3-orders-of-magnitude improvement in error tolerance over the conventional architecture. This error tolerance is employed to reduce energy via the use of voltage overscaling (VOS). ALG-ANT is able to achieve 44.3% energy savings when errors are in FE only, and up to 37.1% savings when errors are in both FE and CE. © 2015 IEEE."
3,IEEE Symposium on Visual Analytics Science and Technology,2015,A light-weighted software-controlled cache for PCM-based main memory systems,"The replacement of DRAM with non-volatile memory relies on solutions to resolve the wear leveling and slow write problems. Different from the past work in compiler-assisted optimization or joint DRAM-PCM management strategies, we explore a light-weighted software-controlled DRAM cache design for the non-volatile-memory-based main memory. The run-time overheads in the management of the DRAM cache is minimized by utilizing the information from a miss of the translation lookaside buffer (TLB) or the cache. Experiments were conducted based on a series of the well-known benchmarks to evaluate the effectiveness of the proposed design, for which the results are very encouraging. © 2015 IEEE."
4,IEEE Symposium on Visual Analytics Science and Technology,2015,Access pattern reshaping for eMMC-enabled SSDs,"The growing popularity of embedded Multi-Media Controllers (eMMCs) presents a unique opportunity to design commodity grade solid-state drives products. This work addresses the essential design issues of such drives and introduces a light-weight FTL design. In particular, access patterns to an eMMC-enabled solid-state drive are reshaped to create sequential access patterns and specific write sizes to better accommodate the characteristics of eMMCs, without resorting to the conventional address translation FTL design. At the same time, garbage collection overheads are minimized with reliability considerations, since eMMCs are usually not equipped with a powerful controller of a sophisticated design. The capability of the proposed design is evaluated by a series of experiments, for which we have very encouraging results. © 2015 IEEE."
5,IEEE Symposium on Visual Analytics Science and Technology,2015,STRAP: Stress-aware placement for aging mitigation in runtime reconfigurable architectures,"Aging effects in nano-scale CMOS circuits impair the reliability and Mean Time to Failure (MTTF) of embedded systems. Especially for FPGAS that are manufactured in the latest technology node, aging is amajor concern. We introduce the first cross-layer aging-aware placement method for accelerators in FPGA-based runtime reconfigurable architectures. It optimizes stress distribution by accelerator placement at runtime, i.e. to which reconfigurable region an accelerator shall be reconfigured. Additionally, it optimizes logic placement at synthesis time to diversify the resource usage of individual accelerators, i.e. which CLBs of a reconfigurable region shall be used by an accelerator. Both layers together balance the intra- and inter-region stress induced by the application workload at negligible performance cost. Experimental results show significant reduction of maximum stress of up to 64% and 35%, which leads to up to 177% and 14% MTTF improvement relative to state-of-the-art methods w.r.t. HCI and BTI aging, respectively. © 2015 IEEE."
6,IEEE Symposium on Visual Analytics Science and Technology,2015,Self-aware Cyber-Physical Systems-on-Chip,"Self-awareness has a long history in biology, psychology, medicine, and more recently in engineering and computing, where self-aware features are used to enable adaptivity to improve a system's functional value, performance and robustness. With complex many-core Systems-on-Chip (SoCs) facing the conflicting requirements of performance, resiliency, energy, heat, cost, security, etc. - in the face of highly dynamic operational behaviors coupled with process, environment, and workload variabilities - there is an emerging need for self-awareness in these complex SoCs. Unlike traditional MultiProcessor Systems-on-Chip (MPSoCs), self-aware SoCs must deploy an intelligent co-design of the control, communication, and computing infrastructure that interacts with the physical environment in real-time in order to modify the system's behavior so as to adaptively achieve desired objectives and Quality-of-Service (QoS). Self-aware SoCs require a combination of ubiquitous sensing and actuation, health-monitoring, and statistical model-building to enable the SoC's adaptation over time and space. After defining the notion of self-awareness in computing, this paper presents the Cyber-Physical System-on-Chip (CPSoC) concept as an exemplar of a self-aware SoC that intrinsically couples on-chip and cross-layer sensing and actuation using a sensor-actuator rich fabric to enable self-awareness. © 2015 IEEE."
7,IEEE Symposium on Visual Analytics Science and Technology,2015,Fine-grained aging prediction based on the monitoring of run-time stress using DFT infrastructure,"Run-time solutions based on real-time monitoring and adaptation are required for resilience in nanoscale integrated circuits as design-time solutions and guard bands are no longer sufficient. Bias Temperature Instability (BTI)-induced transistor aging, one of the major reliability threats in nanoscale VLSI, degrades path delay over time and may eventually induce circuit failure due to timing violations. Chip health monitoring is, therefore, necessary to track delay changes on a per-chip basis. Chip-monitoring techniques based on actual measurement of path delays can only track a coarse-grained aging trend in a reactive manner. In this paper, we show how the on-chip design for test (DFT) infrastructure can be reused in order to perform fine-grain workload-induced stress monitoring for accurate aging prediction. The captured stress information is fed to a prediction model in real-time. The prediction model is trained offline using support-vector regression and implemented in software. This approach can leverage proactive adaptation techniques to mitigate further aging of the circuit by monitoring aging trends. Simulation results for realistic open-source benchmark circuits highlight the accuracy of the proposed approach. © 2015 IEEE."
8,IEEE Symposium on Visual Analytics Science and Technology,2015,Self learning analog/mixed-signal/RF systems: Dynamic adaptation to workload and environmental uncertainties,"Real-time systems for wireless communication, digital signal processing and control experience a wide gamut of operating conditions (signal/channel noise, workload demand, perturbed process conditions). As device bandwidths expand, it becomes increasingly expensive, from a power consumption and reliability perspective, to operate such real-time systems for worst-case (static) performance requirements. In contrast, it is attractive to design algorithms, architectures and circuits that are power-performance tunable and can adapt dynamically, via self-learning techniques, to the requirements of system-level applications for extended battery usage and device lifetime. Such future systems will feed application level demands to the underlying algorithm-architecture-circuit design fabric through built-in sense-and-control infrastructure (hardware, software). The sense functions assess instantaneous application level demands (e.g. throughput, signal integrity) as well as the performances of the individual hardware components as determined by manufacturing process conditions. The control functions actuate algorithm-through-circuit level tuning knobs that continuously trade off performance vs. power of the individual software and hardware modules in such a way as to deliver the end-to-end desired application level Quality of Service (QoS), while minimizing energy/power consumption. Application to wireless communications systems, digital signal processing and control algorithms is discussed. © 2015 IEEE."
9,IEEE Symposium on Visual Analytics Science and Technology,2015,None,None
10,IEEE Symposium on Visual Analytics Science and Technology,2015,Code transformations based on speculative SDC scheduling,"Code motion and speculations are usually exploited in the High Level Synthesis of control dominated applications to improve the performances of the synthesized designs. Selecting the transformations to be applied is not a trivial task: their effects can indeed indirectly spread across the whole design, potentially worsening the quality of the results. In this paper we propose a code transformation flow, based on a new extension of the System of Difference Constraints (SDC) scheduling algorithm, which introduces a large number of transformations, whose profitability is guaranteed by SDC formulation. Experimental results show that the proposed technique in average reduces the execution time of control dominated applications by 37% with respect to a commercial tool without increasing the area usage. © 2015 IEEE."
11,IEEE Symposium on Visual Analytics Science and Technology,2015,ElasticFlow: A complexity-effective approach for pipelining irregular loop nests,"Modern high-level synthesis (HLS) tools commonly employ pipelining to achieve efficient loop acceleration by overlapping the execution of successive loop iterations. However, existing HLS techniques provide inadequate support for pipelining irregular loop nests that contain dynamic-bound inner loops, where unrolling is either very expensive or not even applicable. To overcome this major limitation, we propose ElasticFlow, a novel architectural synthesis approach capable of dynamically distributing inner loops to an array of loop processing units (LPUs) in a complexity-effective manner. These LPUs can be either specialized to execute an individual loop or shared amongst multiple inner loops for area reduction. We evaluate ElasticFlow using a variety of real-life applications and demonstrate significant performance improvements over a widely used commercial HLS tool for Xilinx FPGAS. © 2015 IEEE."
12,IEEE Symposium on Visual Analytics Science and Technology,2015,Communication scheduling and buslet synthesis for low-interconnect HLS designs,"Current nanoscale designs are highly interconnect dominated, taking about 70% of the chip area. Interconnects also consume significant dynamic power, and about 60% of signal delays. It is thus important to be able to synthesize much lower interconnect-complexity designs than are possible with current high-level synthesis (HLS) tools and algorithms. Towards that end, we have developed the new paradigms of: a) flexibly-structured buslets that connect a few neighborhood functional units (FUs) instead of dedicated interconnect between pairs of FUs, thereby sharing interconnects among a number of FU pairs that need to communicate; b) communication scheduling (followed by standard operation scheduling) in which communication between FUs are scheduled at appropriate times to minimize the number of buslets needed, subject to buslet cardinality constraints (for the purpose of upper bounding signal delay). Using a force-directed technique for communication and operation scheduling, and a chronological algorithm that simultaneously performs communication-to-buslet, FU-connections-to-buslets and operation-to-FU binding, we obtain significant wirelength (WL) reduction in the range of 35-71% in our designs compared to conventional FDS-based designs with dedicated-interconnects between communicating FU pairs. © 2015 IEEE."
13,IEEE Symposium on Visual Analytics Science and Technology,2015,MEMIN: SAT-based exact minimization of incompletely specified Mealy machines,"In this paper, we take a fresh look at a well-known NP-complete problem-the exact minimization of incompletely specified Mealy machines. Most existing exact techniques in this area are based on the enumeration of sets of compatible states, and the solution of a covering problem. We propose a different approach. In our approach, first, a polynomial-time algorithm is used to compute a partial solution. This partial solution is then extended to a minimum-size complete solution by solving a series of boolean satisfiability (SAT) problems. We evaluate our implementation on the same set of benchmarks used previously in the literature. On a number of hard benchmarks, our approach outperforms existing exact minimization techniques by several orders of magnitude; it is even competitive with state-of-the-art heuristic approaches on most benchmarks. © 2015 IEEE."
14,IEEE Symposium on Visual Analytics Science and Technology,2015,Global routing with inherent static timing constraints,"We show how to incorporate global static timing constraints into global routing. Our approach is based on the min-max resource sharing model that proved successful for global routing in theory and practice. Static timing constraints are modeled by a linear number of additional resources and customers. The algorithm dynamically adjusts delay budgets and can, thus, trade off wiring congestion for delay. The approach works for many delay models. As a subroutine, the algorithm routes a single net. If this subroutine is near-optimal, we will find near-optimal solutions for the overall problem very efficiently. We demonstrate the benefit of our timing-driven global routing algorithm by experimental results on industrial chips. © 2015 IEEE."
15,IEEE Symposium on Visual Analytics Science and Technology,2015,TILA: Timing-driven incremental layer assignment,"As VLSI technology scales to deep submicron and beyond, interconnect delay greatly limits the circuit performance. The traditional 2D global routing and subsequent net by net assignment of available empty tracks on various layers lacks a global view for timing optimization. To overcome the limitation, this paper presents a timing driven incremental layer assignment tool, TILA, to reassign layers among routing segments of critical nets and non-critical nets. Lagrangian relaxation techniques are proposed to iteratively provide consistent layer/via assignments. Modeling via min-cost flow for layer shuffling avoids using integer programming and yet guarantees integer solutions via uni-modular property of the inherent model. In addition, multiprocessing of K × K partitions of the whole chip provides run time speed up. Certain parameters introduced in the models provide trade-off between timing optimization and via count. Experimental results in both ISPD'08 and industry benchmark suites demonstrate the effectiveness of the proposed incremental algorithms. © 2015 IEEE."
16,IEEE Symposium on Visual Analytics Science and Technology,2015,Accelerate FPGA routing with parallel recursive partitioning,"FPGA routing is a time-consuming step in the EDA design flow. In this paper we present a coarse-grained recursive partitioning approach to exploit parallelism. The basic idea is to partition the nets into three subsets, where the first subset and the other two subsets consist of potentially conflicting nets and potentially conflicting-free nets, respectively. The two potentially conflicting-free subsets are routed in parallel after the first subset is routed. And all subsets are recursively partitioned in the same way. Furthermore, we point out that the estimated runtime using recursive bisection is close to the optimal estimated runtime using the optimal recursive partitioning, which we can find in polynomial time. The parallel router is implemented using the Message Passing Interface (MPI). Experimental results show that our parallel router ParRoute+ achieves a 7.06× speedup compared to the VPR 7.0 router. This is a 3.36× improvement over a recent coarse-grained parallel router. © 2015 IEEE."
17,IEEE Symposium on Visual Analytics Science and Technology,2015,Synthesis for power-aware clock spines,"Clock tree and clock mesh are two extreme structures of clock networks. Clock tree is good at saving clock wires and power, but is vulnerable to clock skew variation. On the other hand, clock mesh is good at mitigating clock skew variation, but spends considerable wires and power. Well known intermediate structures are clock tree with cross links and clock spine. This work addresses the problem automating the synthesis of clock spine networks. Unlike the clock tree with links between clock nodes, which is a sort of an incremental modification of the structure of clock tree, clock spine network is a completely separated structure from the structures of tree and mesh. Consequently, it is necessary and essential to develop a synthesis algorithm for clock spines, which will be compatible to the existing synthesis algorithms of clock trees and clock meshes. To this end, this work first addresses the problem of automating the synthesis of clock-gated clock spines with the objective of minimizing total clock power while meeting the clock skew and slew constraints. The key idea of our proposed synthesis algorithm is to identify and group the flip-flops with tight correlation of clock-gating operations together to form a spine while accurately predicting and maintaining clock skew and slew variations through the buffer insertion and stub allocation. Through experiments with benchmark circuits, it is shown our power-aware synthesis for clock spines uses significantly less power consumption compared to that of the conventional clock mesh synthesis algorithm at the expense of a little relaxed or the same constraint of clock skew. © 2015 IEEE."
18,IEEE Symposium on Visual Analytics Science and Technology,2015,A novel way to authenticate untrusted Integrated Circuits,"Counterfeit Integrated Circuits (IC) can be very harmful to the security and reliability of critical applications. Physical Unclonable Functions (PUF) have been proposed as a mechanism for uniquely identifying ICs and thus reducing the prevalence of counterfeits. However, maintaining large databases of PUF challenge response pairs and dealing with PUF errors makes it difficult to use PUFs reliably. This paper presents an innovative approach to authenticate PUF challenge response pairs on IC chips. The proposed method can tolerate considerable bit errors from responses of PUFs without the use of error correcting codes. It is successful in authenticating 99.96% authorized chips and filtering out 99.92% cloned chips. The overhead is reduced by 65.62% compared to that of other authenticating solutions. © 2015 IEEE."
19,IEEE Symposium on Visual Analytics Science and Technology,2015,RRAM based lightweight user authentication,"Resistance switching memories have emerged as a promising solution for low power and high density non-volatile storage. Unique electronic properties of resistive RAMs (and memristors) have attracted not only memory applications, but other applications such as neuromorphic computation and security as well. In this paper, we investigate how to take advantage of the availability of RRAM devices or components in the system to perform lightweight user authentication. Based on several well-known features of RRAM devices, we argue that the basic requirements for user authentication are met in RRAM devices. Then, we design three RRAM utility functions, namely Read State, Read Pulse Write State, and Copy State that are critical to develop RRAM based user authentication protocols. We propose two such protocol primitives to illustrate the concepts, layout the hardware design, and discuss the potential attacks to these protocols and the corresponding countermeasures. We conclude that under realistic attacking assumptions, the proposed protocols are secure. Finally, we use PTM's 65nm MOSFET models and perform HSPICE simulation of our proposed RRAM based hardware authentication units to demonstrate the reliability of our protocols against environmental variations such as temperature, noise, unbalanced set/reset, filament formation variation and device aging. © 2015 IEEE."
20,IEEE Symposium on Visual Analytics Science and Technology,2015,EM-based on-chip aging sensor for detection and prevention of counterfeit and recycled ICs,"The counterfeiting and recycled integrated circuits (ICs) has become a major security threat for commercial and military systems. In addition to the huge economic impacts, they post significant security and safety threats on those systems. In this paper, we propose a new lightweight on-chip aging sensor, which is based on the electromigration (EM)-induced aging effects for fast detection and prevention of recycled ICs. Our new EM-based aging sensor exploits the natural aging/failure mechanism of interconnect wires to time the aging of the chip. Compared with existing aging sensor, the new aging sensor can provide more accurate prediction of the chip usage time at smaller area footprints due to its simple structure. The new sensor is based on a newly proposed physics-based stress evolution model of EM effects for accurate prediction of the EM failure. As a result, we can design the interconnect wire structures based on copper interconnect technology so that the resulting wires will have detectable EM failure at a specific time with sufficient accuracy. In order to mitigate the problem of the inherent variations in the metal grain sizes and assess its impacts on the nucleation time of metal wires, a number of parallel properly structured wires are used in the sensor. The parameters of the wires are optimized using the new EM model. Our statistical and variational analysis shows that the proposed aging sensor can accurately predict the targeted failure times in the presence of both inherent uncertainties. Our study also shows that more parallel wires will lead to more accurate statistical predictions at costs of more areas. © 2015 IEEE."
21,IEEE Symposium on Visual Analytics Science and Technology,2015,BoardPUF: Physical Unclonable Functions for printed circuit board authentication,"Physical Unclonable Functions (PUFs) are cryptographic primitives that can be used to generate volatile secret keys for cryptographic operations and enable low-cost authentication of integrated circuits. Existing PUF designs mainly exploit variation effects on silicon and hence are not readily applicable for the authentication of printed circuit boards (PCBs). To tackle the above problem, in this paper, we propose a novel PUF device that is able to generate unique and stable IDs for individual PCB, namely BoardPUF. To be specific, we embed a number of capacitors in the internal layer of PCBs and utilize their variations for key generation. Then, by integrating a cryptographic primitive (e.g. hash function) into BoardPUF, we can effectively perform PCB authentication in a challenge-response manner. Our experimental results on fabricated boards demonstrate the efficacy of BoardPUF. © 2015 IEEE."
22,IEEE Symposium on Visual Analytics Science and Technology,2015,Fine-grain power management in manycore processor and System-on-Chip (SoC) designs,"Circuit and design techniques for fine-grain power management in manycore System-on-Chip (SoC) are presented. Recent advances in dynamic platform control techniques to enable (1) independent voltage-frequency domains, (2) dynamic power budget allocation to various blocks depending on workload, (3) fast dynamic voltage-frequency scaling and (4) fast activation and shutdown, are described. Future challenges and opportunities for complex manycore SoC designs with wide dynamic power-performance range, including near-threshold-voltage (NTV) operation, are summarized. Future trends in multi-voltage designs with integrated voltage regulators are highlighted. © 2015 IEEE."
23,IEEE Symposium on Visual Analytics Science and Technology,2015,The (low) power of less wiring: Enabling energy efficiency in many-core platforms through wireless NoC,"During the last decade, we have witnessed a major transition from computation- to communication-centric design of integrated circuits and systems. In particular, the network-on-chip (NoC) approach has emerged as the major design paradigm for multicore systems-on-chip (SoC). The major challenges in traditional wire-based NoCs are the high latency and power consumption of the multi-hop links. By inserting single-hop long-range wireless links in place of multi-hop wired links, the overall system performance can be significantly improved. We should adopt novel architectures inspired by the on-chip wireless links to design high-performance multi-core chips. In this regard, the small-world network-inspired wireless NoC (WiNoC) has emerged as an enabling interconnection infrastructure to design high-bandwidth and energy-efficient multicore chips. In this paper we present the various challenges and possible solutions for designing energy-efficient massive multicore chips enabled by the WiNoC paradigm. © 2015 IEEE."
24,IEEE Symposium on Visual Analytics Science and Technology,2015,Mathematical models and control algorithms for dynamic optimization of multicore platforms: A complex dynamics approach,"The continuous increase in integration densities contributed to a shift from Dennard's scaling to a parallelization era of multi-/many-core chips. However, for multicores to rapidly percolate the application domain from consumer multimedia to high-end functionality (e.g., security, healthcare, big data), power/energy and thermal efficiency challenges must be addressed. Increased power densities can raise on-chip temperatures, which in turn decrease chip reliability and performance, and increase cooling costs. For a dependable multicore system, dynamic optimization (power / thermal management) has to rely on accurate yet low complexity workload models. Towards this end, we present a class of mathematical models that generalize prior approaches and capture their time dependence and long-range memory with minimum complexity. This modeling framework serves as the basis for defining new efficient control and prediction algorithms for hierarchical dynamic power management of future data-centers-on-a-chip. © 2015 IEEE."
25,IEEE Symposium on Visual Analytics Science and Technology,2015,Mitigating the power density and temperature problems in the nano-era,"This paper introduces the power-density and temperature induced issues in the modern on-chip systems. In particular, the emerging Dark Silicon problem is discussed along with critical research challenges. Afterwards, an overview of key research efforts and concepts is presented that leverage dark silicon for performance and reliability optimization. In case temperature constraints are violated, an efficient dynamic thermal management technique is employed. © 2015 IEEE."
26,IEEE Symposium on Visual Analytics Science and Technology,2015,Optimizing stochastic circuits for accuracy-energy tradeoffs,"Stochastic computing (SC) acts on data encoded by bit-streams, and is an attractive, low-cost and error-tolerant alternative to conventional binary circuits in some important applications such as image processing and communications. We study the use of energy reduction techniques such as voltage or frequency scaling in SC circuits. We show that due to their inherent error-tolerance, SC circuits operate satisfactorily without significant accuracy loss even with aggressive scaling that improves their energy efficiency by orders of magnitude. To find the minimum-energy operating point of an SC circuit, we propose a Markov chain model that allows us to quickly explore the space of operating points. We also investigate opportunities to optimize SC circuits under such aggressive scaling. We find that logical and physical design techniques can be used to significantly expand the already powerful accuracy-energy tradeoff possibilities in SC circuits. Our simulation results show that our optimized SC circuits can tolerate aggressive voltage scaling with no significant SNR degradation after 40% supply voltage reduction (1V to 0.6V), leading to 66% energy saving (20.7pJ to 6.9pJ). Similarly, a 100% frequency boosting (400ps to 200ps) of the optimized circuits leads to no significant SNR degradation for several representative circuits. © 2015 IEEE."
27,IEEE Symposium on Visual Analytics Science and Technology,2015,Analytically modeling power and performance of a CNN system,"Cellular neural networks (CNNs) are a powerful analog architecture that can outperform traditional von Neumann architecture for spatio-temporal information processing applications, e.g., image processing and speech recognition. Much existing work reports energy dissipation for CNNs at the chip level, which includes dissipation of sensors, actuators, and other components. As such, the impacts of various system variables, e.g., application templates, characteristics of the resistive element, etc., on the energy profile of a CNN cannot be easily determined. In this work, we propose analytical models to estimate CNN power and performance (measured by settling time). Power dissipations, and settling times obtained via the models for different linear, and non-linear characteristics are verified through circuit simulation. Simulation results show that the proposed models predict power dissipation and settling time with less than 1% and 3% errors, respectively. By using these models, we have also performed case studies for a tactile sensing problem, and a pattern recognition problem to compare power and performance between tunneling field effect transistor (TFET) based non-linear CNN and conventional linear resistor based CNN. © 2015 IEEE."
28,IEEE Symposium on Visual Analytics Science and Technology,2015,Mitigating effects of non-ideal synaptic device characteristics for on-chip learning,"The cross-point array architecture with resistive synaptic devices has been proposed for on-chip implementation of weighted sum and weight update in the training process of learning algorithms. However, the non-ideal properties of the synaptic devices available today, such as the nonlinearity in weight update, limited ON/OFF range and device variations, can potentially hamper the learning accuracy. This paper focuses on the impact of these realistic properties on the learning accuracy and proposes the mitigation strategies. Unsupervised sparse coding is selected as a case study algorithm. With the calibration of the realistic synaptic behavior from the measured experimental data, our study shows that the recognition accuracy of MNIST handwriting digits degrades from ?97 % to ?65 %. To mitigate this accuracy loss, the proposed strategies include 1) the smart programming schemes for achieving linear weight update; 2) a dummy column to eliminate the off-state current; 3) the use of multiple cells for each weight element to alleviate the impact of device variations. With the improved synaptic behavior by these strategies, the accuracy increases back to ?95 %, enabling the reliable integration of realistic synaptic devices in the neuromorphic systems. © 2015 IEEE."
29,IEEE Symposium on Visual Analytics Science and Technology,2015,Robust communication with IoT devices using wearable brain machine interfaces,"Proliferation of internet-of-things (IoT) will lead to scenarios where humans will interact with and control a variety of networked devices including sensors and actuators. Wearable brain-machine interfaces (BMI) can be a key enabler of this interaction for people with disabilities and limited motor skills. At the same time, BMI can improve the experience of healthy individuals significantly. However, state-of-the-art BMI systems have limited applicability as they are prone to errors even with sophisticated machine learning algorithms used for classifying the electroencephalogram (EEG) signals. We improve the reliability of BMI communication significantly by proposing two techniques at higher abstraction layers. Our first contribution is a command confirmation protocol that protects the brain-machine communication against false interpretations at run time. The second contribution is an off-line optimal event selection algorithm that identifies the most reliable subset of events supported by the target BMI system. The event selection is guided by novel user specific reliability metrics defined for the first time in this paper. Extensive experiments using a commercial BMI system demonstrate that the proposed techniques increase the communication robustness significantly, and reduce the time to complete a complex navigation task by 63% on average. © 2015 IEEE."
30,IEEE Symposium on Visual Analytics Science and Technology,2015,Simulation-guided parameter synthesis for chance-constrained optimization of control systems,"We consider the problem of parameter synthesis for black-box systems whose operations are jointly influenced by a set of tunable parameters under the control of designers, and a set of uncontrollable stochastic parameters. The goal is to find values of the tunable parameters that ensure the satisfaction of given performance requirements with a high probability. Such problems are common in robust system design, including feedback controllers, biomedical devices, and many others. These can be naturally cast as chance-constrained optimization problems, which however, are hard to solve precisely. We present a simulation-based approach that provides a piecewise approximation of a certain quantile function for the responses of interest. Using the piecewise approximations as objective functions, a collection of local optima are estimated, from which a global search based on simulated annealing is performed. The search yields tunable parameter values at which the performance requirements are satisfied with a high probability, despite variations in the stochastic parameters. Our approach is applied to three benchmarks: an insulin infusion pump model for type-1 diabetic patients, a robust flight control problem for fixed-wing aircrafts, and an ODE-based apoptosis model from system biology. © 2015 IEEE."
31,IEEE Symposium on Visual Analytics Science and Technology,2015,A mixed discrete-continuous optimization scheme for Cyber-Physical System architecture exploration,"We propose a methodology for architecture exploration for Cyber-Physical Systems (CPS) based on an iterative, optimization-based approach, where a discrete architecture selection engine is placed in a loop with a continuous sizing engine. The discrete optimization routine proposes a candidate architecture to the sizing engine. The sizing routine optimizes over the continuous parameters using simulation to evaluate the physical models and to monitor the requirements. To decrease the number of simulations, we show how balance equations and conservation laws can be leveraged to prune the discrete space, thus achieving significant reduction in the overall runtime. We demonstrate the effectiveness of our methodology on an industrial case study, namely an aircraft environmental control system, showing more than one order of magnitude reduction in optimization time. © 2015 IEEE."
32,IEEE Symposium on Visual Analytics Science and Technology,2015,A user-centric CPU-GPU governing framework for 3D games on mobile devices,"Graphics-intensive mobile games are becoming increasingly popular, but such applications place high demand on device CPUs and GPUS. The design of current mobile systems results in unnecessary energy waste due to lack of consideration of application phases and user attention (a demand-level gap) and because each processor administers power management autonomously (a processor-level gap). This paper proposes a user-centric CPU-GPU governing framework which aims to reduce energy consumption without significantly impacting the user experience. To bridge the gap at the demand level, we identify the user demand at runtime and accordingly determine appropriate governing policies for the respective processors. On the other hand, to bridge the gap at the processor level, the proposed framework interprets the frequency scaling intents of processors based on the observation of the CPU-GPU interaction and the processor status. We implemented our framework on a Samsung Galaxy S4, and conducted extensive experiments with real-world 3D gaming apps. Experimental results showed that, for an application being highly interactive and frequent phase changing, our proposed framework can reduce energy consumption by 45.1% compared with state-of-the-art policy without significantly impacting the user experience. © 2015 IEEE."
33,IEEE Symposium on Visual Analytics Science and Technology,2015,SAT solving using FPGA-based heterogeneous computing,"We present a heterogeneous computing solution to the Boolean satisfiability (SAT) problem. Our field-programmable gate array (FPGA)-based implementation for accelerating the common case computation within a SAT solver utilizes most of the FPGA resources and it seamlessly integrates with our software host. Algorithms and data structures were redesigned to maximize the strengths of customized computing and generalizable optimizations are proposed to maximize throughput, minimize communication latencies, and compact hardware memory. We are significantly faster than state-of-the-art SAT solvers in software and hardware. © 2015 IEEE."
34,IEEE Symposium on Visual Analytics Science and Technology,2015,Heterogeneous hardware/software acceleration of the BWA-MEM DNA alignment algorithm,"The fast decrease in cost of DNA sequencing has resulted in an enormous growth in available genome data, and hence led to an increasing demand for fast DNA analysis algorithms used for diagnostics of genetic disorders, such as cancer. One of the most computationally intensive steps in the analysis is represented by the DNA read alignment. In this paper, we present an accelerated version of BWA-MEM, one of the most popular read alignment algorithms, by implementing a heterogeneous hardware/software optimized version on the Convey HC2ex platform. A challenging factor of the BWA-MEM algorithm is the fact that it consists of not one, but three computationally intensive kernels: SMEM generation, suffix array lookup and local Smith-Waterman. Obtaining substantial speedup is hence contingent on accelerating all of these three kernels at once. The paper shows an architecture containing two hardware-accelerated kernels and one kernel optimized in software. The two hardware kernels of suffix array lookup and local Smith-Waterman are able to reach speedups of 2.8x and 5.7x, respectively. The software optimization of the SMEM generation kernel is able to achieve a speedup of 1.7x. This enables a total application acceleration of 2.6x compared to the original software version. © 2015 IEEE."
35,IEEE Symposium on Visual Analytics Science and Technology,2015,Evolving EDA beyond its E-roots: An overview,"Over the past decade, CMOS scaling has seen increasingly intrusive challenges from cost, variability, energy, reliability, and fundamental device-architectural and materials limitations. To maintain Moore's-Law scaling of integration value, the industry is urgently exploring beyond-silicon and beyond-CMOS device, interconnect and memory options, as well as heterogeneous, More than Moore integration and packaging technologies. This coincides with a turning point for the Electronic Design Automation (EDA) field, which has for 50+ years been a key enabler of the semiconductor industry's amazing growth. Maturation of the EDA industry and its related academic research efforts inevitably result in a spiral of declining valuations (multiples), venture capital investments, research funding, and student interest. To counter this trajectory, the EDA field's business models, research portfolios, and funding models have been going through various diversifications, but in a rather ad-hoc manner. This begs the question of how the paradigms and research methodologies of EDA can be leveraged for design automation (DA) in other, emerging domains. Arguably, more efficient evolution and growth as a community requires a more systematic, coherent effort - as well as forward-looking vision - to steer by. In this paper, we review initial efforts of a new IEEE CEDA technical activity group dedicated to this purpose. These efforts span the cataloguing of past and current research trends, development of new metrics of research impact, and visions for future applications of EDA paradigms in broader design automation contexts. It is hoped that these efforts will be useful to the EDA community as it continues to evolve beyond its E-roots. © 2015 IEEE."
36,IEEE Symposium on Visual Analytics Science and Technology,2015,DA systemization of knowledge: A catalog of prior forward-looking initiatives,"Electronic Design Automation (EDA) has had a profound impact on the development of modern computing and information technology which in turn has transformed our lives and society. Despite its dominant focus on electronics, EDA is one of the first fields in engineering that has taken a truly interdisciplinary route: several abstractions, computational models, algorithms, methodologies, and tools have been jointly developed by the chemists, device physicists, electrical engineers, computer scientists, applied mathematicians, and optimization experts. These EDA tools are capable of not only synthesizing and optimizing design from its high-level functional description to physical entity, but also performing the complex tasks of simulation and verification. In recent years, with the Moore's law approaching it's near-end, a number of studies and new-initiatives have been focusing on more contemporary problems and novel application domains for the field. This paper provides an overview of knowledge gathered by the prior forward-looking efforts pursued by the EDA community. Our goal is to systemize the knowledge, trends, and visions that can help DA community to move beyond its traditional boundaries. © 2015 IEEE."
37,IEEE Symposium on Visual Analytics Science and Technology,2015,Toward metrics of design automation research impact,"Design automation (DA) research has for over fifty years been performed in academia, semiconductor and system companies, and EDA companies worldwide. This research has been enabling to continued scaling of design productivity and growth of the semiconductor industry. For product companies, funding program managers and individual researchers alike, a highly relevant question is: what DA research, and what DA research outcomes, ultimately have the greatest impact? In this paper, we present measurements and analyses of DA research outputs (papers, patents, EDA companies), upon which future metrics of DA research impact might be based. Our studies consider 47000+ conference and journal papers from 1964-2014; the inter-patent citation graph over 759000+ DA-related patents; abstracts of 1150+ U.S. NSF projects over a three-decade span; 36 research needs documents of the Semiconductor Research Corporation from 2000-2013; and market segmentation of hundreds of EDA companies. We identify several interesting correlations, but do not claim to identify causal relationships; indeed, connecting traditional measures of research output to real-world impacts seems quite challenging. We conclude with several directions and targets for future investigation. © 2015 IEEE."
38,IEEE Symposium on Visual Analytics Science and Technology,2015,DA vision 2015: From here to eternity,"Design automation (DA) is at a historical moment where it has a chance - after mathematics, statistics, and computer science - to establish itself as the fourth universal approach with widespread applications in a variety of scientific, engineering, and economic domains. We start by outlining some of the most important research contributions and industrial applications of the design automation; we identify key conceptual DA techniques and describe how they interact to form synthesis and analysis flows. Next, we discuss the most attractive emerging and pending DA domains by analyzing several recent technologies, applications, and conceptual trends. Our emphasis is not just on the most challenging research or the most lucrative application areas but also on the technological trends relevant to DA. Furthermore, we elaborate on the types of new DA techniques and tools that are required for further fundamental progress and improved practical relevance. In order to provide a balanced picture of DA, we also identify the most pronounced dangers in false starts and false research in DA. Finally, we briefly discuss the need for a DA educational reform and community social reorganization that are beneficial for rapid and impactful research and development contributions. © 2015 IEEE."
39,IEEE Symposium on Visual Analytics Science and Technology,2015,Impact of loop transformations on software reliability,"Application-level correctness is a useful and widely accepted concept for many kinds of applications in this modern world. The results of some applications, such as multimedia, may be incorrect due to transient hardware faults or soft-errors, but they are still acceptable from a user's perspective. Thus, it is worthwhile to develop approaches to guarantee application-level correctness in software, instead of hardware, to reduce cost and save energy. Many previous research efforts presented solutions to identify parts of programs that may potentially cause unacceptable results, and placed error detectors to improve reliability. On the other hand, we observe that loop transformations have the ability to improve reliability. By applying suitable loop transformations, some critical instructions may become non-critical. In this paper we propose a metric to analyze the reliability impact of each loop transformation. Thus, we can guide a compiler to optimize programs not only for reliability improvement, but for energy saving. The experimental results show that our analysis perfectly matches the results of fault injection, and achieves a 39.72% energy saving while improving performance by 52.16% when compared with [1]. To our knowledge, this is the first work that considers a software reliability by loop transformations. © 2015 IEEE."
40,IEEE Symposium on Visual Analytics Science and Technology,2015,Error-tolerant processors: Formal specification and verification,"There has been significant recent research in reliable architectures. This is in response to the perceived hardware failure threats faced by late- and post-CMOS devices, e.g., energized particle hits, increasing variability of device parameters and aging-related failures. This body of research proposes specific micro-architecture mechanisms to defend against these threats. Each proposed mechanism makes some assumptions about the underlying fault model and addresses some set of errors. Of particular interest are error-tolerant processors which do not guarantee that the processor will execute each instruction strictly as per the ISA, but rather provide a best-effort response to these faults. These processors are suited for application classes which are error-tolerant, e.g. media processing, and thus provide useful output even without strictly implementing their ISA. What is left unsaid is the minimum guarantees that they must provide to result in useful computation. This paper addresses this question. It makes the following contributions (i) It provides a minimum set of properties that such processors must satisfy, e.g., progress and non-accumulating errors, and states these formally using temporal logic for a model of the processor. This model captures not just the error-free function, but also the faults and the error response mechanisms. (ii) We have developed such full-system models for two case studies of recently proposed fault-tolerant processors, YMM [16] and ERSA [5]. (iii) Further, we present the result of model checking these properties for both case-studies and show that they do not fully satisfy these properties. © 2015 IEEE."
41,IEEE Symposium on Visual Analytics Science and Technology,2015,FEMTO: Fast error analysis in Multipliers through Topological Traversal,"Approximate computing has emerged as a circuit design technique that can reduce system power without significantly sacrificing the output quality in error-resilient applications. However, there are few approaches for systematically and efficiently determining the error introduced by approximate hardware units. This paper focuses on the development of error analysis techniques for approximate multipliers, which are a key hardware component used in error-resilient applications, and presents a novel algorithm that efficiently determines the probability distribution of the error introduced by the approximation. The accuracy of the technique is demonstrated to be comparable to Monte Carlo simulations, while being significantly less computationally intensive. © 2015 IEEE."
42,IEEE Symposium on Visual Analytics Science and Technology,2015,Pairwise proximity-based features for test escape screening,"Test escapes are chips that pass the chip-level test program but fail system-level test or in the field. It is known that statistical analysis based on chip production test data could identify abnormalities for screening test escapes. It has also been shown that from the chip test data, we can generate revealing features for statistical analysis by comparing the measurement data to different references such as the measurement mean of a wafer, the spatial pattern of a wafer, and the measurements of neighboring chips. Given these existing features as the base features, this paper proposes a new class of transformations which could generate additional informative features based on pairwise proximities between chips on the same wafer. Specifically, we apply multiple distance functions in a feature space composed of the base features and calculate the corresponding pairwise proximities between each pair of chips. Each of the resulting proximities could potentially embed some unique information that reveals the abnormalities of some test escapes. Then we convert the proximities into Euclidean vector spaces using constant shift embedding (CSE), which preserves the cluster structure through the conversion, so that traditional outlier analysis algorithms such as local outlier factor (LOF) can be applied. The LOF value and the first dimension in each embedded space are used as additional features for each sample. These new features, jointly analyzed with the base features, provide more revealing information about test escapes and thus further improve the test escape detection rate in our experiment based on production test data. © 2015 IEEE."
43,IEEE Symposium on Visual Analytics Science and Technology,2015,None,None
44,IEEE Symposium on Visual Analytics Science and Technology,2015,Performance evaluation of software-based error detection mechanisms for localizing electrical timing failures under dynamic supply noise,"For facilitating error localization, software-based error detection techniques have been proposed and EDM (error detection mechanisms) transformation is one of these techniques. To discuss the effectiveness of EDM for electrical bug localization, two scenarios are considered; (1) localizing an electrical bug occurred in the original program, and (2) localizing as many potential bugs as possible. We experimentally evaluated the error detection performance in these two scenarios under dynamic power supply noise. Experimental results show that the EDM transformation customized for quick error detection cannot locate electrical bugs in the original program in the firs scenario, but it is useful for findin potential bugs in the second scenario. © 2015 IEEE."
45,IEEE Symposium on Visual Analytics Science and Technology,2015,High level synthesis of RDF queries for graph analytics,"In this paper we present a set of techniques that enable the synthesis of efficient custom accelerators for memory intensive, irregular applications. To address the challenges of irregular applications (large memory footprint, unpredictable fine-grained data accesses, and high synchronization intensity), and exploit their opportunities (thread level parallelism, memory level parallelism), we propose a novel accelerator design that employs an adaptive and Distributed Controller (DC) architecture, and a Memory Interface Controller (MIC) that supports concurrent and atomic memory operations on a multi-ported/multi-banked shared memory. Among the multitude of algorithms that may benefit from our solution, we focus on the acceleration of graph analytics applications and, in particular, on the synthesis of SPARQL queries on Resource Description Framework (RDF) databases. We achieve this objective by incorporating the synthesis techniques into Bambu, an Open Source high-level synthesis tools, and interfacing it with GEMS, the Graph database Engine for Multithreaded Systems. The GEMS' front-end generates optimized C implementations of the input queries, modeled as graph pattern matching algorithms, which are then automatically synthesized by Bambu. We validate our approach by synthesizing several SPARQL queries from the Lehigh University Benchmark (LUBM). © 2015 IEEE."
46,IEEE Symposium on Visual Analytics Science and Technology,2015,CAMs as synchronizing caches for multithreaded irregular applications on FPGAS,"Irregular applications, by their very nature, suffer from poor data locality. This often results in high miss rates for caches, and many long waits to off-chip memory. Historically, long latencies have been dealt with in two ways: (1) latency mitigation using large cache hierarchies, or (2) latency masking where threads relinquish their control after issuing a memory request. Multithreaded CPUs are designed for a fixed maximum number of threads tailored for an average application. FPGAS, however, can be customized to specific applications. Their massive parallelism is well known, and ideally suited to dynamically manage hundreds, or thousands of threads. Multithreading, in essence, trades memory bandwidth for latency. Therefore, to achieve a high throughput, the system must support a large memory bandwidth. Many irregular application, however, must rely on inter-thread synchronization for parallel execution. In-memory synchronization suffers from very long memory latencies. In this paper we describe the use of CAMs (Content Addressable Memories) as synchronizing caches for hardware multithreading. We demonstrate and evaluate this mechanism using graph breadth-first search (BFS). © 2015 IEEE."
47,IEEE Symposium on Visual Analytics Science and Technology,2015,None,None
48,IEEE Symposium on Visual Analytics Science and Technology,2015,Security policy enforcement in modern SoC designs,"Modern SoC designs contain a large number of sensitive assets that must be protected from unauthorized access. Authentication mechanisms which control the access to such assets are governed by complex security policies. The security policies affect multiple design blocks and may involve subtle interactions among hardware, firmware, OS kernel, and applications. The implementation of security policies in an SoC design, often referred to as its security architecture, is a subtle composition of coordinating design modules distributed across the different IPs. Toward this direction, this paper gives an overview of SoC security architectures in modern SoC designs and provides a glimpse of their implementation, as well as their design complexities and functional shortcomings. Design of security architectures involves a complex interplay of requirements from functionality, power, security, and validation. We also outline some of the research needs in the area for developing robust, trustworthy SoC designs. © 2015 IEEE."
49,IEEE Symposium on Visual Analytics Science and Technology,2015,Protecting endpoint devices in IoT supply chain,"The Internet of Things (IoT), an emerging global network of uniquely identifiable embedded computing devices within the existing Internet infrastructure, is transforming how we live and work by increasing the connectedness of people and things on a scale that was once unimaginable. In addition to increased communication efficiency between connected objects, the IoT also brings new security and privacy challenges. Comprehensive measures that enable IoT device authentication and secure access control need to be established. Existing hardware, software, and network protection methods, however, are designed against fraction of real security issues and lack the capability to trace the provenance and history information of IoT devices. To mitigate this shortcoming, we propose an RFID-enabled solution that aims at protecting endpoint devices in IoT supply chain. We take advantage of the connection between RFID tag and control chip in an IoT device to enable data transfer from tag memory to centralized database for authentication once deployed. Finally, we evaluate the security of our proposed scheme against various attacks. © 2015 IEEE."
50,IEEE Symposium on Visual Analytics Science and Technology,2015,A polyhedral-based SystemC modeling and generation framework for effective low-power design space exploration,"With the prevalence of System-on-Chips there is a growing need for automation and acceleration of the design process. A classical approach is to take a C/C++ specification of the application, convert it to a SystemC (or equivalent) description of hardware implementing this application, and perform successive refinement of the description to improve various design metrics. In this work, we present an automated SystemC generation and design space exploration flow alleviating several productivity and design time issues encountered in the current design process. We first automatically convert a subset of C/C++, namely affine program regions, into a full SystemC description through polyhedral model-based techniques while performing powerful data locality and parallelism transformations. We then leverage key properties of affine computations to design a fast and accurate latency and power characterization flow. Using this flow, we build analytical models of power and performance that can effectively prune away a large amount of inferior design points very fast and generate Pareto-optimal solution points. Experimental results show that (1) our SystemC models can evaluate system performance and power that is only 0.57% and 5.04% away from gate-level evaluation results, respectively; (2) our latency and power analytical models are 3.24% and 5.31% away from the actual Pareto points generated by SystemC simulation, with 2091x faster design-space exploration time on average. The generated Pareto-optimal points provide effective low-power design solutions given different latency constraints. © 2015 IEEE."
51,IEEE Symposium on Visual Analytics Science and Technology,2015,Uncore RPD: Rapid design space exploration of the uncore via regression modeling,"A regression-based design space exploration methodology is proposed that models the impacts of the memory hierarchy and the network-on-chip (NoC) on the overall chip multiprocessor (CMP) performance. Designers cannot explore all possible designs for a NoC without considering interactions with the rest of the uncore, in particular the cache configuration and memory hierarchy which determine the amount and pattern of the traffic on the NoC. The proposed regression model is able to capture the salient design points of the uncore for a comprehensive design space exploration by designing memory and NoC-specific regression models and leveraging recent advances in uncore simulation. To show the utility of our methodology, Uncore RPD, two case studies are presented: i) analyzing and refining regression models for an 8-core CMP and ii) performing a rapid design space exploration to find best performing designs of a NoC-based CMP given area-constraints for CMPs of up to 64 cores. Through these case studies, it is shown that i) simultaneous consideration of the memory and NoC parameters in the NoC design space exploration can refine uncore-based regression models, ii) sampling techniques must consider the dynamic design space of the uncore, and iii) overall, the proposed regression models reduce the amount of simulations required to characterize the NoC design space by up to four orders of magnitude. © 2015 IEEE."
52,IEEE Symposium on Visual Analytics Science and Technology,2015,Multi-threaded Simics SystemC Virtual Platform,"The functional simulator Simics provides a co-simulation integration path with a SystemC simulation environment to create Virtual Platforms. With increasing complexity of the SystemC models, this platform suffers from performance degradation due to the single threaded nature of the integrated Virtual Platform. In this paper, we present a multi-threaded Simics SystemC platform solution that significantly improves performance over the existing single threaded solution. The two schedulers run independently, only communicating in a thread safe manner through a message interface. Simics based logging and check-pointing are preserved within SystemC and tied to the corresponding Simics' APIs for a seamless experience. The solution also scales to multiple SystemC models within the platform, each running its own thread with an instantiation of the SystemC kernel. A second multi-cell solution is proposed providing comparable performance with the multi-thread solution, but reducing the burden of integration on the SystemC model. Empirical data is presented showing performance gains over the legacy single threaded solution. © 2015 IEEE."
53,IEEE Symposium on Visual Analytics Science and Technology,2015,PARADE: A cycle-accurate full-system simulation Platform for Accelerator-Rich Architectural Design and Exploration,"The power wall and utilization wall in today's processors have led to a focus on accelerator-rich architecture, which will include a sea of accelerators that can achieve orders-of-magnitude performance and energy gains. The emerging accelerator-rich architecture is still in its early stage, and many design issues, such as the efficient accelerator resource management and communication between accelerators and CPU cores, remain unclear. Therefore, a research platform that can enable those design explorations will be extremely useful. This paper presents the first cycle-accurate full-system simulation Platform for Accelerator-Rich Architectural Design and Exploration (PARADE). PARADE can automatically generate dedicated or composable accelerator simulation modules, simulate the global accelerator management, a coherent cache/scratchpad with shared memory, and a customizable network-on-chip-all at cycle-level. In addition, PARADE provides visualization support to assist architects with design space exploration. Finally, a few case studies are conducted to confirm that PARADE can enable various system-level design space explorations in the accelerator-rich architecture. © 2015 IEEE."
54,IEEE Symposium on Visual Analytics Science and Technology,2015,None,None
55,IEEE Symposium on Visual Analytics Science and Technology,2015,None,None
56,IEEE Symposium on Visual Analytics Science and Technology,2015,Defect probability of directed self-assembly lithography: Fast identification and post-placement optimization,"In directed self-assembly lithography (DSAL), an inter-cell cluster of contacts, which crosses the boundary of cells, is more likely to cause patterning failure because corresponding guide pattern (GP) has not been verified beforehand. All forms of inter-cell clusters can systematically be identified and grouped, which allows us to define DSA defect probability when two arbitrary cells are placed side by side. We then address post-placement optimization, in which some cells are flipped and some cells are swapped with their adjacent cells so that the number of whitespaces inserted in between cell pairs of high defect probability is minimized. Experiments with a few test circuits demonstrate 11% increase of placement density, on average, with no expected DSA defects. © 2015 IEEE."
57,IEEE Symposium on Visual Analytics Science and Technology,2015,None,None
58,IEEE Symposium on Visual Analytics Science and Technology,2015,DRUM: A Dynamic Range Unbiased Multiplier for approximate applications,"Many applications for signal processing, computer vision and machine learning show an inherent tolerance to some computational error. This error resilience can be exploited to trade off accuracy for savings in power consumption and design area. Since multiplication is an essential arithmetic operation for these applications, in this paper we focus specifically on this operation and propose a novel approximate multiplier with a dynamic range selection scheme. We design the multiplier to have an unbiased error distribution, which leads to lower computational errors in real applications because errors cancel each other out, rather than accumulate, as the multiplier is used repeatedly for a computation. Our approximate multiplier design is also scalable, enabling designers to parameterize it depending on their accuracy and power targets. Furthermore, our multiplier benefits from a reduction in propagation delay, which enables its use on the critical path. We theoretically analyze the error of our design as a function of its parameters and evaluate its performance for a number of applications in image processing, and machine classification. We demonstrate that our design can achieve power savings of 54% - 80%, while introducing bounded errors with a Gaussian distribution with near-zero average and standard deviations of 0.45% - 3.61%. We also report power savings of up to 58% when using the proposed design in applications. We show that our design significantly outperforms other approximate multipliers recently proposed in the literature. © 2015 IEEE."
59,IEEE Symposium on Visual Analytics Science and Technology,2015,Fast Lagrangian Relaxation based gate sizing using multi-threading,"We propose techniques to achieve very fast multi-threaded gate-sizing and threshold-voltage swap for leakage power minimization. We focus on multi-threading Lagrangian Relaxation (LR) based gate sizing which has shown both better power savings and better runtime compared to other gate sizing approaches. Our techniques, mutual exclusion edge assignment and directed graph-based netlist traversal, maximize thread execution efficiency to take full advantage of the inherent parallelism when solving the LR subproblem, without compromising the leakage power savings. © 2015 IEEE."
60,IEEE Symposium on Visual Analytics Science and Technology,2015,Asynchronous QDI circuit synthesis from signal transition protocols,"Asynchronous circuits are promising in resolving the emerging issue of process variation and high synchronization power consumption. Among various asynchronous delay models, quasi-delay insensitive (QDI) model is the most robust and yet practical one due to its relaxed timing assumption. However, automatic synthesis of QDI circuits from signal transition graph (STG) protocol specification has not yet been proposed, despite the fact that algorithms synthesizing circuits under other delay models do exist. In this paper we propose the first algorithm synthesizing protocols specified in STGs into QDI circuits by analyzing STG structures without utilizing state graph assignment techniques. Furthermore, an optimization technique is proposed to simplify QDI circuits. In our synthesis algorithm, the state explosion issue is avoided, and restrictions on STGs are relaxed. Case studies on Advanced Microcontroller Bus Architecture (AMBA) and other protocols indicate the feasibility of our method. © 2015 IEEE."
61,IEEE Symposium on Visual Analytics Science and Technology,2015,SPOCK: Static performance analysis and deadlock verification for efficient asynchronous circuit synthesis,"Performance analysis and deadlock verification are two critical issues in asynchronous circuit design, which can be advantageous over the synchronous counterpart in terms of robustness against timing variability, security against side-channel attack, and other benefits. Nevertheless, asynchronous design automation tools are far away from mature. In this paper, we advance the synthesis of quasi-delay insensitive (QDI) circuits of pre-charged half buffer (PCHB) and weak-conditioned half buffer (WCHB) pipelines in three respects. First, static performance analysis (SPA) with linear time complexity is generalized from acyclic to cyclic PCHB and WCHB pipelines. Second, a deadlock verification (DV) algorithm with linear time complexity is proposed for checking PCHB and WCHB pipelines using their four-phase marked graph models. Third, we propose a new simple register circuitry for PCHB and WCHB pipelines that consists of one reset-latch and one buffer-latch and is amenable to circuit minimization. With the above two algorithms, we develop an efficient synthesis flow for buffer-latch minimization while maintaining the system throughput and deadlock-free property. Experimental results show the efficiency of our SPA and DV algorithms and demonstrate the effectiveness of our synthesis method with an average of 37% reduction on the number of buffer-laches. As our SPA and DV algorithms are applicable to arbitrary PCHB and WCHB pipelines and our buffer-latch minimization algorithm is orthogonal to existing synthesis methods such as cut-based technology mapping and slack matching, our methods can be generally useful in the analysis, verification, and synthesis of PCHB and WCHB pipelines. © 2015 IEEE."
62,IEEE Symposium on Visual Analytics Science and Technology,2015,None,None
63,IEEE Symposium on Visual Analytics Science and Technology,2015,From robust chip to smart building: CAD algorithms and methodologies for uncertainty analysis of building performance,"Buildings consume about 40% of the total energy use in the U.S. and, hence, accurately modeling, analyzing and optimizing building energy is considered as an extremely important task today. Towards this goal, uncertainty/sensitivity analysis has been proposed to identify the critical physical and environmental parameters contributing to building energy consumption. In this paper, we propose to apply sparse regression techniques to uncertainty/sensitivity analysis of smart buildings. We consider the orthogonal matching pursuit (OMP) algorithm as a case study to demonstrate its superior efficacy over other conventional approaches. Experimental results reveal that OMP achieves up to 18.6× runtime speedups over the conventional least-squares fitting method without surrendering any accuracy. © 2015 IEEE."
64,IEEE Symposium on Visual Analytics Science and Technology,2015,Security analysis of proactive participation of smart buildings in smart grid,"Demand response (DR) is an effective mechanism in improving power system efficiency and reducing energy cost for customers. However, DR processes might be vulnerable to cyber attacks from the usage of advanced metering infrastructure and wide-area network to exchange information. In this paper, we study potential attacks for a proactive demand participation scheme we recently proposed and for a conventional passive demand response scheme, particularly focusing on guideline price manipulation attacks. Our experiment results demonstrate that 1) guideline price manipulations may significantly lower the attacker's own electricity consumption cost while increasing other customers' cost, for both proactive and passive schemes; 2) such impact is less severe in the proactive scheme, i.e., the proactive demand participation scheme is more robust with respect to guideline price manipulation than the conventional DR. © 2015 IEEE."
65,IEEE Symposium on Visual Analytics Science and Technology,2015,None,None
66,IEEE Symposium on Visual Analytics Science and Technology,2015,On relaxing page program disturbance over 3D MLC flash memory,"With the rapidly-increasing capacity demand over flash memory, 3D NAND flash memory has drawn tremendous attention as a promising solution to further reduce the bit cost and to increase the bit density. However, such advanced 3D devices will suffer more intensive program disturbance, compared to 2D NAND flash memory. Especially when multi-level-cell (MLC) technology is adopted, the deteriorated disturbance due to the program operations of intra and inter pages will become even more critical for reliability. In contrast to the past efforts that try to resolve the reliability issue with error correction codes or hardware designs, this work seeks for the redesign of the program operation. A disturb-aware programming scheme is proposed to not only relax the disturbance induced by slow cells as much as possible but also reduce the possibility in requiring a high voltage to program the slow cells. A series of experiments was conducted based on real 3D MLC flash chips, and the results demonstrate that the proposed scheme is extremely effective on reducing the disturbance as well as the bit error rate. © 2015 IEEE."
67,IEEE Symposium on Visual Analytics Science and Technology,2015,Variation-aware adaptive tuning for nanophotonic interconnects,"Short-reach nanophotonic interconnects are promising to solve the communication bottleneck in data centers and chip-level scenarios. However, the nanophotonic interconnects are sensitive to process and thermal variations, especially for the microring structures, resulting in significant variation of an optical link's bit error rate (BER). In this paper, we propose a power-efficient adaptive tuning approach for nanophotonic interconnects to address the variation issues. During the adaptive tuning process, each nanophotonic interconnect is adaptively allocated just enough power to meet the BER requirement. The proposed adaptive tuning approach could reduce the photonic receiver power by 8% - 34% than the worst-case based fixed design while achieving the same BER. Our evaluation results show that the adaptive tuning approach scales well with the process variation, the thermal variation and the number of communication nodes, and can accommodate different types of NoC architectures and lasers. © 2015 IEEE."
68,IEEE Symposium on Visual Analytics Science and Technology,2015,Threshold logic synthesis based on cut pruning,"This paper presents a novel approach to synthesize circuits based on threshold logic gates (TLGs). Emerging technologies, such as memristors, spintronics devices and tunneling diodes, are able to build this class of gates efficiently. For this reason, threshold logic is a promising alternative to conventional CMOS logic. The proposed approach is based on pruning non-threshold-logic cuts in order to limit the search space during technology mapping. As a result, both the number of TLGs and logic depth of the synthesized circuits are reduced. Experimental results have shown that, compared to the state-of-the-art methods, the TLG count is reduced by 8% and logic depth is reduced by 46%. © 2015 IEEE."
69,IEEE Symposium on Visual Analytics Science and Technology,2015,TEI-Turbo: Temperature effect inversion-aware turbo boost for finfet-based multi-core systems,"Energy and temperature are the main constraints for modern high-performance multi-core systems. To save power or increase performance, Dynamic Voltage and Frequency Scaling (DVFS) is widely applied in industry. As CMOS technology continues scaling, FinFET has recently become the common choice for multi-core systems. In contrast with planar CMOS, FinFET is observed to have lower delay under higher temperature in super-threshold voltage region, an effect called temperature effect inversion (TEI). Due to this effect, performance can be further improved under power constraints. This work explores TEI-aware performance improvement for power limited multi-core systems. Our experimental results show that on average 15.70% throughput improvement can be achieved in steady state by a TEI-aware DVFS policy over a TEI-agnostic one. In further investigations, we observe multiple sweet spots in the operating voltage/frequency regions resulting from TEI effects. Based on these sweet spot operation regimes, this work introduces a fast algorithm which determines the maximum performance under power constraints. Experimental results confirm its effectiveness by exhibiting a speedup of an average of 45.9X in runtime while keeping resulting performance only 0.22% away from existing state-of-the-art algorithms. © 2015 IEEE."
70,IEEE Symposium on Visual Analytics Science and Technology,2015,Detailed-routability-driven analytical placement for mixed-size designs with technology and region constraints,"A placer without considering modern technology and region constraints could generate solutions with irresolvable detailed-routing violations or even illegal solutions. This paper presents a high-quality placement algorithm to satisfy technology and region constraints and optimize detailed-routing routability with three major techniques: (1) a clustering algorithm followed by two-round quadratic placement to obtain an initial placement satisfying region constraints, (2) an analytical placement algorithm with new wirelength and density models to consider region constraints, and (3) a legalization algorithm that preserves the solution quality of global placement while satisfying technology/region constraints. Compared with the winning teams of the ISPD 2015 Blockage-Aware Detailed Routing-Driven Placement Contest, our placer achieves the best overall score and detailed-routing results. © 2015 IEEE."
71,IEEE Symposium on Visual Analytics Science and Technology,2015,High performance global placement and legalization accounting for fence regions,"The placement problem has become challenging due to a variety of complicated constraints imposed by modern process technologies. Some of the most challenging constraints were highlighted during the ISPD 2015 placement contest and include fence region and target density constraints; these constraints are in addition to those issues that affect detailed routability such as pin shorts, pin access problems and cell spacing issues. These constraints not only make cell placement more difficult, but can impact the placement objectives such as wire length, routability and so forth. In this paper, we present a comprehensive technique to address fence region constraints in global placement and legalization while still considering detailed-routing issues. We combine concepts from image processing such as region coloring with parallel programming to efficiently deal with fence regions. We also introduce a heuristic method to adjust target densities while avoiding adverse effects on the quality of global routability. Numerical results using both the released and hidden benchmarks from the ISPD 2015 placement contest demonstrate the efficacy of our proposed techniques. © 2015 IEEE."
72,IEEE Symposium on Visual Analytics Science and Technology,2015,None,None
73,IEEE Symposium on Visual Analytics Science and Technology,2015,Exploiting non-critical Steiner tree branches for post-placement timing optimization,"The increasing impact of interconnections on the overall circuit performance renders physical design a crucial step to timing closure. Several techniques are used to optimize timing within the flow, such as gate sizing, buffer insertion, and timing-driven placement (TDP). Unfortunately, gate sizing and buffer insertion are not capable of modifying the length of interconnections. Although TDP is able to shorten critical interconnection by finding new legal locations for a subset of cells, it generally overlooks the impact of non-critical branches on the delay of critical cells. This work proposes a post-placement timing optimization technique to reduce the capacitive load of critical cells by shortening non-critical Steiner tree branches. To shorten such branches, our technique uses computational geometry for finding effective cell movements that consider maximum displacement constraints and macro blocks. Our experiments evaluate the capability of our technique to further reduce the timing violations from a TDP solution. We applied our technique on the solutions obtained by the top 3 teams in the ICCAD 2014 TDP Contest, where short and long displacement constraints are defined. For the short constraints, the average reductions assuming worst and total late negative slack metrics are 23% and 34%. Considering the long constraints, the average reductions are 62% and 67%. We also present extensions of our technique to tackle related physical design problems such as early violations reduction and electrical correction. © 2015 IEEE."
74,IEEE Symposium on Visual Analytics Science and Technology,2015,A flexible architecture for systematic implementation of SoC security policies,"Modern SoC designs incorporate several security policies to protect sensitive assets from unauthorized access. The policies affect multiple design blocks, and may involve subtle interactions between hardware, firmware, and software. This makes it difficult for SoC designers to implement these policies, and system validators to ensure adherence. Associated problems include complexity in upgrading these policies, IP reuse for systems targeted for markets with differing security requirement, and consequent increase in design time and time-to-market. In this paper, we address this important problem by developing a generic, flexible architectural framework for implementing arbitrary security policies in SoC designs. Our architecture has several distinctive features: (1) it relies on a dedicated, centralized, firmware-upgradable plug-and-play IP block that can implement diverse security policies; (2) it interfaces with individual IP blocks through their security wrapper, which exploits and extends test/debug wrappers; (3) it implements a security policy as firmware code following existing security policy languages; (4) it can implement any security policy as long as relevant observable and controllable signals from the constituent IPs are accessible through the security wrappers; and (5) it realizes a low-overhead communication link between security wrappers of IP blocks and the centralized, dedicated controller. The approach builds on and extends the recent work on developing a centralized infrastructure IP for SoC security, referred to as IIPS, that interface with IP blocks using their boundary scan based wrappers. While this architecture is generic and independent of security policy types, we provide case studies with several common policies to show the flexibility and extendibility of the architecture. We also evaluate its viability in terms of overhead in area and power. © 2015 IEEE."
75,IEEE Symposium on Visual Analytics Science and Technology,2015,ConFirm: Detecting firmware modifications in embedded systems using Hardware Performance Counters,"Critical infrastructure components nowadays use microprocessor-based embedded control systems. It is often infeasible, however, to employ the same level of security measures used in general purpose computing systems, due to the stringent performance and resource constraints of embedded control systems. Furthermore, as software sits atop and relies on the firmware for proper operation, software-level techniques cannot detect malicious behavior of the firmware. In this work, we propose ConFirm, a low-cost technique to detect malicious modifications in the firmware of embedded control systems by measuring the number of low-level hardware events that occur during the execution of the firmware. In order to count these events, ConFirm leverages the Hardware Performance Counters (HPCs), which readily exist in many embedded processors. We evaluate the detection capability and performance overhead of the proposed technique on various types of firmware running on ARM- and PowerPC-based embedded processors. Experimental results demonstrate that ConFirm can detect all the tested modifications with low performance overhead. © 2015 IEEE."
76,IEEE Symposium on Visual Analytics Science and Technology,2015,Quantifying timing-based information flow in cryptographic hardware,"Cryptographic function implementations are known to leak information about private keys through timing information. By using statistical analysis of the variations in runtime required to encrypt different messages, an attacker can relatively easily determine the key with high probability. There are many mitigation techniques to combat these side channels; however, there are limited metrics available to quantify the effectiveness of these mitigation attacks. In this work, we employ information theoretic ideas to quantify the amount of leakage that can be extracted from runtime measurements and reveal the influence of individual key bits on the timing observations across a variety of hardware implementations. By studying different RSA hardware architectures (each with different performance optimizations and mitigation techniques), we determine the effectiveness of these information theoretic techniques against the success of attacks. Our experimental results show that mutual information is a promising metric to quantify timing-based information leakage and it also correlates to the attack-ability of a cryptographic implementation. © 2015 IEEE."
77,IEEE Symposium on Visual Analytics Science and Technology,2015,Detecting hardware Trojans in unspecified functionality using mutation testing,"Existing functional Trojan detection methodologies assume Trojans violate the design specification under carefully crafted rare triggering conditions. We present a new type of Trojan that leaks secret information from the design by only modifying unspecified functionality, meaning the Trojan is no longer restricted to being active only under rare conditions. We provide a method based on mutation testing for detecting this new Trojan type along with mutant ranking heuristics to prioritize analysis of the most dangerous functionality. Applying our method to a UART controller design, we discover unspecified and untested bus functionality with the potential to leak 32 bits of information during hundreds of cycles without being detected! Our method also reveals poorly tested interrupt functionality with information leakage potential. After modifying the specification and test bench to remove the discovered vulnerabilities, we close the verification loop by re-analyzing the design using our methodology and observe the functionality is no longer flagged as dangerous. © 2015 IEEE."
78,IEEE Symposium on Visual Analytics Science and Technology,2015,A sample reduction technique by aliasing channel response for fast equalizing transceiver design,"This paper proposes a technique to reduce the sample number of channel's pulse response required to optimize equalization coefficients. In our method, channel's pulse response is aliased in calculating equalization coefficients reducing the number of samples of the channel's frequency response. As a result, the computation time to acquire the channel's frequency response is greatly reduced. To demonstrate our method, equalization coefficients are calculated using the conventional and our methods and then compared. Since the necessary number of samples is reduced by 8 times at most in our method, the computation time is reduced up to by 7.01 times. For accuracy verification, we also calculated the equalized eye sizes using both methods. The calculated eye sizes are almost identical. These results show that using our method, engineers can accurately optimize equalizing transceiver design with reduced efforts to simulate channel's frequency response. © 2015 IEEE."
79,IEEE Symposium on Visual Analytics Science and Technology,2015,Co-Learning Bayesian Model Fusion: Efficient performance modeling of analog and mixed-signal circuits using side information,"Efficient performance modeling of today's analog and mixed-signal (AMS) circuits is an important yet challenging task. In this paper, we propose a novel performance modeling algorithm that is referred to as Co-Learning Bayesian Model Fusion (CL-BMF). The key idea of CL-BMF is to take advantage of the additional information collected from simulation and/or measurement to reduce the performance modeling cost. Different from the traditional performance modeling approaches which focus on the prior information of model coefficients (i.e. the coefficient side information) only, CL-BMF takes advantage of another new form of prior knowledge: the performance side information. In particular, CL-BMF combines the coefficient side information, the performance side information and a small number of training samples through Bayesian inference based on a graphical model. Two circuit examples designed in a commercial 32nm SOI CMOS process demonstrate that CL-BMF achieves up to 5× speed-up over other state-of-the-art performance modeling techniques without surrendering any accuracy. © 2015 IEEE."
80,IEEE Symposium on Visual Analytics Science and Technology,2015,STAVES: Speedy tensor-aided Volterra-based electronic simulator,"Volterra series is a powerful tool for black-box macro-modeling of nonlinear devices. However, the exponential complexity growth in storing and evaluating higher order Volterra kernels has limited so far its employment on complex practical applications. On the other hand, tensors are a higher order generalization of matrices that can naturally and efficiently capture multi-dimensional data. Significant computational savings can often be achieved when the appropriate low-rank tensor decomposition is available. In this paper we exploit a strong link between tensors and frequency-domain Volterra kernels in modeling nonlinear systems. Based on such link we have developed a technique called speedy tensor-aided Volterra-based electronic simulator (STAVES) utilizing high-order Volterra transfer functions for highly accurate time-domain simulation of nonlinear systems. The main computational tools in our approach are the canonical tensor decomposition and the inverse discrete Fourier transform. Examples demonstrate the efficiency of the proposed method in simulating some practical nonlinear circuit structures. © 2015 IEEE."
81,IEEE Symposium on Visual Analytics Science and Technology,2015,Simulation of noise in neurons and neuronal circuits,"Stochastic behavior of ion channels, neurotransmitter release mechanisms and synaptic connections in neurons emerge as a source of variability and noise in neuronal circuits, causing uncertainty in the computations performed by the brain. One can gain insight into this important aspect of brain mechanism via computational modeling. Stochastic behavior in neurons is usually modeled with fine-grained, discrete-state, continuous-time Markov Chains (MCs). Although these models are considered as the golden standard, they become computationally prohibitive in analyzing multi-neuron circuits. Thus, several approximate models, where the random behavior is captured by coarse-grained, continuous-state, continuous-time Stochastic Differential Equations (SDEs), were proposed. In this paper, we first present a general, fine-grained modeling framework based on MC models of ion channels and synaptic processes. We then develop a formalism for automatically generating the corresponding SDE models, based on representing generic/abstract MCs as a set of chemical reactions and by utilizing techniques from stochastic chemical kinetics. With this formalism, we can exploit the sparsity and special structure in the MC models and arrive at compact SDE models. We present results obtained by our neuronal circuit simulator based on the proposed methodology in analyzing stochasticity in neurons and neuronal circuits. We employ numerical simulation techniques that were previously developed for noise in electronic circuits. We point to the use of non Monte Carlo noise analysis techniques for large-scale analysis of noise in the nervous system. © 2015 IEEE."
82,IEEE Symposium on Visual Analytics Science and Technology,2015,Acceleration of nested conditionals on CGRAs via trigger scheme,"Coarse-Grained Reconfigurable Architecture (CGRA) is a promising accelerator when considering both high performance and high power-efficiency. One of the challenges that CGRAs are confronting is to accelerate loops with control flow (if-then-else structures). Existing techniques employ predication to accelerate the conditionals but cannot accelerate nested conditionals efficiently. The state-of-the-art method dual issue scheme issues instructions from both the branch paths and then executes only the instructions from the path chosen by a predicate. But it also cannot handle nested conditionals. In this paper, we propose a solution to map loops with nested conditionals on a CGRA for the Triggered Instruction Architecture (TIA) paradigm - in which lacks compiler support. Experimental results show:We can accelerate loop kernels with nested conditionals via trigger scheme average of 1.41×, 1.79× and 1.29× better performance compared to partial predication, full predication and dual issue scheme respectively. © 2015 IEEE."
83,IEEE Symposium on Visual Analytics Science and Technology,2015,Smartphone analysis and optimization based on user activity recognition,"Behavior of smartphone systems is highly influenced by user interactions, such as 'zooming' and 'scrolling', which determine the execution phases within applications and lead to different power and performance demands. Current power and thermal management algorithms are agnostic to these behaviors. We propose a novel user activity recognition framework that enables user activity-aware system decisions. The proposed framework carefully monitors system events initiated by user interactions and identifies the current user activity based on an online activity model. We implemented the proposed framework in Android platform, and tested it on Qualcomm MDP 8660 smartphone. To show the practical value of our recognition strategy, we design effective power and thermal management policies that adapt system settings to user activity changes. Our experimental results using 10 real mobile applications show that the proposed proactive management technique can reduce the CPU energy by up to 28% while meeting a given thermal constraint. © 2015 IEEE."
84,IEEE Symposium on Visual Analytics Science and Technology,2015,Perception-aware power management for mobile games via dynamic resolution scaling,"Modern mobile devices provide ultra-high resolutions in their display panels. This imposes ever increasing workload on the GPU leading to high power consumption and shortened battery life. In this paper, we first show that resolution scaling leads to significant power savings. Second, we propose a perception-aware adaptive scheme that sets the resolution during game play. We exploit the fact that game players are often willing to trade quality for longer battery life. Our scheme uses decision theory, where the predicted user perception is combined with a novel asymmetric loss function that encodes users' alterations in their willingness to save power. © 2015 IEEE."
85,IEEE Symposium on Visual Analytics Science and Technology,2015,A unified stochastic model for energy management in solar-powered embedded systems,"Energy harvesting from environments such as solar energy are promising solutions to tackle energy sustainability in embedded systems. However, uncertainties in energy availability, non-ideal characteristics of harvesting circuits, energy storage (battery or supercapacitor), and application demand dynamics add more complexity in the system. We present a unified model based on discrete-time Finite State Markov Chain to capture the dynamicity and variations in both the energy supply from solar irradiance and the energy demand from the application. In this paper, we exploit the temporal and spatial characteristics of solar energy and propose a deterministic profile with stochastic process to reflect the fluctuation due to unexpected weather condition. Optimal policy to maximize expected total QoS is derived from the presented model using a probabilistic dynamic programming approach. Compared to a state-of-the-art deterministic energy management framework, our proposed approach outperforms in term of QoS and energy sustainability (with less shutdown time) of the system. © 2015 IEEE."
86,IEEE Symposium on Visual Analytics Science and Technology,2015,Machine learning-based energy management in a hybrid electric vehicle to minimize total operating cost,"This paper investigates the energy management problem in hybrid electric vehicles (HEVs) focusing on the minimization of the operating cost of an HEV, including both fuel and battery replacement cost. More precisely, the paper presents a nested learning framework in which both the optimal actions (which include the gear ratio selection and the use of internal combustion engine versus the electric motor to drive the vehicle) and limits on the range of the state-of-charge of the battery are learned on the fly. The inner-loop learning process is the key to minimization of the fuel usage whereas the outer-loop learning process is critical to minimization of the amortized battery replacement cost. Experimental results demonstrate a maximum of 48% operating cost reduction by the proposed HEV energy management policy. © 2015 IEEE."
87,IEEE Symposium on Visual Analytics Science and Technology,2015,A Contract design approach for colocation data center demand response,"Demand response programs maintain transmission stability in power grid through reducing electricity use during peak period, making grid more efficient and robust. While numerous demand response programs are currently being deployed by utility companies, we focus on emergency demand response program, which is critical to ensure reliability during emergency situations. As a key participant in such program, we consider a critical type of data center: multi-tenant colocation data center (or colocation), where multiple tenants mange their own servers in shared space but typically lack incentives to reduce energy for demand response. To enable multi-tenant data center demand response, we propose a contract-based mechanism, called Contract-DR, which offers financial incentives to tenants to shed energy during emergency situations, reducing the usage of cost-ineffective and environmentally-unfriendly diesel generation. We conduct theoretical analysis to prove the optimality of Contract-DR and also validate it through a trace-based study. © 2015 IEEE."
88,IEEE Symposium on Visual Analytics Science and Technology,2015,"Design methodologies, models and tools for very-large-scale integration of NEM relay-based circuits","Integrated circuits based on nano-electro-mechanical (NEM) relays are a promising alternative to conventional CMOS technology in ultra-low energy applications due to their (near) zero stand-by energy consumption. Here we describe the details of an overarching design framework for NEM relays, including automated synthesis from design entry in RTL to layout, based on commercially available EDA tools and engines. Critical differences between relays and FETs manifest in fundamentally different timing characteristics, which significantly affect static timing analysis and the requisite timing models. The adaptation of existing EDA methods, models, tools and platforms for logic and physical synthesis to account for these differences are described, providing insight into large-scale design of NEM relay-based digital processors. A historically well-known processor, the Intel 4004, and a modern MIPS32 compatible processor are synthesized based on a NEM relay-based standard cell library to demonstrate the customized synthesis methodology. An energy study is carried out using the proposed design framework on benchmark circuits implemented in existing CMOS nodes and NEM node, to better understand the energy saving potential of NEM technology. © 2015 IEEE."
89,IEEE Symposium on Visual Analytics Science and Technology,2015,Full-chip inter-die parasitic extraction in face-to-face-bonded 3D ICs,"Face-to-face (F2F) bonded 3D ICs are promising design solutions. However, because of the short die-to-die distance, direct coupling between the metal layers of the top and bottom dies introduces severe signal integrity problems that call for accurate extraction. This study is the first to demonstrate and compare three parasitic extraction methods of F2F-bonded 3D ICs. One is traditional die-by-die extraction, which cannot handle inter-die coupling and E-field sharing. We propose another method, holistic extraction, which treats all layers from both dies simultaneously and captures all inter-die coupling at the cost of high Layout Versus Schematic (LVS) complexity. We also propose an in-context extraction method that accounts for interface layers between dies. Carefully handling double-counting and surface layers issues, in-context extraction is LVS-friendly without losing accuracy. Full-chip analyses show that both of our extraction methods are highly accurate and able to handle various metal layers in several process nodes. It also corrects timing, power, and signal integrity errors introduced by die-by-die extraction. In-context extraction with two interface layers is highly accurate and efficient with an error of 0.9% for total ground capacitance and 0.8% for total coupling capacitance. © 2015 IEEE."
90,IEEE Symposium on Visual Analytics Science and Technology,2015,Power-down circuit synthesis for analog/mixed-signal,"Due to the need for energy efficiency, power management features of modern systems on chips are becoming more and more complex. The complexity also affects analog/mixed-signal circuit blocks. They are equipped with power-down modes to shut off bias currents while the block is not used. In industrial practice, the power-down circuitry is added manually towards the end of the design phase. Due to the increasing complexity of the power-down functionality, fault-free implementation and verification are becoming more and more challenging and time consuming. In this work, we are going one step beyond verification to an automatic, i.e., fault free synthesis of power-down circuitry. We formulate the power-down synthesis problem and solve it by combining a new rip-up algorithm with a constraint programming formulation. To the best of our knowledge, the first synthesis algorithm for power-down circuit synthesis for analog/mixed-signal blocks is presented. The ability to successfully synthesize the power-down circuitry is demonstrated for three amplifier circuits and a voltage-controlled oscillator. © 2015 IEEE."
91,IEEE Symposium on Visual Analytics Science and Technology,2015,None,None
92,IEEE Symposium on Visual Analytics Science and Technology,2015,Dynamic machine learning based matching of nonvolatile processor microarchitecture to harvested energy profile,"Energy harvesting systems without an energy storage device have to efficiently harness the fluctuating and weak power sources to ensure the maximum computational progress. While a simpler processor enables a higher turn-on potential with a weak source, a more powerful processor can utilize more energy that is harvested. Earlier work shows that different complexity levels of nonvolatile microarchitectures provide best fit for different power sources, and even different trails within same power source. In this work, we propose a dynamic nonvolatile microarchitecture by integrating all non-pipelined (NP), N-stage-pipeline (NSP), and Out of Order (OoO) cores together. Neural network machine learning algorithms are also integrated to dynamically adjust the microarchitecture to achieve the maximum forward progress. This integrated solution can achieve forward progress equal to 2.4× of the baseline NP architecture (1.82× of an OoO core). © 2015 IEEE."
93,IEEE Symposium on Visual Analytics Science and Technology,2015,Architectural requirements for energy efficient execution of graph analytics applications,"Intelligent data analysis has become more important in the last decade especially because of the significant increase in the size and availability of data. In this paper, we focus on the common execution models and characteristics of iterative graph analytics applications. We show that the features that improve work efficiency can lead to significant overheads on existing systems. We identify the opportunities for custom hardware implementation, and outline the desired architectural features for energy efficient computation of graph analytics applications. © 2015 IEEE."
94,IEEE Symposium on Visual Analytics Science and Technology,2015,None,None
95,IEEE Symposium on Visual Analytics Science and Technology,2015,CAUSE: Critical application usage-aware memory system using non-volatile memory for mobile devices,"Mobile devices are severely limited in memory, which affects critical user-experience metrics such as application service time. Emerging non-volatile memory (NVM) technologies such as STT-RAM and PCM are ideal candidates to provide higher memory capacity with negligible energy overhead. However, existing memory management systems overlook mobile users application usage which provides crucial cues for improving user experience. In this paper, we propose CAUSE, a novel memory system based on DRAM-NVM hybrid memory architecture. CAUSE takes explicit account of the application usage patterns to distinguish data criticality and identify suitable swap candidates. We also devise NVM hardware design optimized for the access characteristics of the swapped pages. We evaluate CAUSE on a real Android smartphone and NVSim simulator using user application usage logs. Our experimental results show that the proposed technique achieves 32% faster launch time for mobile applications while reducing energy cost by 90% and 44% on average over non-optimized STT-RAM and PCM, respectively. © 2015 IEEE."
96,IEEE Symposium on Visual Analytics Science and Technology,2015,A universal ordered NoC design platform for shared-memory MPSoC,"Shared memory is the predominant programming model in today's MPSoCs. However, existing SoC on-chip communication standards like AMBA relies on the interconnect for ordering. This is a problem as the number of actors increases, as traditional simple interconnects like buses and crossbars do not scale, yet scalable distributed NoCs are inherently unordered. Without built-in ordering capability from NoC, cache coherence protocols have to rely on external ordering points which can forward the requests so that every cache observes the requests in the same order. Such ordering points incur significant scalability issues though, such as indirection latency or communication hotspots in the network. In this paper, we propose a universal ordered NoC platform for shared-memory MPSoC designs to provide coherence request ordering in addition to communication. The proposed solution is based on a separate light-weight ordering network to establish the global request order which the receiving NIC leverages for delivering requests. The proposed solution provides a comprehensive support for general network topologies and various levels of memory consistency, while adhering to existing cache coherence protocol standards. The full-system simulation with heterogeneous MPSoC Rodinia benchmarks shows that it reduces the request latency by 37.6% and 35.7% over ordering points in 2D-mesh and butterfly fat tree topologies, respectively. This translates to overall runtime improvements of 17.8% and 12.0% in each topology, for a 36-node and 32-node MPSoC respectively. © 2015 IEEE."
97,IEEE Symposium on Visual Analytics Science and Technology,2015,Optimizing 3D NoC design for energy efficiency: A machine learning approach,"Three-dimensional (3D) Network-on-Chip (NoC) is an emerging technology that has the potential to achieve high performance with low power consumption for multicore chips. However, to fully realize their potential, we need to consider novel 3D NoC architectures. In this paper, inspired by the inherent advantages of small-world (SW) 2D NoCs, we explore the design space of SW network-based 3D NoC architectures. We leverage machine learning to intelligently explore the design space to optimize the placement of both planar and vertical communication links for energy efficiency. We demonstrate that the optimized 3D SW NoC designs perform significantly better than their 3D MESH counterparts. On an average, the 3D SW NoC shows 35% energy-delay-product (EDP) improvement over 3D MESH for the nine PARSEC and SPLASH2 benchmarks considered in this work. The highest performance improvement of 43% was achieved for RADIX. Interestingly, even after reducing the number of vertical links by 50%, the optimized 3D SW NoC performs 25% better than the fully connected 3D MESH, which is a strong indication of the effectiveness of our optimization methodology. © 2015 IEEE."
98,IEEE Symposium on Visual Analytics Science and Technology,2015,Transient noise bounds using vectorless power grid verification(Open Access),"Efficient power grid verification, critical in modern integrated circuits, is computationally demanding because of increasing grid sizes. Vectorless approach to grid verification estimates worst-case voltage noises without detailed evaluation of load current excitations. We study voltage noise assessment in RLC models of VDD and GND networks in integrated power grids. Transitory circuit behaviours are captured by transient constraints, while abstract grid model is utilized to accelerate convergence. Heuristics are proposed to extract constraints that restrict power consumption profiles to realistic scenarios. Bounds on voltage overshoots and undershoots are evaluated by formulating multiple optimization problems. We propose ways to mitigate storage and computational requirements on processing resources, enabling users to deploy computations on economical Cloud Computing platforms. Recommended solution is parallelizable, thereby reducing the overall verification time. Experimental results suggest that the proposed technique is practical and scalable for industrial grids. © 2015 IEEE."
99,IEEE Symposium on Visual Analytics Science and Technology,2015,1-bit compressed sensing based framework for built-in resonance frequency prediction using on-chip noise sensors,"Significant noise will occur when the load currents of a chip contain frequency components that are close to its resonance frequency, which is mainly decided by power delivery network (PDN) capacitance and package inductance. Yet with technology scaling, the wire parasitic capacitance, which suffers from large process variations, starts to become a dominant contributor in the PDN capacitance, leading to a large resonance frequency variation across dies. It is thus important to know the resonance frequency of individual chips to effectively avoid resonance noise at runtime. Existing methods are mostly based on frequency sweeping, which are too expensive to apply to individual chips. In this paper, we propose a novel framework to predict the resonance frequency using existing on-chip noise sensors, based on the theory of 1-bit compressed sensing. Experimental results on industrial designs show that compared with frequency sweeping, our proposed framework can achieve up to 7.6× measurement time reduction under the same accuracy, with 15% resonance frequency variation. To the best of the authors knowledge, this is the very first work to point out the need of as well as a practical solution to the resonance frequency prediction for individual chips. © 2015 IEEE."
100,IEEE Symposium on Visual Analytics Science and Technology,2015,Graph-based dynamic analysis: Efficient characterization of dynamic timing and activity distributions,"In light of increasing energy overheads required to guarantee correctness as variations increase with continued technology scaling, better-than-worst-case (BTWC) design has become a hot topic. Several BTWC design techniques utilize dynamic information like path activity when optimizing a design and rely on path-based analysis to determine the dynamic slack distribution of a workload running on a processor and subsequently optimize a design. In this paper, we show that path-based techniques are not scalable, due to the enormous number of paths in modern designs, and can also result in incorrect results. We propose a graph-based technique for performing dynamic timing and activity analysis of a workload on a processor that addresses the limitations of path-based techniques. Our tool has significantly lower runtime and memory requirements than path-based tools. Consequently, we can perform analysis for larger designs over longer time windows in a shorter amount of time. We also propose two optimizations that improve the performance of our tool. © 2015 IEEE."
101,IEEE Symposium on Visual Analytics Science and Technology,2015,A general framework for efficient performance analysis of acyclic asynchronous pipelines,"Asynchronous design methodologies gain recent extensive attention due to the variability issues in fabricating nanometer integrated circuits. Prior work on asynchronous pipeline performance analysis mostly focused on full buffer pipelines. To date half buffer performance analysis still lacks a systematic and precise treatment. In this paper, we propose a general framework abstracting four-phase asynchronous protocols and thus uniquely enable efficient performance analysis on various acyclic quasi-delay insensitive (QDI) pipelines (including the well-known pre-charged full buffer (PCFB), pre-charged half buffer (PCHB), weak-conditioned half buffer (WCHB), and null convention logic (NCL)) whose analysis has been challenging, if not impossible. Two approaches, linear programming-based performance analysis (LPA) and static performance analysis (SPA), that were applicable only to restricted set of full-buffer and half-buffer pipelines, respectively, are extended to support the entire set of considered pipelines. Thereby the two approaches can be directly compared for the first time. Experiments show that on average SPA achieve five orders of magnitude speedup over LPA, while LPA may provide 7% to 22% tighter cycle time estimation than SPA. Our results are essential to scalable performance analysis for a comprehensive set of QDI circuits. © 2015 IEEE."
102,IEEE Symposium on Visual Analytics Science and Technology,2015,A novel entropy production based full-chip TSV fatigue analysis,"Through-silicon vias (TSVs) are subject to thermal fatigue due to stress over time, no matter how small the stress is. Existing works on TSV fatigue all rely on measurement-based parameters to estimate the lifetime, and cannot consider detailed thermal profiles. In this paper, we propose a new method for TSV fatigue prediction using entropy production during thermal cycles, which is validated by theoretical analysis and measurement results. By combining thermodynamics and mechanics laws, the fatigue process can be quantitatively evaluated with detailed thermal profiles. Experimental results show that interestingly, the landing pad possesses the most easy-to-fail region, which generates up to 50% more entropy compared with the TSV body. The impact of landing pad dimension and TSV geometries are also studied, providing guidance for reliability enhancement. Finally, full-chip fatigue analysis is performed based on stress superposition. To the best of the authors' knowledge, this is the first TSV fatigue model that is free of measurement data fitting, the first that is capable of considering detailed thermal profiles, and the first framework for efficient full-chip TSV fatigue analysis. © 2015 IEEE."
103,IEEE Symposium on Visual Analytics Science and Technology,2015,"Three-tier 3D ICs for more power reduction: Strategies in CAD, design, and bonding selection","Low-power is one of the key driving forces in modern VLSI systems. Several recent studies show that 3D ICs offer significant power savings over 2D ICs, primarily due to wirelength and buffer saving. However, these existing studies are mainly limited to 2-tier designs. In this paper, our target is extended to 3-tier 3D ICs. Our study first shows that the one additional tier available in 3-tier 3D ICs does offer more power saving compared with their 2-tier 3D IC counterparts, but more careful floorplanning, through-silicon via (TSV) management, and block folding considerations are required. Second, we find that the three tiers can be bonded in different ways: (1) face-to-back only and (2) face-to-face and face-to-back combined. Our study shows that these choices pose additional challenges in design optimizations for more power saving. Lastly, we develop effective CAD solutions that are seamlessly integrated into commercial 2D IC tools to handle 3-tier 3D IC power optimization under various bonding style options. With our low-power design methods combined, our 3-tier 3D ICs provide -14.8% more power reduction over 2-tier 3D ICs and -36.0% over 2D ICs under the same performance. © 2015 IEEE."
104,IEEE Symposium on Visual Analytics Science and Technology,2015,Optimization of FinFET-based circuits using a dual gate pitch technique,"Source/drain stressors in FinFET-based circuits lose their effectiveness at smaller contacted gate pitches. To improve circuit performance, a dual gate pitch technique is proposed in this work, where standard cells with double the gate pitch are selectively used on the gates of the circuit critical paths, at minimal area and power costs. A stress-aware library characterization is performed for FinFET-based standard cells by obtaining stress distributions using finite element simulations on a subset of structures. The stresses are then employed to create look-up tables for mobility multipliers and threshold voltage shifts, for subsequent performance characterization of FinFET-based standard cells. Finally, a circuit delay optimizer is applied using the dual gate pitch approach and is compared with an alternative gate sizing approach. Using a combination of gate sizing and the dual gate pitch approach, it is shown that the average power delay product improves by 12.9% and 15.9% in 14nm and 10nm technologies, respectively. © 2015 IEEE."
105,IEEE Symposium on Visual Analytics Science and Technology,2015,Redundancy based interconnect duplication to mitigate soft errors in SRAM-based FPGAS,"Soft error induced reliability problem has already become a major concern for modern SRAM-based FPGAS (Field Programmable Gate Arrays) even at the ground level. In this paper, we propose a duplication-with-recovery (DWR) technique to recover the configuration bit faults on interconnects, which contribute to the majority of soft errors in FPGAS. Based on a study on the detailed routing structure in real FPGAS, DWR leverages redundant resources for interconnect duplication and enables fault recovery with lightweight circuit-level support. Compared with traditional fault tolerant techniques, DWR retains the fault recovering capability but eliminates expensive copies. The experimental results show that a large portion of the interconnects can be protected, which in consequence significantly reduces the vulnerable configuration bits. In addition, DWR does not alter the placement and routing from standard design flow, and therefore does not affect the design closure but greatly improves the design reliability in a cost-effective way. © 2015 IEEE."
106,IEEE Symposium on Visual Analytics Science and Technology,2015,Hardware accelerator design for data centers,"As the size of available data is increasing, it is becoming inefficient to scale the computational power of traditional systems. To overcome this problem, customized application-specific accelerators are becoming integral parts of modern system on chip (SOC) architectures. In this paper, we summarize existing hardware accelerators for data centers and discuss the techniques to implement and embed them along with the existing SOCs. © 2015 IEEE."
107,IEEE Symposium on Visual Analytics Science and Technology,2015,Modern big data analytics for Old-fashioned semiconductor industry applications,"Big data analytics is the latest spotlight with all the glare of fame ranging from media coverage to booming startup companies to eye-catching merges and acquisitions. On the contrary, the 336 billion industry of semiconductor was seen as an old-fashioned business, with fading interests from the best and brightest among young graduates and engineers. How will modern big data analytics help the semiconductor industry walk through this transition? This paper answers this question via a number of practical but challenging problems arising from semiconductor manufacturing process. We show that many existing machine learning algorithms are not well positioned to solve these problems, and novel techniques involving temporal, structural and hierarchical properties need to be developed to solve these problems. © 2015 IEEE."
108,IEEE Symposium on Visual Analytics Science and Technology,2015,Effective CAD research in the sea of papers,"In the past decade, there has been a rapid growth in the number of journal, conference and workshop publications from academic research. The growth seems to be accelerated as time goes by. Accordingly, it has become increasingly difficult for researchers to efficiently identify papers related to a given topic, leading to missing important references or even repetitive work. Moreover, even when these papers are found, it is very time-consuming to find their inherent relations. In this paper, using CAD research as a vehicle, we will demonstrate a novel deep learning based framework that can automatically search for papers related to a given abstract of research, and suggest how they are correlated. We also provide the analysis and comparison among several classic machine-learning approaches. Experimental results show that the proposed approach always outperforms the conventional keyword-based rankings, in both accuracy and F1 scores. © 2015 IEEE."
109,IEEE Symposium on Visual Analytics Science and Technology,2015,Dynamically resilient and agile fine-grained replication configuration,"Service resiliency is crucial to the operation of global-scale cloud applications with fine-grained replication (FGR). If poorly designed, a few disruptions may cause cascading failures or severely impair the level of service. Due to high complexity of FGR configuration problem, existing techniques usually rely on over-provisioning and static replica configuration to achieve reliability to a certain extent. Such approaches may suffer from slow disruption response and unnecessary sacrifice on service availability. This paper proposes a novel problem formulation of online FGR configuration for service resiliency, which includes a new definition of service availability and a new constraint of zero-data-move configuration. To efficiently solve the proposed problem, this paper presents a brand new optimal dimension reduction technique - Replica Vector Decomposition (RVD), which greatly reduces problem complexity while preserving solution optimality (by formal proof). A RVD-based framework is designed for the online FGR configuration problem. Our evaluation results show that RVD-based FGR configuration scheme achieves substantial speedup of online disruption response, significantly improves service resiliency, and maintains a high level of service in the face of multiple disruptions. © 2015 IEEE."
110,IEEE Symposium on Visual Analytics Science and Technology,2015,Property-directed synthesis of reactive systems from safety specifications,"Reactive system synthesis from safety specifications is a promising approach to the correct-by-construction methodology. The synthesis process is often divided into two separate steps: First, check specification realizability by computing the winning region of states under a game-theoretic interpretation; second, synthesize the implementation circuit based on the computed winning region if the specification is realizable. Moreover, recent results suggest that methods based on satisfiability (SAT) solving outperform those based on Binary Decision Diagrams (BDDs) especially on large benchmark instances. In this paper, we focus on the the winning region computation and propose a SAT-based algorithm. By adopting the concepts from the state-of-the-art model checking algorithm property directed reachability (PDR, a.k.a. IC3), we aim at devising an efficient computation method for automatic controller synthesis. Experimental results on the benchmarks from the synthesis competition (SyntComp 2014) show that our proposed algorithm outperforms the existing SAT-based and QBF-based methods by some margin. © 2015 IEEE."
111,IEEE Symposium on Visual Analytics Science and Technology,2015,Efficient transistor-level symbolic timing simulation using cached partial circuit states,"Previous work has demonstrated the feasibility of transistor-level symbolic timing simulation, using MTBDDs to share computations across input combinations with similar behaviors. This paper introduces an alternative approach using cached Partial Circuit States paired with simple BDD guards. The proposed approach improves efficiency by decoupling the numerical and Boolean computations required for symbolic circuit simulation, with no loss of verification capability. The logical computations become more efficient by using BDDs, which have more significant internal sharing since they are no longer differentiated by floating point terminal values, and which can now take advantage of the classical BDD negation pointer method. The numerical computations benefit as well, by enabling caching of circuit-level computations and reuse across similar topologies and multiple time-steps in the simulation. We have implemented this approach in a commercial symbolic simulator, and validated the performance benefits in the verification of 21 industrial designs. © 2015 IEEE."
112,IEEE Symposium on Visual Analytics Science and Technology,2015,On-chip generation of uniformly distributed constrained-random stimuli for post-silicon validation,"Post-silicon validation is becoming widely adopted because it runs significantly faster than pre-silicon verification and hence it helps uncover subtle design errors that escape to silicon prototypes. However, it is hindered by limited controllability and observability, which makes it challenging to reuse pre-silicon content. In order to enable the reuse of stimuli constraints from pre-silicon verification environments, we present a method that facilitates the on-chip generation of uniformly distributed constrained-random stimuli. More specifically, our method, which relies on new pre-processing steps and on-chip hardware features, can generate in real-time pseudo cyclic-random stimuli with no repetition until the space of the compliant stimuli is exhausted. © 2015 IEEE."
113,IEEE Symposium on Visual Analytics Science and Technology,2015,Reducing post-silicon coverage monitoring overhead with emulation and Bayesian feature selection,"With increasing design complexity, post-silicon validation has become a critical problem. In pre-silicon validation, coverage is the primary metric of validation effectiveness, but in post-silicon, the lack of observability makes coverage measurement problematic. On-chip coverage monitors are a possible solution, but prior research has shown that the overhead is prohibitive for anything beyond a small number of coverage points. This paper presents a novel solution for post-silicon coverage monitoring: fully instrument the design in emulation to sample the relationships between coverage points, and then use this statistical data to choose a small set of coverage points whose coverage provides high probability that all the other coverage points are covered as well; only that small set is instrumented on silicon. To demonstrate the method, we propose a simple feature selection algorithm based on Bayesian networks to choose the small set of coverage points. In experiments emulating a non-trivial SoC, our technique reduces the number of coverage monitors by 92%, yet predicts over 98% probability that all coverage points are covered. © 2015 IEEE."
114,IEEE Symposium on Visual Analytics Science and Technology,2015,ApproxEigen: An approximate computing technique for large-scale eigen-decomposition,"Recognition, Mining, and Synthesis (RMS) applications are expected to make up much of the computing workloads of the future. Many of these applications (e.g., recommender systems and search engine) are formulated as finding eigenvalues/vectors of large-scale matrices. These applications are inherently error-tolerant, and it is often unnecessary, sometimes even impossible, to calculate all the eigenpairs. Motivated by the above, in this work, we propose a novel approximate computing technique for large-scale eigen-decomposition, namely ApproxEigen, wherein we focus on the practically-used Krylov subspace methods to find finite number of eigenpairs. With ApproxEigen, we provide a set of computation kernels with different levels of approximation for data pre-processing and solution finding, and conduct accuracy tuning under given quality constraints. Experimental results demonstrate that ApproxEigen is able to achieve significant energy-efficiency improvement while keeping high accuracy. © 2015 IEEE."
115,IEEE Symposium on Visual Analytics Science and Technology,2015,Modeling and mitigation of extra-SoC thermal coupling effects and heat transfer variations in mobile devices,"In smartphones and tablets, a number of components, such as display and communication subsystem, dissipate a significant amount of heat. This influences the SoC thermal envelope, because of the absence of a fan. Thus the thermal conditions of the SoC cannot simply be modeled as only a function of the SoC component power. In addition, contact surfaces and phone orientation variations (e.g., phone inside a pocket, phone held in a hand, and phone laying on a desk) change the heat transfer coefficients of the device over time and influence the SoC temperature. In this work, we analyze the thermal behavior of a commercial mobile device in varying user interaction profiles and under different environmental conditions. Next, we propose a system-variation aware thermal modeling strategy that only uses available power and thermal sensors. Lastly, we devise a novel ambient-aware proactive thermal management algorithm. Our approach is able to meet the given thermal constraints while providing stable performance and comparable power consumption with respect to existing techniques. In contrast, the state-of-the-art approaches, which do not consider ambient condition variations, violate the thermal constraints and lead up to 2.6× higher performance variations. © 2015 IEEE."
116,IEEE Symposium on Visual Analytics Science and Technology,2015,Just enough is more: Achieving sustainable performance in mobile devices under thermal limitations,"With the integration of high-performance multicore processors and multiple accelerators into modern mobile system-on-chips (SoCs), power densities have grown substantially. As a result, thermal management policies, which ensure operation at thermally safe conditions, became essential components of state-of-the-art mobile systems. Traditional thermal throttling approaches aim at maximum utilization of the available thermal headroom to minimize the performance loss and maximize user performance. This paper demonstrates that, in a mobile platform, such greedy techniques can lead to significant degradation in the quality-of-service (QoS) levels as the duration of device activity increases, leading to inconsistent user experience over time. We demonstrate that incorporating user/application QoS requirements into mobile power management to provide just enough performance (instead of always maximizing performance) allows for more efficient usage of the thermal headroom, which translates to substantially extended durations of sustainable performance. We propose a closed-loop QoS control policy, including an efficient dynamic voltage and frequency scaling (DVFS) state scheduling technique, to minimize the thermal impact for extending the sustainability of desired QoS levels. Experiments on a modern smartphone show that the proposed technique provides up to 74% longer sustainable performance while meeting the target QoS demands for a variety of real-life applications. © 2015 IEEE."
117,IEEE Symposium on Visual Analytics Science and Technology,2015,Learning-based power modeling of system-level black-box IPs,"Virtual platform prototypes are widely utilized to enable early system-level design space exploration. Accurate power models for hardware components at high levels of abstraction are needed to enable system-level power analysis and optimization. However, the limited observability of third party IPs renders traditional power modeling methods challenging and inaccurate. In this paper, we present a novel approach for extending behavioral models of black-box hardware IPs with an accurate power estimate. We leverage state-of-the-art-machine learning techniques to synthesize an abstract power model. Our model uses input and output history to track data-dependent pipeline behavior. Furthermore, we introduce a specialized ensemble learning that is composed out of individually selected cycle-by-cycle models to reduce overall complexity and further increase estimation accuracy. Results of applying our approach to various industrial-strength design examples shows that our models predict average power consumption to within 3% of a commercial gate-level power estimation tool, all while running several orders of magnitude faster. © 2015 IEEE."
118,IEEE Symposium on Visual Analytics Science and Technology,2015,Mixed cell-height implementation for improved design quality in advanced nodes,"In advanced nodes, standard-cell libraries can be developed with different cell heights (e.g., in FinFET technology, corresponding to different numbers of fins). Larger cell heights provide higher drive strengths, but at the cost of larger area and power consumption as well as pin capacitance. Cells with smaller heights are relatively smaller in area, but have weaker drive strengths and are more likely to suffer from routing congestion and pin accessibility issues. Existing design methodologies and tool flows are able to mix cells with different heights at the block level (i.e., each block contains cells of a particular cell height). To our knowledge, no design methodology in the literature mixes cells of different heights in a fine-grained manner. In this work, we propose a novel physical design optimization flow to implement design blocks with mixed cell heights in a fine-grained manner. Our optimization resolves the chicken-and-egg loop between floorplan site definition and the optimized choices of cell heights after placement. Comprehending the constraints and costs of mixing cells of different heights (e.g., the breaker cell area overheads of row alignment between sub-blocks of 8T and 12T cell rows), our optimization achieves 25% area reduction versus 12T-only implementation while maintaining the same performance, and 20% performance improvement versus 8T-only implementation while maintaining similar total cell area. © 2015 IEEE."
119,IEEE Symposium on Visual Analytics Science and Technology,2015,GasStation: Power and area efficient buffering for multiple power domain design,"Power management, which can be effectively realized by dynamically turning on/off power domains, is a key concern for modern mobile devices. Leakage power in multiple power domain design is usually dominated by nets passing through different power domains because prior work allocates always-on buffers for these feedthrough nets. Unlike prior work, which uses always-on buffers, we create specific power islands with normal buffers in this paper; these power islands gather buffers on feedthrough nets together to share the power and area overhead. The buffer allocation is performed by a wave-propagation based algorithm, named GasStation. Compared with the conventional always-on buffer approach, experimental results show that GasStation can reduce 75% buffer area, 34% buffer count, 80% leakage power, and 8% wirelength on feedthrough nets in eight industrial smart phone designs. © 2015 IEEE."
120,IEEE Symposium on Visual Analytics Science and Technology,2015,Scalable detailed placement legalization for complex sub-14nm constraints,"Technology scaling to 10nm and below introduces complex intra-row and inter-row constraints in standard-cell detailed placement. Examples of such constraints are found in rules for drain-drain abutment, minimum implant region area and width, oxide diffusion (OD) notching and jogging, etc. Typically, these rules are too complex for the normal global-detailed placement flow to fully consider. On the other hand, guardbanding the library cell design so that arbitrary cell placement adjacencies are all correct by construction has increasingly high area cost. This motivates the introduction of a final legalization phase for standard-cell placement tools in advanced (particularly 10nm and 7nm) foundry nodes. In this work, we develop a mixed integer-linear programming (MILP)-based placer, called DFPlacer, for final-phase design rule violation (DRV) fixing. DFPlacer finds (near-)DRV-free solutions considering various complex layout constraints including minimum implant width, drain-drain abutment, and oxide diffusion jogs. To overcome the runtime limitation of MILP-based approaches, we implement a distributable optimization strategy based on partitioning of the block layout into windows of cells that can be independently legalized. Using layouts in an abstracted 7nm library, we find that DFPlacer fixes 99% of DRVs on average with minimal impacts on area and timing. We also study an area-DRV tradeoff between two types of standard-cell library strategies, namely, with and without dummy poly gates. © 2015 IEEE."
121,IEEE Symposium on Visual Analytics Science and Technology,2015,A general and exact routing methodology for Digital Microfluidic Biochips,"Advances in microfluidic technologies have led to the emergence of Digital Microfluidic Biochips (DMFBs), which are capable of automating laboratory procedures in biochemistry and molecular biology. During the design and use of these devices, droplet routing represents a particularly critical challenge. Here, various design tasks have to be addressed for which, depending on the corresponding scenario, different solutions are available. However, all these developments eventually result in an inflation of different design approaches for routing of DMFBs - many of them addressing a very dedicated routing task only. In this work, we propose a comprehensive routing methodology which (1) provides one (generic) solution capable of addressing a variety of different design tasks, (2) employs a push-button-scheme that requires no (manual) composition of partial results, and (3) guarantees minimality e.g., with respect to the number of timesteps or the number of required control pins. Experimental evaluations demonstrate the benefits of the solution, i.e., the applicability for a wide range of design tasks as well as improvements compared to specialized solutions presented in the past. © 2015 IEEE."
122,IEEE Symposium on Visual Analytics Science and Technology,2015,None,None
123,IEEE Symposium on Visual Analytics Science and Technology,2015,None,None
124,IEEE Symposium on Visual Analytics Science and Technology,2015,OpenTimer: A high-performance timing analysis tool,"We introduce in this paper, OpenTimer, an open-source timing analysis tool that efficiently supports (1) both block-based and path-based timing propagations, (2) common path pessimism removal (CPPR), and (3) incremental processing. OpenTimer works on industry formats (e.g.,.v,.spef,.lib,.sdc) and is designed to be parallel and portable. To further facilitate integration between timing and other electronic design automation (EDA) applications such as timing-driven placement and routing, OpenTimer provides user-friendly application programming interface (API) for inactive analysis. Experimental results on industry benchmarks released from TAU 2015 timing analysis contest have demonstrated remarkable results achieved by OpenTimer, especially in its order-of-magnitude speedup over existing timers. © 2015 IEEE."
125,IEEE Symposium on Visual Analytics Science and Technology,2015,IitRACE: A memory efficient engine for fast incremental timing analysis and clock pessimism removal,"We describe a timing analysis engine for efficient processing of incremental changes to a circuit. The engine uses a block-based approach for incremental slack propagation. Logic cones affected by incremental changes to the design are identified and used to restrict the scope of the computation. Incremental block-based clock-pessimism removal and reporting of worst paths in the circuit is implemented using a novel dynamic path reduction technique. The engine is very efficient in memory usage compared to other known academic timers while maintaining a very high accuracy of reported path slacks when compared to a standard industrial timing engine. Certain paths are intentionally omitted from reporting in order to save on runtime, while ensuring that all paths with highest criticality are covered. Our timer (iitRACE) placed overall third in TAU 2015 contest on incremental timing analysis. Experimental results on industrial benchmarks from TAU 2015 contest have justified that iitRACE has average memory requirement 2X and 30X lower than that of first and second place timers respectively. © 2015 IEEE."
126,IEEE Symposium on Visual Analytics Science and Technology,2015,Overview of the 2015 CAD contest at ICCAD,"The 2015 CAD Contest at ICCAD presents cutting-edge, real-world EDA problems and challenging benchmarks derived from modern industrial designs. It also provides a standard, publicly available evaluation framework for each of the problems. The ever-increasing complexity of integrated circuit design has brought forth new and challenging problems for the EDA community. These require novel, efficient, and high-quality algorithms and methodologies. It is our hope that the CAD Contest at ICCAD would encourage timely and much-needed research on these critical problems in the field of EDA. © 2015 IEEE."
127,IEEE Symposium on Visual Analytics Science and Technology,2015,ICCAD 2015 contest in 3D interlayer cooling optimized network,"Microchannel liquid cooling has been proposed since the late 2000s as a viable enabler for 3D integration of microprocessors to continue scaling of computing power in the face of increasingly reduced returns from CMOS technology scaling. Thermal and electrical demonstrations of microchannel liquid-cooled heat sinks on the back side of IC dies exist in the literature and the compatibility of its fabrication with the existing CMOS process has been shown. This compatibility also gives rise to the prospect of building of nearly an infinite variety of channel networks with no additional manufacturing cost. This ICCAD 2015 problem aims to identify methods to optimize such microchannel fluid networks, and to evaluate impact of different cooling networks on different computing architectures floorplans. © 2015 IEEE."
128,IEEE Symposium on Visual Analytics Science and Technology,2015,ICCAD-2015 CAD contest in large-scale equivalence checking and function correction and benchmark suite,"Equivalence checking (EC) and functional Engineering Change Order (ECO) on large-scale designs becomes a crucial industrial topic as the design scale expands. In this topic, we are especially interested in how to partition the large-scale problems into smaller EC and ECO problem with lower complexity. In this contest, we ask the participants to design the algorithm to insert the corresponding cuts as the partitioned points on given two designs as simplifying the EC and ECO problems. The team correctly simplifying the problem most wins the contest. The benchmark suites are extracted from the real designs in our interesting applications. We look forward to triggering the academic area to investigate on this problem. © 2015 IEEE."
129,IEEE Symposium on Visual Analytics Science and Technology,2015,ICCAD-2015 CAD contest in incremental timing-driven placement and benchmark suite,"At modern technology nodes, improving routability and reducing total wirelength are no longer sufficient to close timing. Incremental timing-driven placement (TDP) seeks to resolve timing violations while limiting the impact to the original placement in an effort to achieve timing closure. To improve the timing landscape in localized regions, some latches or nets may require specialized attention that may not be available in other traditional placement flows (e.g., wirelength-driven). To address this problem, the ICCAD-2015 contest encourages advanced research in incremental timing-driven placement, by providing (i) a flexible timing-oriented placement framework, including a publicly-available and high-quality academic timer, (ii) a set of realistic benchmarks that facilitates academic and commercial collaboration, (iii) an evaluation metric that objectively defines the quality of newly-developed algorithms. © 2015 IEEE."
130,IEEE Symposium on Visual Analytics Science and Technology,2015,Rebooting Computing and Low-Power Image Recognition Challenge,"Rebooting Computing (RC) is an effort in the IEEE to rethink future computers. RC started in 2012 by the co-chairs, Elie Track (IEEE Council on Superconductivity) and Tom Conte (Computer Society). RC takes a holistic approach, considering revolutionary as well as evolutionary solutions needed to advance computer technologies. Three summits have been held in 2013 and 2014, discussing different technologies, from emerging devices to user interface, from security to energy efficiency, from neuromorphic to reversible computing. The first part of this paper introduces RC to the design automation community and solicits revolutionary ideas from the community for the directions of future computer research. Energy efficiency is identified as one of the most important challenges in future computer technologies. The importance of energy efficiency spans from miniature embedded sensors to wearable computers, from individual desktops to data centers. To gauge the state of the art, the RC Committee organized the first Low Power Image Recognition Challenge (LPIRC). Each image contains one or multiple objects, among 200 categories. A contestant has to provide a working system that can recognize the objects and report the bounding boxes of the objects. The second part of this paper explains LPIRC and the solutions from the top two winners. © 2015 IEEE."
