,conference,year,title,abstract
0,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
1,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Unsupervised induction of semantic roles within a reconstruction-error minimization framework,"We introduce a new approach to unsupervised estimation of feature-rich semantic role labeling models. Our model consists of two components: (1) an encoding component: a semantic role labeling model which predicts roles given a rich set of syntactic and lexical features; (2) a reconstruction component: a tensor factorization model which relies on roles to predict argument fillers. When the components are estimated jointly to minimize errors in argument reconstruction, the induced roles largely correspond to roles defined in annotated resources. Our method performs on par with most accurate role induction methods on English and German, even though, unlike these previous approaches, we do not incorporate any prior linguistic knowledge about the languages. © 2015 Association for Computational Linguistics."
2,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Predicate argument alignment using a global coherence model,"We present a joint model for predicate argument alignment. We leverage multiple sources of semantic information, including temporal ordering constraints between events. These are combined in a max-margin framework to find a globally consistent view of entities and events across multiple documents, which leads to improvements over a very strong local baseline. © 2015 Association for Computational Linguistics."
3,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Improving unsupervised vector-space thematic fit evaluation via role-filler prototype clustering,"Most recent unsupervised methods in vector space semantics for assessing thematic fit (e.g. Erk, 2007; Baroni and Lenci, 2010; Sayeed and Demberg, 2014) create prototypical rolefillers without performing word sense disambiguation. This leads to a kind of sparsity problem: candidate role-fillers for different senses of the verb end up being measured by the same ""yardstick"", the single prototypical role-filler. In this work, we use three different feature spaces to construct robust unsupervised models of distributional semantics. We show that correlation with human judgements on thematic fit estimates can be improved consistently by clustering typical role-fillers and then calculating similarities of candidate rolefillers with these cluster centroids. The suggested methods can be used in any vector space model that constructs a prototype vector from a non-trivial set of typical vectors. © 2015 Association for Computational Linguistics."
4,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,A compositional and interpretable semantic space,"Vector Space Models (VSMs) of Semantics are useful tools for exploring the semantics of single words, and the composition of words to make phrasal meaning. While many methods can estimate the meaning (i.e. vector) of a phrase, few do so in an interpretable way. We introduce a new method (CNNSE) that allows word and phrase vectors to adapt to the notion of composition. Our method learns a VSM that is both tailored to support a chosen semantic composition operation, and whose resulting features have an intuitive interpretation. Interpretability allows for the exploration of phrasal semantics, which we leverage to analyze performance on a behavioral task. © 2015 Association for Computational Linguistics."
5,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,"Randomized greedy inference for joint segmentation, POS tagging and dependency parsing","In this paper, we introduce a new approach for joint segmentation, POS tagging and dependency parsing. While joint modeling of these tasks addresses the issue of error propagation inherent in traditional pipeline architectures, it also complicates the inference task. Past research has addressed this challenge by placing constraints on the scoring function. In contrast, we propose an approach that can handle arbitrarily complex scoring functions. Specifically, we employ a randomized greedy algorithm that jointly predicts segmentations, POS tags and dependency trees. Moreover, this architecture readily handles different segmentation tasks, such as morphological segmentation for Arabic and word segmentation for Chinese. The joint model outperforms the state-of-the-art systems on three datasets, obtaining 2.1% TedEval absolute gain against the best published results in the 2013 SPMRL shared task. © 2015 Association for Computational Linguistics."
6,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,An incremental algorithm for transition-based CCG parsing,"Incremental parsers have potential advantages for applications like language modeling for machine translation and speech recognition. We describe a new algorithm for incremental transition-based Combinatory Categorial Grammar parsing. As English CCGbank derivations are mostly right branching and non-incremental, we design our algorithm based on the dependencies resolved rather than the derivation. We introduce two new actions in the shift-reduce paradigm based on the idea of 'revealing' (Pareschi and Steedman, 1987) the required information during parsing. On the standard CCGbank test data, our algorithm achieved improvements of 0.88% in labeled and 2.0% in unlabeled F-score over a greedy non-incremental shift-reduce parser. © 2015 Association for Computational Linguistics."
7,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Because syntax does matter: Improving predicate-argument structures parsing with syntactic features,"Parsing full-fledged predicate-argument structures in a deep syntax framework requires graphs to be predicted. Using the DeepBank (Flickinger et al., 2012) and the Predicate-Argument Structure treebank (Miyao and Tsujii, 2005) as a test field, we show how transition-based parsers, extended to handle connected graphs, benefit from the use of topologically different syntactic features such as dependencies, tree fragments, spines or syntactic paths, bringing a much needed context to the parsing models, improving notably over long distance dependencies and elided coordinate structures. By confirming this positive impact on an accurate 2nd-order graphbased parser (Martins and Almeida, 2014), we establish a new state-of-the-art on these data sets. © 2015 Association for Computational Linguistics."
8,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,A hybrid generative/discriminative approach to citation prediction,"Text documents of varying nature (e.g., summary documents written by analysts or published, scientific papers) often cite others as a means of providing evidence to support a claim, attributing credit, or referring the reader to related work. We address the problem of predicting a document's cited sources by introducing a novel, discriminative approach which combines a content-based generative model (LDA) with author-based features. Further, our classifier is able to learn the importance and quality of each topic within our corpus-which can be useful beyond this task-and preliminary results suggest its metric is competitive with other standard metrics (Topic Coherence). Our flagship system, Logit-Expanded, provides state-of-the-art performance on the largest corpus ever used for this task. © 2015 Association for Computational Linguistics."
9,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Weakly supervised slot tagging with partially labeled sequences from web search click logs,"In this paper, we apply a weakly-supervised learning approach for slot tagging using conditional random fields by exploiting web search click logs. We extend the constrained lattice training of Täckström et al. (2013) to non-linear conditional random fields in which latent variables mediate between observations and labels. When combined with a novel initialization scheme that leverages unlabeled data, we show that our method gives significant improvement over strong supervised and weakly-supervised baselines. © 2015 Association for Computational Linguistics."
10,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Not all character N-grams are created equal: A study in authorship attribution,"Character n-grams have been identified as the most successful feature in both singledomain and cross-domain Authorship Attribution (AA), but the reasons for their discriminative value were not fully understood. We identify subgroups of character n-grams that correspond to linguistic aspects commonly claimed to be covered by these features: morphosyntax, thematic content and style. We evaluate the predictiveness of each of these groups in two AA settings: a single domain setting and a cross-domain setting where multiple topics are present. We demonstrate that character ngrams that capture information about affixes and punctuation account for almost all of the power of character n-grams as features. Our study contributes new insights into the use of n-grams for future AA work and other classification tasks. © 2015 Association for Computational Linguistics."
11,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Effective use of word order for text categorization with convolutional neural networks,"Convolutional neural network (CNN) is a neural network that can make use of the internal structure of data such as the 2D structure of image data. This paper studies CNN on text categorization to exploit the 1D structure (namely, word order) of text data for accurate prediction. Instead of using low-dimensional word vectors as input as is often done, we directly apply CNN to high-dimensional text data, which leads to directly learning embedding of small text regions for use in classification. In addition to a straightforward adaptation of CNN from image to text, a simple but new variation which employs bag-ofword conversion in the convolution layer is proposed. An extension to combine multiple convolution layers is also explored for higher accuracy. The experiments demonstrate the effectiveness of our approach in comparison with state-of-the-art methods. © 2015 Association for Computational Linguistics."
12,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
13,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Extractive summarisation based on keyword profile and language model,"We present a statistical framework to extract information-rich citation sentences that summarise the main contributions of a scientific paper. In a first stage, we automatically discover salient keywords from a paper's citation summary, keywords that characterise its main contributions. In a second stage, exploiting the results of the first stage, we identify citation sentences that best capture the paper's main contributions. Experimental results show that our approach using methods rooted in quantitative statistics and information theory outperforms the current state-of-the-art systems in scientific paper summarisation. © 2015 Association for Computational Linguistics."
14,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,HEADS: Headline generation as sequence prediction using an abstract: Feature-rich space,"Automatic headline generation is a sub-task of document summarization with many reported applications. In this study we present a sequence-prediction technique for learning how editors title their news stories. The introduced technique models the problem as a discrete optimization task in a feature-rich space. In this space the global optimum can be found in polynomial time by means of dynamic programming. We train and test our model on an extensive corpus of financial news, and compare it against a number of baselines by using standard metrics from the document summarization domain, as well as some new ones proposed in this work. We also assess the readability and informativeness of the generated titles through human evaluation. The obtained results are very appealing and substantiate the soundness of the approach. © 2015 Association for Computational Linguistics."
15,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
16,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Combining language and vision with a multimodal skip-gram model,"We extend the SKIP-GRAM model of Mikolov et al. (2013a) by taking visual information into account. Like SKIP-GRAM, our multimodal models (MMSKIP-GRAM) build vector-based word representations by learning to predict linguistic contexts in text corpora. However, for a restricted set of words, the models are also exposed to visual representations of the objects they denote (extracted from natural images), and must predict linguistic and visual features jointly. The MMSKIP-GRAM models achieve good performance on a variety of semantic benchmarks. Moreover, since they propagate visual information to all words, we use them to improve image labeling and retrieval in the zero-shot setup, where the test concepts are never seen during model training. Finally, the MMSKIP-GRAM models discover intriguing visual properties of abstract words, paving the way to realistic implementations of embodied theories of meaning. © 2015 Association for Computational Linguistics."
17,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Discriminative unsupervised alignment of natural language instructions with corresponding video segments,"We address the problem of automatically aligning natural language sentences with corresponding video segments without any direct supervision. Most existing algorithms for integrating language with videos rely on handaligned parallel data, where each natural language sentence is manually aligned with its corresponding image or video segment. Recently, fully unsupervised alignment of text with video has been shown to be feasible using hierarchical generative models. In contrast to the previous generative models, we propose three latent-variable discriminative models for the unsupervised alignment task. The proposed discriminative models are capable of incorporating domain knowledge, by adding diverse and overlapping features. The results show that discriminative models outperform the generative models in terms of alignment accuracy. © 2015 Association for Computational Linguistics."
18,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,TopicCheck: Interactive alignment for assessing topic model stability,"Content analysis, a widely-applied social science research method, is increasingly being supplemented by topic modeling. However, while the discourse on content analysis centers heavily on reproducibility, computer scientists often focus more on scalability and less on coding reliability, leading to growing skepticism on the usefulness of topic models for automated content analysis. In response, we introduce TopicCheck, an interactive tool for assessing topic model stability. Our contributions are threefold. First, from established guidelines on reproducible content analysis, we distill a set of design requirements on how to computationally assess the stability of an automated coding process. Second, we devise an interactive alignment algorithm for matching latent topics from multiple models, and enable sensitivity evaluation across a large number of models. Finally, we demonstrate that our tool enables social scientists to gain novel insights into three active research questions. © 2015 Association for Computational Linguistics."
19,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Inferring latent attributes of Twitter users with label regularization,"Inferring latent attributes of online users has many applications in public health, politics, and marketing. Most existing approaches rely on supervised learning algorithms, which require manual data annotation and therefore are costly to develop and adapt over time. In this paper, we propose a lightly supervised approach based on label regularization to infer the age, ethnicity, and political orientation of Twitter users. Our approach learns from a heterogeneous collection of soft constraints derived from Census demographics, trends in baby names, and Twitter accounts that are emblematic of class labels. To counteract the imprecision of such constraints, we compare several constraint selection algorithms that optimize classification accuracy on a tuning set. We find that using no user-annotated data, our approach is within 2% of a fully supervised baseline for three of four tasks. Using a small set of labeled data for tuning further improves accuracy on all tasks. © 2015 Association for Computational Linguistics."
20,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,A neural network approach to context-sensitive generation of conversational responses,"We present a novel response generation system that can be trained end to end on large quantities of unstructured Twitter conversations. A neural network architecture is used to address sparsity issues that arise when integrating contextual information into classic statistical models, allowing the system to take into account previous dialog utterances. Our dynamic-context generative models show consistent gains over both context-sensitive and non-context-sensitive Machine Translation and Information Retrieval baselines. © 2015 Association for Computational Linguistics."
21,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,How to make a frenemy: Multitape FSTs for portmanteau generation,"A portmanteau is a type of compound word that fuses the sounds and meanings of two component words; for example, ""frenemy"" (friend + enemy) or ""smog"" (smoke + fog). We develop a system, including a novel multitape FST, that takes an input of two words and outputs possible portmanteaux. Our system is trained on a list of known portmanteaux and their component words, and achieves 45% exact matches in cross-validated experiments. © 2015 Association for Computational Linguistics."
22,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Aligning sentences from standard Wikipedia to simple Wikipedia,"This work improves monolingual sentence alignment for text simplification, specifically for text in standard and simple Wikipedia. We introduce a method that improves over past efforts by using a greedy (vs. ordered) search over the document and a word-level semantic similarity score based on Wiktionary (vs. WordNet) that also accounts for structural similarity through syntactic dependencies. Experiments show improved performance on a hand-aligned set, with the largest gain coming from structural similarity. Resulting datasets of manually and automatically aligned sentence pairs are made available. © 2015 Association for Computational Linguistics."
23,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Inducing lexical style properties for paraphrase and genre differentiation,"We present an intuitive and effective method for inducing style scores on words and phrases. We exploit signal in a phrase's rate of occurrence across stylistically contrasting corpora, making our method simple to implement and efficient to scale. We show strong results both intrinsically, by correlation with human judgements, and extrinsically, in applications to genre analysis and paraphrasing. © 2015 Association for Computational Linguistics."
24,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Entity linking for spoken language,"Research on entity linking has considered a broad range of text, including newswire, blogs and web documents in multiple languages. However, the problem of entity linking for spoken language remains unexplored. Spoken language obtained from automatic speech recognition systems poses different types of challenges for entity linking; transcription errors can distort the context, and named entities tend to have high error rates. We propose features to mitigate these errors and evaluate the impact of ASR errors on entity linking using a new corpus of entity linked broadcast news transcripts. © 2015 Association for Computational Linguistics."
25,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Spinning straw into gold: Using free text to train monolingual alignment models for non-factoid question answering,"Monolingual alignment models have been shown to boost the performance of question answering systems by ""bridging the lexical chasm"" between questions and answers. The main limitation of these approaches is that they require semistructured training data in the form of question-answer pairs, which is difficult to obtain in specialized domains or lowresource languages. We propose two inexpensive methods for training alignment models solely using free text, by generating artificial question-answer pairs from discourse structures. Our approach is driven by two representations of discourse: a shallow sequential representation, and a deep one based on Rhetorical Structure Theory. We evaluate the proposed model on two corpora from different genres and domains: one from Yahoo! Answers and one from the biology domain, and two types of non-factoid questions: manner and reason. We show that these alignment models trained directly from discourse structures imposed on free text improve performance considerably over an information retrieval baseline and a neural network language model trained on the same data. © 2015 Association for Computational Linguistics."
26,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Personalized page rank for named entity disambiguation,The task of Named Entity Disambiguation is to map entity mentions in the document to their correct entries in some knowledge base. We present a novel graph-based disambiguation approach based on Personalized PageRank (PPR) that combines local and global evidence for disambiguation and effectively filters out noise introduced by incorrect candidates. Experiments show that our method outperforms state-of-the-art approaches by achieving 91.7% in micro-and 89.9% in macroaccuracy on a dataset of 27.8K named entity mentions. © 2015 Association for Computational Linguistics.
27,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,When and why are log-linear models self-normalizing?,"Several techniques have recently been proposed for training ""self-normalized"" discriminative models. These attempt to find parameter settings for which unnormalized model scores approximate the true label probability. However, the theoretical properties of such techniques (and of self-normalization generally) have not been investigated. This paper examines the conditions under which we can expect self-normalization to work. We characterize a general class of distributions that admit self-normalization, and prove generalization bounds for procedures that minimize empirical normalizer variance. Motivated by these results, we describe a novel variant of an established procedure for training self-normalized models. The new procedure avoids computing normalizers for most training examples, and decreases training time by as much as factor of ten while preserving model quality. © 2015 Association for Computational Linguistics."
28,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Deep multilingual correlation for improved word embeddings,"Word embeddings have been found useful for many NLP tasks, including part-of-speech tagging, named entity recognition, and parsing. Adding multilingual context when learning embeddings can improve their quality, for example via canonical correlation analysis (CCA) on embeddings fromtwo languages. In this paper, we extend this idea to learn deep non-linear transformations of word embeddings of the two languages, using the recently proposed deep canonical correlation analysis. The resulting embeddings, when evaluated on multiple word and bigram similarity tasks, consistently improve over monolingual embeddings and over embeddings transformed with linear CCA. © 2015 Association for Computational Linguistics."
29,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Disfluency detection with a semi-markov model and prosodic features,"We present a discriminative model for detecting disfluencies in spoken language transcripts. Structurally, our model is a semi-Markov conditional random field with features targeting characteristics unique to speech repairs. This gives a significant performance improvement over standard chain-structured CRFs that have been employed in past work. We then incorporate prosodic features over silences and relative word duration into our semi-CRF model, resulting in further performance gains; moreover, these features are not easily replaced by discrete prosodic indicators such as ToBI breaks. Our final system, the semi-CRF with prosodic information, achieves an F-score of 85.4, which is 1.3 F1 better than the best prior reported F-score on this dataset. © 2015 Association for Computational Linguistics."
30,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Empty category detection with joint context-label embeddings,"This paper presents a novel technique for empty category (EC) detection using distributed word representations. A joint model is learned from the labeled data to map both the distributed representations of the contexts of ECs and EC types to a low dimensional space. In the testing phase, the context of possible EC positions will be projected into the same space for empty category detection. Experiments on Chinese Treebank prove the effectiveness of the proposed method. We improve the precision by about 6 points on a subset of Chinese Treebank, which is a new state-ofthe-art performance on CTB. © 2015 Association for Computational Linguistics."
31,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Incrementally tracking reference in human/human dialogue using linguistic and extra-linguistic information,"A large part of human communication involves referring to entities in the world and often these entities are objects that are visually present for the interlocutors. A system that aims to resolve such references needs to tackle a complex task: objects and their visual features need to be determined, the referring expressions must be recognised, and extra-linguistic information such as eye gaze or pointing gestures need to be incorporated. Systems that can make use of such information sources exist, but have so far only been tested under very constrained settings, such as WOz interactions. In this paper, we apply to a more complex domain a reference resolution model that works incrementally (i.e., word by word), grounds words with visually present properties of objects (such as shape and size), and can incorporate extra-linguistic information. We find that the model works well compared to previous work on the same data, despite using fewer features. We conclude that the model shows potential for use in a realtime interactive dialogue system. © 2015 Association for Computational Linguistics."
32,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Digital leafleting: Extracting structured data from multimedia online flyers,"Marketing materials such as flyers and other infographics are a vast online resource. In a number of industries, such as the commercial real estate industry, they are in fact the only authoritative source of information. Companies attempting to organize commercial real estate inventories spend a significant amount of resources on manual data entry of this information. In this work, we propose a method for extracting structured data from free-form commercial real estate flyers in PDF and HTML formats. We modeled the problem as text categorization and Named Entity Recognition (NER) tasks and applied a supervised machine learning approach (Support Vector Machines). Our dataset consists of more than 2,200 commercial real estate flyers and associated manually entered structured data, which was used to automatically create training datasets. Traditionally, text categorization and NER approaches are based on textual information only. However, information in visually rich formats such as PDF and HTML is often conveyed by a combination of textual and visual features. Large fonts, visually salient colors, and positioning often indicate the most relevant pieces of information. We applied novel features based on visual characteristics in addition to traditional text features and show that performance improved significantly for both the text categorization and NER tasks. © 2015 Association for Computational Linguistics."
33,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Multi-target machine translation with multi-synchronous context-free grammars,"We propose a method for simultaneously translating from a single source language to multiple target languages T1, T2, etc. The motivation behind this method is that if we only have a weak language model for T1 and translations in T1 and T2 are associated, we can use the information from a strong language model over T2 to disambiguate the translations in T1, providing better translation results. As a specific framework to realize multi-target translation, we expand the formalism of synchronous context-free grammars to handle multiple targets, and describe methods for rule extraction, scoring, pruning, and search with these models. Experiments find that multi-target translation with a strong language model in a similar second target language can provide gains of up to 0.8-1.5 BLEU points. © 2015 Association for Computational Linguistics."
34,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Sign constraints on feature weights improve a joint model of word segmentation and phonology,"This paper describes a joint model of word segmentation and phonological alternations, which takes unsegmented utterances as input and infers word segmentations and underlying phonological representations. The model is a Maximum Entropy or log-linear model, which can express a probabilistic version of Optimality Theory (OT; Prince and Smolensky (2004)), a standard phonological framework. The features in our model are inspired by OT's Markedness and Faithfulness constraints. Following the OT principle that such features indicate ""violations"", we require their weights to be non-positive. We apply our model to a modified version of the Buckeye corpus (Pitt et al., 2007) in which the only phonological alternations are deletions of word-final /d/and /t/segments. The model sets a new state-ofthe-art for this corpus for word segmentation, identification of underlying forms, and identification of /d/and /t/deletions. We also show that the OT-inspired sign constraints on feature weights are crucial for accurate identification of deleted /d/s; without them our model posits approximately 10 times more deleted underlying /d/s than appear in the manually annotated data. © 2015 Association for Computational Linguistics."
35,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Semi-supervised word sense disambiguation using word embeddings in general and specific domains,"One of the weaknesses of current supervised word sense disambiguation (WSD) systems is that they only treat a word as a discrete entity. However, a continuous-space representation of words (word embeddings) can provide valuable information and thus improve generalization accuracy. Since word embeddings are typically obtained from unlabeled data using unsupervised methods, this method can be seen as a semi-supervised word sense disambiguation approach. This paper investigates two ways of incorporating word embeddings in a word sense disambiguation setting and evaluates these two methods on some SensEval/SemEval lexical sample and all-words tasks and also a domain-specific lexical sample task. The obtained results show that such representations consistently improve the accuracy of the selected supervised WSD system. Moreover, our experiments on a domainspecific dataset show that our supervised baseline system beats the best knowledge-based systems by a large margin. © 2015 Association for Computational Linguistics."
36,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Continuous space representations of linguistic typology and their application to phylogenetic inference,"For phylogenetic inference, linguistic typology is a promising alternative to lexical evidence because it allows us to compare an arbitrary pair of languages. A challenging problem with typology-based phylogenetic inference is that the changes of typological features over time are less intuitive than those of lexical features. In this paper, we work on reconstructing typologically natural ancestors To do this, we leverage dependencies among typological features. We first represent each language by continuous latent components that capture feature dependencies. We then combine them with a typology evaluator that distinguishes typologically natural languages from other possible combinations of features. We perform phylogenetic inference in the continuous space and use the evaluator to ensure the typological naturalness of inferred ancestors. We show that the proposed method reconstructs known language families more accurately than baseline methods. Lastly, assuming the monogenesis hypothesis, we attempt to reconstruct a common ancestor of the world's languages. © 2015 Association for Computational Linguistics."
37,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Interpreting compound noun phrases using web search queries,"A weakly-supervised method is applied to anonymized queries to extract lexical interpretations of compound noun phrases (e.g., ""fortune 500 companies""). The interpretations explain the subsuming role (""listed in"") that modifiers (fortune 500) play relative to heads (companies) within the noun phrases. Experimental results over evaluation sets of noun phrases from multiple sources demonstrate that interpretations extracted from queries have encouraging coverage and precision. The top interpretation extracted is deemed relevant for more than 70% of the noun phrases. © 2015 Association for Computational Linguistics."
38,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Lexicon-free conversational speech recognition with neural networks,"We present an approach to speech recognition that uses only a neural network to map acoustic input to characters, a character-level language model, and a beam search decoding procedure. This approach eliminates much of the complex infrastructure of modern speech recognition systems, making it possible to directly train a speech recognizer using errors generated by spoken language understanding tasks. The system naturally handles out of vocabulary words and spoken word fragments. We demonstrate our approach using the challenging Switchboard telephone conversation transcription task, achieving a word error rate competitive with existing baseline systems. To our knowledge, this is the first entirely neural-network-based system to achieve strong speech transcription results on a conversational speech task. We analyze qualitative differences between transcriptions produced by our lexicon-free approach and transcriptions produced by a standard speech recognition system. Finally, we evaluate the impact of large context neural network character language models as compared to standard n-gram models within our framework. © 2015 Association for Computational Linguistics."
39,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,I can has Cheezburger? A nonparanormal approach to combining textual and visual information for predicting and generating popular meme descriptions,"The advent of social media has brought Internet memes, a unique social phenomenon, to the front stage of the Web. Embodied in the form of images with text descriptions, little do we know about the ""language of memes"". In this paper, we statistically study the correlations among popular memes and their wordings, and generate meme descriptions from raw images. To do this, we take a multimodal approach-we propose a robust nonparanormal model to learn the stochastic dependencies among the image, the candidate descriptions, and the popular votes. In experiments, we show that combining text and vision helps identifying popular meme descriptions; that our nonparanormal model is able to learn dense and continuous vision features jointly with sparse and discrete text features in a principled manner, outperforming various competitive baselines; that our system can generate meme descriptions using a simple pipeline. © 2015 Association for Computational Linguistics."
40,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,A transition-based algorithm for AMR parsing,"We present a two-stage framework to parse a sentence into its Abstract Meaning Representation (AMR). We first use a dependency parser to generate a dependency tree for the sentence. In the second stage, we design a novel transition-based algorithm that transforms the dependency tree to an AMR graph. There are several advantages with this approach. First, the dependency parser can be trained on a training set much larger than the training set for the tree-to-graph algorithm, resulting in a more accurate AMR parser overall. Our parser yields an improvement of 5% absolute in F-measure over the best previous result. Second, the actions that we design are linguistically intuitive and capture the regularities in the mapping between the dependency structure and the AMR of a sentence. Third, our parser runs in nearly linear time in practice in spite of a worst-case complexity of O(n2). © 2015 Association for Computational Linguistics."
41,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,The geometry of statistical machine translation,"Most modern statistical machine translation systems are based on linear statistical models. One extremely effective method for estimating the model parameters is minimum error rate training (MERT), which is an efficient form of line optimisation adapted to the highly nonlinear objective functions used in machine translation. We describe a polynomial-time generalisation of line optimisation that computes the error surface over a plane embedded in parameter space. The description of this algorithm relies on convex geometry, which is the mathematics of polytopes and their faces. Using this geometric representation of MERT we investigate whether the optimisation of linear models is tractable in general. Previous work on finding optimal solutions in MERT (Galley and Quirk, 2011) established a worstcase complexity that was exponential in the number of sentences, in contrast we show that exponential dependence in the worst-case complexity is mainly in the number of features. Although our work is framed with respect to MERT, the convex geometric description is also applicable to other error-based training methods for linear models. We believe our analysis has important ramifications because it suggests that the current trend in building statistical machine translation systems by introducing a very large number of sparse features is inherently not robust. © 2015 Association for Computational Linguistics."
42,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Data-driven sentence generation with non-isomorphic trees,"structures from which the generation naturally starts often do not contain any functional nodes, while surface-syntactic structures or a chain of tokens in a linearized tree contain all of them. Therefore, data-driven linguistic generation needs to be able to cope with the projection between non-isomorphic structures that differ in their topology and number of nodes. So far, such a projection has been a challenge in data-driven generation and was largely avoided. We present a fully stochastic generator that is able to cope with projection between non-isomorphic structures. The generator, which starts from PropBank-like structures, consists of a cascade of SVM-classifier based submodules that map in a series of transitions the input structures onto sentences. The generator has been evaluated for English on the Penn-Treebank and for Spanish on the multi-layered Ancora-UPF corpus. © 2015 Association for Computational Linguistics."
43,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
44,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Extracting human temporal orientation from Facebook language,"People vary widely in their temporal orientation-how often they emphasize the past, present, and future-and this affects their finances, health, and happiness. Traditionally, temporal orientation has been assessed by self-report questionnaires. In this paper, we develop a novel behavior-based assessment using human language on Facebook. We first create a past, present, and future message classifier, engineering features and evaluating a variety of classification techniques. Our message classifier achieves an accuracy of 71.8%, compared with 52.8% from the most frequent class and 58.6% from a model based entirely on time expression features. We quantify a users' overall temporal orientation based on their distribution of messages and validate it against known human correlates: conscientiousness, age, and gender. We then explore social scientific questions, finding novel associations with the factors openness to experience, satisfaction with life, depression, IQ, and one's number of friends. Further, demonstrating how one can track orientation over time, we find differences in future orientation around birthdays. © 2015 Association for Computational Linguistics."
45,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,An in-depth analysis of the effect of text normalization in social media,"Recent years have seen increased interest in text normalization in social media, as the informal writing styles found in Twitter and other social media data often cause problems for NLP applications. Unfortunately, most current approaches narrowly regard the normalization task as a ""one size fits all"" task of replacing non-standard words with their standard counterparts. In this work we build a taxonomy of normalization edits and present a study of normalization to examine its effect on three different downstream applications (dependency parsing, named entity recognition, and text-to-speech synthesis). The results suggest that how the normalization task should be viewed is highly dependent on the targeted application. The results also show that normalization must be thought of as more than word replacement in order to produce results comparable to those seen on clean text. © 2015 Association for Computational Linguistics."
46,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Using summarization to discover argument facets in online idealogical dialog,"More and more of the information available on the web is dialogic, and a significant portion of it takes place in online forum conversations about current social and political topics. We aim to develop tools to summarize what these conversations are about. What are the CENTRAL PROPOSITIONS associated with different stances on an issue; what are the abstract objects under discussion that are central to a speaker's argument? How can we recognize that two CENTRAL PROPOSITIONS realize the same FACET of the argument? We hypothesize that the CENTRAL PROPOSITIONS are exactly those arguments that people find most salient, and use human summarization as a probe for discovering them. We describe our corpus of human summaries of opinionated dialogs, then show how we can identify similar repeated arguments, and group them into FACETS across many discussions of a topic. We define a new task, ARGUMENT FACET SIMILARITY (AFS), and show that we can predict AFS with a .54 correlation score, versus an ngram system baseline of .39 and a semantic textual similarity system baseline of .45. © 2015 Association for Computational Linguistics."
47,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Active learning with rationales for text classification,"We present a simple and yet effective approach that can incorporate rationales elicited from annotators into the training of any offthe-shelf classifier. We show that our simple approach is effective for multinomial naïve Bayes, logistic regression, and support vector machines. We additionally present an active learning method tailored specifically for the learning with rationales framework. © 2015 Association for Computational Linguistics."
48,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Inferring temporally-anchored spatial knowledge from semantic roles,"This paper presents a framework to infer spatial knowledge from verbal semantic role representations. First, we generate potential spatial knowledge deterministically. Second, we determine whether it can be inferred and a degree of certainty. Inferences capture that something is located or is not located somewhere, and temporally anchor this information. An annotation effort shows that inferences are ubiquitous and intuitive to humans. © 2015 Association for Computational Linguistics."
49,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,A dynamic programming algorithm for tree trimming-based text summarization,"Tree trimming is the problem of extracting an optimal subtree from an input tree, and sentence extraction and sentence compression methods can be formulated and solved as tree trimming problems. Previous approaches require integer linear programming (ILP) solvers to obtain exact solutions. The problem of this approach is that ILP solvers are black-boxes and have no theoretical guarantee as to their computation complexity. We propose a dynamic programming (DP) algorithm for tree trimming problems whose running time is O(NLlogN), where N is the number of tree nodes and L is the length limit. Our algorithm exploits the zero-suppressed binary decision diagram (ZDD), a data structure that represents a family of sets as a directed acyclic graph, to represent the set of subtrees in a compact form; the structure of ZDD permits the application of DP to obtain exact solutions, and our algorithm is applicable to different tree trimming problems. Moreover, experiments show that our algorithm is faster than state-of-the-art ILP solvers, and that it scales well to handle large summarization problems. © 2015 Association for Computational Linguistics."
50,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Modeling word meaning in context with substitute vectors,"Context representations are a key element in distributional models of word meaning. In contrast to typical representations based on neighboring words, a recently proposed approach suggests to represent a context of a target word by a substitute vector, comprising the potential fillers for the target word slot in that context. In this work we first propose a variant of substitute vectors, which we find particularly suitable for measuring context similarity. Then, we propose a novel model for representing word meaning in context based on this context representation. Our model outperforms state-of-the-art results on lexical substitution tasks in an unsupervised setting. © 2015 Association for Computational Linguistics."
51,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Corpus-based discovery of semantic intensity scales,"Gradable terms such as brief, lengthy and extended illustrate varying degrees of a scale and can therefore participate in comparative constructs. Knowing the set of words that can be compared on the same scale and the associated ordering between them (brief < lengthy < extended) is very useful for a variety of lexical semantic tasks. Current techniques to derive such an ordering rely on WordNet to determine which words belong on the same scale and are limited to adjectives. Here we describe an extension to recent work: we investigate a fully automated pipeline to extract gradable terms from a corpus, group them into clusters reflecting the same scale and establish an ordering among them. This methodology reduces the amount of required handcrafted knowledge, and can infer gradability of words independent of their part of speech. Our approach infers an ordering for adjectives with comparable performance to previous work, but also for adverbs with an accuracy of 71%. We find that the technique is useful for inferring such rankings among words across different domains, and present an example using biomedical text. © 2015 Association for Computational Linguistics."
52,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Dialogue focus tracking for zero pronoun resolution,"We take a novel approach to zero pronoun resolution in Chinese: our model explicitly tracks the flow of focus in a discourse. Our approach, which generalizes to deictic references, is not reliant on the presence of overt noun phrase antecedents to resolve to, and allows us to address the large percentage of ""non-anaphoric"" pronouns filtered out in other approaches. We furthermore train our model using readily available parallel Chinese/English corpora, allowing for training without hand-annotated data. Our results demonstrate improvements on two test sets, as well as the usefulness of linguistically motivated features. © 2015 Association for Computational Linguistics."
53,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
54,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Inferring missing entity type instances for knowledge base completion: New dataset and methods,"Most of previous work in knowledge base (KB) completion has focused on the problem of relation extraction. In this work, we focus on the task of inferring missing entity type instances in a KB, a fundamental task for KB competition yet receives little attention. Due to the novelty of this task, we construct a large-scale dataset and design an automatic evaluation methodology. Our knowledge base completion method uses information within the existing KB and external information from Wikipedia. We show that individual methods trained with a global objective that considers unobserved cells from both the entity and the type side gives consistently higher quality predictions compared to baseline methods. We also perform manual evaluation on a small subset of the data to verify the effectiveness of our knowledge base completion methods and the correctness of our proposed automatic evaluation method. © 2015 Association for Computational Linguistics."
55,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Robust morphological tagging with word representations,"We present a comparative investigation of word representations for part-of-speech (POS) and morphological tagging, focusing on scenarios with considerable differences between training and test data where a robust approach is necessary. Instead of adapting the model towards a specific domain we aim to build a robust model across domains. We developed a test suite for robust tagging consisting of six languages and different domains. We find that representations similar to Brown clusters perform best for POS tagging and that word representations based on linguistic morphological analyzers perform best for morphological tagging. © 2015 Association for Computational Linguistics."
56,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,"English orthography is not ""close to optimal""","In spite of the apparent irregularity of the English spelling system, Chomsky and Halle (1968) characterize it as ""near optimal"". We investigate this assertion using computational techniques and resources. We design an algorithm to generate word spellings that maximize both phonemic transparency and morphological consistency. Experimental results demonstrate that the constructed system is much closer to optimality than the traditional English orthography. © 2015 Association for Computational Linguistics."
57,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,LCCT: A semi-supervised model for sentiment classification,"Analyzing public opinions towards products, services and social events is an important but challenging task. An accurate sentiment analyzer should take both lexicon-level information and corpus-level information into account. It also needs to exploit the domainspecific knowledge and utilize the common knowledge shared across domains. In addition, we want the algorithm being able to deal with missing labels and learning from incomplete sentiment lexicons. This paper presents a LCCT (Lexicon-based and Corpus-based, Co-Training) model for semi-supervised sentiment classification. The proposed method combines the idea of lexicon-based learning and corpus-based learning in a unified cotraining framework. It is capable of incorporating both domain-specific and domainindependent knowledge. Extensive experiments show that it achieves very competitive classification accuracy, even with a small portion of labeled data. Comparing to state-ofthe-art sentiment classification methods, the LCCT approach exhibits significantly better performances on a variety of datasets in both English and Chinese. © 2015 Association for Computational Linguistics."
58,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Multiview LSA: Representation learning via generalized CCA,"Multiview LSA (MVLSA) is a generalization of Latent Semantic Analysis (LSA) that supports the fusion of arbitrary views of data and relies on Generalized Canonical Correlation Analysis (GCCA). We present an algorithm for fast approximate computation of GCCA, which when coupled with methods for handling missing values, is general enough to approximate some recent algorithms for inducing vector representations of words. Experiments across a comprehensive collection of test-sets show our approach to be competitive with the state of the art. © 2015 Association for Computational Linguistics."
59,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,NASARI: A novel approach to a semantically-aware representation of items,"The semantic representation of individual word senses and concepts is of fundamental importance to several applications in Natural Language Processing. To date, concept modeling techniques have in the main based their representation either on lexicographic resources, such as WordNet, or on encyclopedic resources, such as Wikipedia. We propose a vector representation technique that combines the complementary knowledge of both these types of resource. Thanks to its use of explicit semantics combined with a novel cluster-based dimensionality reduction and an effective weighting scheme, our representation attains state-of-the-art performance on multiple datasets in two standard benchmarks: word similarity and sense clustering. We are releasing our vector representations at http://lcl.uniroma1.it/nasari/. © 2015 Association for Computational Linguistics."
60,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Towards a standard evaluation method for grammatical error detection and correction,"We present a novel evaluation method for grammatical error correction that addresses problems with previous approaches and scores systems in terms of improvement on the original text. Our method evaluates corrections at the token level using a globally optimal alignment between the source, a system hypothesis, and a reference. Unlike the M2 Scorer, our method provides scores for both detection and correction and is sensitive to different types of edit operations. © 2015 Association for Computational Linguistics."
61,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Using zero-resource spoken term discovery for ranked retrieval,"Research on ranked retrieval of spoken content has assumed the existence of some automated (word or phonetic) transcription. Recently, however, methods have been demonstrated for matching spoken terms to spoken content without the need for language-tuned transcription. This paper describes the first application of such techniques to ranked retrieval, evaluated using a newly created test collection. Both the queries and the collection to be searched are based on Gujarati produced naturally by native speakers; relevance assessment was performed by other native speakers of Gujarati. Ranked retrieval is based on fast acoustic matching that identifies a deeply nested set of matching speech regions, coupled with ways of combining evidence from those matching regions. Results indicate that the resulting ranked lists may be useful for some practical similarity-based ranking tasks. © 2015 Association for Computational Linguistics."
62,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Constraint-based models of lexical borrowing,"Linguistic borrowing is the phenomenon of transferring linguistic constructions (lexical, phonological, morphological, and syntactic) from a ""donor"" language to a ""recipient"" language as a result of contacts between communities speaking different languages. Borrowed words are found in all languages, and-in contrast to cognate relationships-borrowing relationships may exist across unrelated languages (for example, about 40% of Swahili's vocabulary is borrowed from Arabic). In this paper, we develop a model of morpho-phonological transformations across languages with features based on universal constraints from Optimality Theory (OT). Compared to several standard-but linguistically naive-baselines, our OTinspired model obtains good performance with only a few dozen training examples, making this a cost-effective strategy for sharing lexical information across languages. © 2015 Association for Computational Linguistics."
63,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Model invertibility regularization: Sequence alignment with or without parallel data,"We present Model Invertibility Regularization (MIR), a method that jointly trains two directional sequence alignment models, one in each direction, and takes into account the invertibility of the alignment task. By coupling the two models through their parameters (as opposed to through their inferences, as in Liang et al.'s Alignment by Agreement (ABA), and Ganchev et al.'s Posterior Regularization (PostCAT)), our method seamlessly extends to all IBMstyle word alignment models as well as to alignment without parallel data. Our proposed algorithm is mathematically sound and inherits convergence guarantees from EM.We evaluate MIR on two tasks: (1) On word alignment, applying MIR on fertility based models we attain higher F-scores than ABA and PostCAT. (2) On Japanese-to-English backtransliteration without parallel data, applied to the decipherment model of Ravi and Knight, MIR learns sparser models that close the gap in whole-name error rate by 33% relative to a model trained on parallel data, and further, beats a previous approach by Mylonakis et al. © 2015 Association for Computational Linguistics."
64,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Jointly modeling inter-slot relations by random walk on knowledge graphs for unsupervised spoken language understanding,"A key challenge of designing coherent semantic ontology for spoken language understanding is to consider inter-slot relations. In practice, however, it is difficult for domain experts and professional annotators to define a coherent slot set, while considering various lexical, syntactic, and semantic dependencies. In this paper, we exploit the typed syntactic dependency theory for unsupervised induction and filling of semantics slots in spoken dialogue systems. More specifically, we build two knowledge graphs: a slot-based semantic graph, and a word-based lexical graph. To jointly consider word-to-word, word-toslot, and slot-to-slot relations, we use a random walk inference algorithm to combine the two knowledge graphs, guided by dependency grammars. The experiments show that considering inter-slot relations is crucial for generating a more coherent and compete slot set, resulting in a better spoken language understanding model, while enhancing the interpretability of semantic slots. © 2015 Association for Computational Linguistics."
65,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Expanding paraphrase lexicons by exploiting lexical variants,"This study tackles the problem of paraphrase acquisition: achieving high coverage as well as accuracy. Our method first induces paraphrase patterns from given seed paraphrases, exploiting the generality of paraphrases exhibited by pairs of lexical variants, e.g., ""amendment"" and ""amending,"" in a fully empirical way. It then searches monolingual corpora for new paraphrases that match the patterns. This can extract paraphrases comprising words that are completely different from those of the given seeds. In experiments, our method expanded seed sets by factors of 42 to 206, gaining 84% to 208% more coverage than a previous method that generalizes only identical word forms. Human evaluation through a paraphrase substitution test demonstrated that the newly acquired paraphrases retained reasonable quality, given substantially high-quality seeds. © 2015 Association for Computational Linguistics."
66,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Diamonds in the rough: Event extraction from imperfect microblog data,"We introduce a distantly supervised event extraction approach that extracts complex event templates from microblogs. We show that this near real-time data source is more challenging than news because it contains information that is both approximate (e.g., with values that are close but different from the gold truth) and ambiguous (due to the brevity of the texts), impacting both the evaluation and extraction methods. For the former, we propose a novel, ""soft"", F1 metric that incorporates similarity between extracted fillers and the gold truth, giving partial credit to different but similar values. With respect to extraction methodology, we propose two extensions to the distant supervision paradigm: to address approximate information, we allow positive training examples to be generated from information that is similar but not identical to gold values; to address ambiguity, we aggregate contexts across tweets discussing the same event. We evaluate our contributions on the complex domain of earthquakes, with events with up to 20 arguments. Our results indicate that, despite their simplicity, our contributions yield a statistically-significant improvement of 33% (relative) over a strong distantly-supervised system. The dataset containing the knowledge base, relevant tweets and manual annotations is publicly available. © 2015 Association for Computational Linguistics."
67,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
68,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,A linear-time transition system for crossing interval trees,"We define a restricted class of non-projective trees that 1) covers many natural language sentences; and 2) can be parsed exactly with a generalization of the popular arc-eager system for projective trees (Nivre, 2003). Crucially, this generalization only adds constant overhead in run-time and space keeping the parser's total run-time linear in the worst case. In empirical experiments, our proposed transition-based parser is more accurate on average than both the arc-eager system or the swap-based system, an unconstrained nonprojective transition system with a worst-case quadratic runtime (Nivre, 2009). © 2015 Association for Computational Linguistics."
69,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Unsupervised multi-domain adaptation with feature embeddings,"Representation learning is the dominant technique for unsupervised domain adaptation, but existing approaches have two major weaknesses. First, they often require the specification of ""pivot features"" that generalize across domains, which are selected by taskspecific heuristics. We show that a novel but simple feature embedding approach provides better performance, by exploiting the feature template structure common in NLP problems. Second, unsupervised domain adaptation is typically treated as a task of moving from a single source to a single target domain. In reality, test data may be diverse, relating to the training data in some ways but not others. We propose an alternative formulation, in which each instance has a vector of domain attributes, can be used to learn distill the domain-invariant properties of each feature. © 2015 Association for Computational Linguistics."
70,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Ontologically grounded multi-sense representation learning for semantic vector space models,"Words are polysemous. However, most approaches to representation learning for lexical semantics assign a single vector to every surface word type. Meanwhile, lexical ontologies such as WordNet provide a source of complementary knowledge to distributional information, including a word sense inventory. In this paper we propose two novel and general approaches for generating sense-specific word embeddings that are grounded in an ontology. The first applies graph smoothing as a postprocessing step to tease the vectors of different senses apart, and is applicable to any vector space model. The second adapts predictive maximum likelihood models that learn word embeddings with latent variables representing senses grounded in an specified ontology. Empirical results on lexical semantic tasks show that our approaches effectively captures information from both the ontology and distributional statistics. Moreover, in most cases our sense-specific models outperform other models we compare against. © 2015 Association for Computational Linguistics."
71,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Subsentential sentiment on a shoestring: A crosslingual analysis of compositional classification,"Sentiment analysis has undergone a shift from document-level analysis, where labels expresses the sentiment of a whole document or whole sentence, to subsentential approaches, which assess the contribution of individual phrases, in particular including the composition of sentiment terms and phrases such as negators and intensifiers. Starting from a small sentiment treebank modeled after the Stanford Sentiment Treebank of Socher et al. (2013), we investigate suitable methods to perform compositional sentiment classification for German in a data-scarce setting, harnessing cross-lingual methods as well as existing general-domain lexical resources. © 2015 Association for Computational Linguistics."
72,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
73,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Multitask learning for adaptive quality estimation of automatically transcribed utterances,"We investigate the problem of predicting the quality of automatic speech recognition (ASR) output under the following rigid constraints: i) reference transcriptions are not available, ii) confidence information about the system that produced the transcriptions is not accessible, and iii) training and test data come from multiple domains. To cope with these constraints (typical of the constantly increasing amount of automatic transcriptions that can be found on the Web), we propose a domain-adaptive approach based on multitask learning. Different algorithms and strategies are evaluated with English data coming from four domains, showing that the proposed approach can cope with the limitations of previously proposed single task learning methods. © 2015 Association for Computational Linguistics."
74,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Incorporating word correlation knowledge into topic modeling,"This paper studies how to incorporate the external word correlation knowledge to improve the coherence of topic modeling. Existing topic models assume words are generated independently and lack the mechanism to utilize the rich similarity relationships among words to learn coherent topics. To solve this problem, we build a Markov Random Field (MRF) regularized Latent Dirichlet Allocation (LDA) model, which defines a MRF on the latent topic layer of LDA to encourage words labeled as similar to share the same topic label. Under our model, the topic assignment of each word is not independent, but rather affected by the topic labels of its correlated words. Similar words have better chance to be put into the same topic due to the regularization of MRF, hence the coherence of topics can be boosted. In addition, our model can accommodate the subtlety that whether two words are similar depends on which topic they appear in, which allows word with multiple senses to be put into different topics properly. We derive a variational inference method to infer the posterior probabilities and learn model parameters and present techniques to deal with the hardto-compute partition function in MRF. Experiments on two datasets demonstrate the effectiveness of our model. © 2015 Association for Computational Linguistics."
75,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,The unreasonable effectiveness of word representations for Twitter named entity recognition,"Named entity recognition (NER) systems trained on newswire perform very badly when tested on Twitter. Signals that were reliable in copy-edited text disappear almost entirely in Twitter's informal chatter, requiring the construction of specialized models. Using wellunderstood techniques, we set out to improve Twitter NER performance when given a small set of annotated training tweets. To leverage unlabeled tweets, we build Brown clusters and word vectors, enabling generalizations across distributionally similar words. To leverage annotated newswire data, we employ an importance weighting scheme. Taken all together, we establish a new state-of-the-art on two common test sets. Though it is wellknown that word representations are useful for NER, supporting experiments have thus far focused on newswire data. We emphasize the effectiveness of representations on Twitter NER, and demonstrate that their inclusion can improve performance by up to 20 F1. © 2015 Association for Computational Linguistics."
76,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Is your anchor going up or down? Fast and accurate supervised topic models,"Topic models provide insights into document collections, and their supervised extensions also capture associated document-level metadata such as sentiment. However, inferring such models from data is often slow and cannot scale to big data. We build upon the ""anchor"" method for learning topic models to capture the relationship between metadata and latent topics by extending the vector-space representation of word-cooccurrence to include metadataspecific dimensions. These additional dimensions reveal new anchor words that reflect specific combinations of metadata and topic. We show that these new latent representations predict sentiment as accurately as supervised topic models, and we find these representations more quickly without sacrificing interpretability. © 2015 Association for Computational Linguistics."
77,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Grounded semantic parsing for complex knowledge extraction,"Recently, there has been increasing interest in learning semantic parsers with indirect supervision, but existing work focuses almost exclusively on question answering. Separately, there have been active pursuits in leveraging databases for distant supervision in information extraction, yet such methods are often limited to binary relations and none can handle nested events. In this paper, we generalize distant supervision to complex knowledge extraction, by proposing the first approach to learn a semantic parser for extracting nested event structures without annotated examples, using only a database of such complex events and unannotated text. The key idea is to model the annotations as latent variables, and incorporate a prior that favors semantic parses containing known events. Experiments on the GENIA event extraction dataset show that our approach can learn from and extract complex biological pathway events. Moreover, when supplied with just five example words per event type, it becomes competitive even among supervised systems, outperforming 19 out of 24 teams that participated in the original shared task. © 2015 Association for Computational Linguistics."
78,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Sentiment after translation: A case-study on Arabic social media posts,"When text is translated from one language into another, sentiment is preserved to varying degrees. In this paper, we use Arabic social media posts as stand-in for source language text, and determine loss in sentiment predictability when they are translated into English, manually and automatically. As benchmarks, we use manually and automatically determined sentiment labels of the Arabic texts. We show that sentiment analysis of English translations of Arabic texts produces competitive results, w.r.t. Arabic sentiment analysis. We discover that even though translation significantly reduces the human ability to recover sentiment, automatic sentiment systems are still able to capture sentiment information from the translations. © 2015 Association for Computational Linguistics."
79,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Using external resources and joint learning for bigram weighting in ILP-based multi-document summarization,"Some state-of-the-art summarization systems use integer linear programming (ILP) based methods that aim to maximize the important concepts covered in the summary. These concepts are often obtained by selecting bigrams from the documents. In this paper, we improve such bigram based ILP summarization methods from different aspects. First we use syntactic information to select more important bigrams. Second, to estimate the importance of the bigrams, in addition to the internal features based on the test documents (e.g., document frequency, bigram positions), we propose to extract features by leveraging multiple external resources (such as word embedding from additional corpus,Wikipedia, Dbpedia,Word-Net, SentiWordNet). The bigram weights are then trained discriminatively in a joint learning model that predicts the bigram weights and selects the summary sentences in the ILP framework at the same time. We demonstrate that our system consistently outperforms the prior ILP method on different TAC data sets, and performs competitively compared to other previously reported best results. We also conducted various analyses to show the contributions of different components. © 2015 Association for Computational Linguistics."
80,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Transforming dependencies into phrase structures,"We present a new algorithm for transforming dependency parse trees into phrase-structure parse trees. We cast the problem as structured prediction and learn a statistical model. Our algorithm is faster than traditional phrasestructure parsing and achieves 90.4% English parsing accuracy and 82.4% Chinese parsing accuracy, near to the state of the art on both benchmarks. © 2015 Association for Computational Linguistics."
81,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Improving the inference of implicit discourse relations via classifying explicit discourse connectives,"Discourse relation classification is an important component for automatic discourse parsing and natural language understanding. The performance bottleneck of a discourse parser comes from implicit discourse relations, whose discourse connectives are not overtly present. Explicit discourse connectives can potentially be exploited to collect more training data to collect more data and boost the performance. However, using them indiscriminately has been shown to hurt the performance because not all discourse connectives can be dropped arbitrarily. Based on this insight, we investigate the interaction between discourse connectives and the discourse relations and propose the criteria for selecting the discourse connectives that can be dropped independently of the context without changing the interpretation of the discourse. Extra training data collected only by the freely omissible connectives improve the performance of the system without additional features. © 2015 Association for Computational Linguistics."
82,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Solving hard coreference problems,"Coreference resolution is a key problem in natural language understanding that still escapes reliable solutions. One fundamental difficulty has been that of resolving instances involving pronouns since they often require deep language understanding and use of background knowledge. In this paper we propose an algorithmic solution that involves a new representation for the knowledge required to address hard coreference problems, along with a constrained optimization framework that uses this knowledge in coreference decision making. Our representation, Predicate Schemas, is instantiated with knowledge acquired in an unsupervised way, and is compiled automatically into constraints that impact the coreference decision. We present a general coreference resolution system that significantly improves state-of-the-art performance on hard,Winograd-style, pronoun resolution cases, while still performing at the stateof-the-art level on standard coreference resolution datasets. © 2015 Association for Computational Linguistics."
83,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Pragmatic neural language modelling in machine translation,"This paper presents an in-depth investigation on integrating neural language models in translation systems. Scaling neural language models is a difficult task, but crucial for real-world applications. This paper evaluates the impact on end-to-end MT quality of both new and existing scaling techniques. We show when explicitly normalising neural models is necessary and what optimisation tricks one should use in such scenarios. We also focus on scalable training algorithms and investigate noise contrastive estimation and diagonal contexts as sources for further speed improvements. We explore the tradeoffs between neural models and back-off ngram models and find that neural models make strong candidates for natural language applications in memory constrained environments, yet still lag behind traditional models in raw translation quality. We conclude with a set of recommendations one should follow to build a scalable neural language model for MT. © 2015 Association for Computational Linguistics."
84,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Key female characters in film have more to talk about besides men: Automating the bechdel test,"The Bechdel test is a sequence of three questions designed to assess the presence of women in movies. Many believe that because women are seldom represented in film as strong leaders and thinkers, viewers associate weaker stereotypes with women. In this paper, we present a computational approach to automate the task of finding whether a movie passes or fails the Bechdel test. This allows us to study the key differences in language use and in the importance of roles of women in movies that pass the test versus the movies that fail the test. Our experiments confirm that in movies that fail the test, women are in fact portrayed as less-central and less-important characters. © 2015 Association for Computational Linguistics."
85,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Semantic grounding in dialogue for complex problem solving,"Dialogue systems that support users in complex problem solving must interpret user utterances within the context of a dynamically changing, user-created problem solving artifact. This paper presents a novel approach to semantic grounding of noun phrases within tutorial dialogue for computer programming. Our approach performs joint segmentation and labeling of the noun phrases to link them to attributes of entities within the problem-solving environment. Evaluation results on a corpus of tutorial dialogue for Java programming demonstrate that a Conditional Random Field model performs well, achieving an accuracy of 89.3% for linking semantic segments to the correct entity attributes. This work is a step toward enabling dialogue systems to support users in increasingly complex problem-solving tasks. © 2015 Association for Computational Linguistics."
86,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Learning knowledge graphs for question answering through conversational dialog,"We describe how a question-answering system can learn about its domain from conversational dialogs. Our system learns to relate concepts in science questions to propositions in a fact corpus, stores new concepts and relations in a knowledge graph (KG), and uses the graph to solve questions. We are the first to acquire knowledge for question-answering from open, natural language dialogs without a fixed ontology or domain model that predetermines what users can say. Our relation-based strategies complete more successful dialogs than a query expansion baseline, our taskdriven relations are more effective for solving science questions than relations from general knowledge sources, and our method is practical enough to generalize to other domains. © 2015 Association for Computational Linguistics."
87,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Sentence segmentation of aphasic speech,"Automatic analysis of impaired speech for screening or diagnosis is a growing research field; however there are still many barriers to a fully automated approach. When automatic speech recognition is used to obtain the speech transcripts, sentence boundaries must be inserted before most measures of syntactic complexity can be computed. In this paper, we consider how language impairments can affect segmentation methods, and compare the results of computing syntactic complexity metrics on automatically and manually segmented transcripts. We find that the important boundary indicators and the resulting segmentation accuracy can vary depending on the type of impairment observed, but that results on patient data are generally similar to control data. We also find that a number of syntactic complexity metrics are robust to the types of segmentation errors that are typically made. © 2015 Association for Computational Linguistics."
88,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Semantic parsing of speech using grammars learned with weak supervision,"Semantic grammars can be applied both as a language model for a speech recognizer and for semantic parsing, e.g. in order to map the output of a speech recognizer into formal meaning representations. Semantic speech recognition grammars are, however, typically created manually or learned in a supervised fashion, requiring extensive manual effort in both cases. Aiming to reduce this effort, in this paper we investigate the induction of semantic speech recognition grammars under weak supervision. We present empirical results, indicating that the induced grammars support semantic parsing of speech with a rather low loss in performance when compared to parsing of input without recognition errors. Further, we show improved parsing performance compared to applying n-gram models as language models and demonstrate how our semantic speech recognition grammars can be enhanced by weights based on occurrence frequencies, yielding an improvement in parsing performance over applying unweighted grammars. © 2015 Association for Computational Linguistics."
89,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
90,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Optimizing multivariate performance measures for learning relation extraction models,"We describe a novel max-margin learning approach to optimize non-linear performance measures for distantly-supervised relation extraction models. Our approach can be generally used to learn latent variable models under multivariate non-linear performance measures, such as Fβ-score. Our approach interleaves Concave-Convex Procedure (CCCP) for populating latent variables with dual decomposition to factorize the original hard problem into smaller independent sub-problems. The experimental results demonstrate that our learning algorithm is more effective than the ones commonly used in the literature for distant supervision of information extraction models. On several data conditions, we show that our method outperforms the baseline and results in up to 8.5% improvement in the F1-score. © 2015 Association for Computational Linguistics."
91,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
92,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Representation learning using multi-task deep neural networks for semantic classification and information retrieval,"Methods of deep neural networks (DNNs) have recently demonstrated superior performance on a number of natural language processing tasks. However, in most previous work, the models are learned based on either unsupervised objectives, which does not directly optimize the desired task, or singletask supervised objectives, which often suffer from insufficient training data. We develop a multi-task DNN for learning representations across multiple tasks, not only leveraging large amounts of cross-task data, but also benefiting from a regularization effect that leads to more general representations to help tasks in new domains. Our multi-task DNN approach combines tasks of multiple-domain classification (for query classification) and information retrieval (ranking for web search), and demonstrates significant gains over strong baselines in a comprehensive set of domain adaptation. © 2015 Association for Computational Linguistics."
93,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Inflection generation as discriminative string transduction,"We approach the task of morphological inflection generation as discriminative string transduction. Our supervised system learns to generate word-forms from lemmas accompanied by morphological tags, and refines them by referring to the other forms within a paradigm. Results of experiments on six diverse languages with varying amounts of training data demonstrate that our approach improves the state of the art in terms of predicting inflected word-forms. © 2015 Association for Computational Linguistics."
94,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Penalized expectation propagation for graphical models over strings,"We present penalized expectation propagation (PEP), a novel algorithm for approximate inference in graphical models. Expectation propagation is a variant of loopy belief propagation that keeps messages tractable by projecting them back into a given family of functions. Our extension, PEP, uses a structuredsparsity penalty to encourage simple messages, thus balancing speed and accuracy. We specifically show how to instantiate PEP in the case of string-valued random variables, where we adaptively approximate finite-state distributions by variable-order n-gram models. On phonological inference problems, we obtain substantial speedup over previous related algorithms with no significant loss in accuracy. © 2015 Association for Computational Linguistics."
95,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Joint generation of transliterations from multiple representations,"Machine transliteration is often referred to as phonetic translation. We show that transliterations incorporate information from both spelling and pronunciation, and propose an effective model for joint transliteration generation from both representations. We further generalize this model to include transliterations from other languages, and enhance it with reranking and lexicon features. We demonstrate significant improvements in transliteration accuracy on several datasets. © 2015 Association for Computational Linguistics."
96,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Prosodic boundary information helps unsupervised word segmentation,"It is well known that prosodic information is used by infants in early language acquisition. In particular, prosodic boundaries have been shown to help infants with sentence and wordlevel segmentation. In this study, we extend an unsupervised method for word segmentation to include information about prosodic boundaries. The boundary information used was either derived from oracle data (handannotated), or extracted automatically with a system that employs only acoustic cues for boundary detection. The approach was tested on two different languages, English and Japanese, and the results show that boundary information helps word segmentation in both cases. The performance gain obtained for two typologically distinct languages shows the robustness of prosodic information for word segmentation. Furthermore, the improvements are not limited to the use of oracle information, similar performances being obtained also with automatically extracted boundaries. © 2015 Association for Computational Linguistics."
97,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,So similar and yet incompatible: Toward automated identification of semantically compatible words,"We introduce the challenge of detecting semantically compatible words, that is, words that can potentially refer to the same thing (cat and hindrance are compatible, cat and dog are not), arguing for its central role in many semantic tasks. We present a publicly available data-set of human compatibility ratings, and a neural-network model that takes distributional embeddings of words as input and learns alternative embeddings that perform the compatibility detection task quite well. © 2015 Association for Computational Linguistics."
98,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Do supervised distributional methods really learn lexical inference relations?,"Distributional representations of words have been recently used in supervised settings for recognizing lexical inference relations between word pairs, such as hypernymy and entailment. We investigate a collection of these state-of-the-art methods, and show that they do not actually learn a relation between two words. Instead, they learn an independent property of a single word in the pair: whether that word is a ""prototypical hypernym"". © 2015 Association for Computational Linguistics."
99,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,A word embedding approach to predicting the compositionality of multiword expressions,"This paper presents the first attempt to use word embeddings to predict the compositionality of multiword expressions. We consider both single- and multi-prototype word embeddings. Experimental results show that, in combination with a back-off method based on string similarity, word embeddings outperform a method using count-based distributional similarity. Our best results are competitive with, or superior to, state-of-the-art methods over three standard compositionality datasets, which include two types of multiword expressions and two languages. © 2015 Association for Computational Linguistics."
100,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Word embedding-based antonym detection using thesauri and distributional information,"This paper proposes a novel approach to train word embeddings to capture antonyms. Word embeddings have shown to capture synonyms and analogies. Such word embeddings, however, cannot capture antonyms since they depend on the distributional hypothesis. Our approach utilizes supervised synonym and antonym information from thesauri, as well as distributional information from large-scale unlabelled text data. The evaluation results on the GRE antonym question task show that our model outperforms the state-of-the-art systems and it can answer the antonym questions in the F-score of 89%. © 2015 Association for Computational Linguistics."
101,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,A comparison of word similarity performance using explanatory and non-explanatory texts,Vectorial representations of words derived from large current events datasets have been shown to perform well on word similarity tasks. This paper shows vectorial representations derived from substantially smaller explanatory text datasets such as English Wikipedia and Simple English Wikipedia preserve enough lexical semantic information to make these kinds of category judgments with equal or better accuracy. © 2015 Association for Computational Linguistics.
102,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Morphological modeling for machine translation of English-Iraqi Arabic spoken dialogs,"This paper addresses the problem of morphological modeling in statistical speech-to-speech translation for English to Iraqi Arabic. An analysis of user data from a real-time MT-based dialog system showed that generating correct verbal inflections is a key problem for this language pair. We approach this problem by enriching the training data with morphological information derived from source-side dependency parses. We analyze the performance of several parsers as well as the effect on different types of translation models. Our method achieves an improvement of more than a full BLEU point and a significant increase in verbal inflection accuracy; at the same time, it is computationally inexpensive and does not rely on target-language linguistic tools. © 2015 Association for Computational Linguistics."
103,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Continuous adaptation to user feedback for statistical machine translation,"This paper gives a detailed experiment feedback of different approaches to adapt a statistical machine translation system towards a targeted translation project, using only small amounts of parallel in-domain data. The experiments were performed by professional translators under realistic conditions of work using a computer assisted translation tool. We analyze the influence of these adaptations on the translator productivity and on the overall post-editing effort. We show that significant improvements can be obtained by using the presented adaptation techniques. © 2015 Association for Computational Linguistics."
104,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Normalized word embedding and orthogonal transform for bilingual word translation,"Word embedding has been found to be highly powerful to translate words from one language to another by a simple linear transform. However, we found some inconsistence among the objective functions of the embedding and the transform learning, as well as the distance measurement. This paper proposes a solution which normalizes the word vectors on a hypersphere and constrains the linear transform as an orthogonal transform. The experimental results confirmed that the proposed solution can offer better performance on a word similarity task and an English-to-Spanish word translation task. © 2015 Association for Computational Linguistics."
105,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Fast and accurate preordering for SMT using neural networks,"We propose the use of neural networks to model source-side preordering for faster and better statistical machine translation. The neural network trains a logistic regression model to predict whether two sibling nodes of the source-side parse tree should be swapped in order to obtain a more monotonic parallel corpus, based on samples extracted from the word-aligned parallel corpus. For multiple language pairs and domains, we show that this yields the best reordering performance against other state-of-the-art techniques, resulting in improved translation quality and very fast decoding. © 2015 Association for Computational Linguistics."
106,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,APRO: All-pairs ranking optimization for MT tuning,"We present APRO, a new method for machine translation tuning that can handle large feature sets. As opposed to other popular methods (e.g., MERT, MIRA, PRO), which involve randomness and require multiple runs to obtain a reliable result, APRO gives the same result on any run, given initial feature weights. APRO follows the pairwise ranking approach of PRO (Hopkins and May, 2011), but instead of ranking a small sampled subset of pairs from the kbest list, APRO efficiently ranks all pairs. By obviating the need for manually determined sampling settings, we obtain more reliable results. APRO converges more quickly than PRO and gives similar or better translation results. © 2015 Association for Computational Linguistics."
107,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Paradigm classification in supervised learning of morphology,"Supervised morphological paradigm learning by identifying and aligning the longest common subsequence found in inflection tables has recently been proposed as a simple yet competitive way to induce morphological patterns. We combine this non-probabilistic strategy of inflection table generalization with a discriminative classifier to permit the reconstruction of complete inflection tables of unseen words. Our system learns morphological paradigms from labeled examples of inflection patterns (inflection tables) and then produces inflection tables from unseen lemmas or base forms. We evaluate the approach on datasets covering 11 different languages and show that this approach results in consistently higher accuracies vis-à-vis other methods on the same task, thus indicating that the general method is a viable approach to quickly creating high-accuracy morphological resources. © 2015 Association for Computational Linguistics."
108,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Shift-reduce constituency parsing with dynamic programming and POS tag lattice,"We present the first dynamic programming (DP) algorithm for shift-reduce constituency parsing, which extends the DP idea of Huang and Sagae (2010) to context-free grammars. To alleviate the propagation of errors from part-of-speech tagging, we also extend the parser to take a tag lattice instead of a fixed tag sequence. Experiments on both English and Chinese tree-banks show that our DP parser significantly improves parsing quality over non-DP baselines, and achieves the best accuracies among empirical linear-time parsers. © 2015 Association for Computational Linguistics."
109,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Unsupervised code-switching for multilingual historical document transcription,"Transcribing documents from the printing press era, a challenge in its own right, is more complicated when documents interleave multiple languages - a common feature of 16th century texts. Additionally, many of these documents precede consistent orthographic conventions, making the task even harder. We extend the state-of-the-art historical OCR model of Berg-Kirkpatrick et al. (2013) to handle word-level code-switching between multiple languages. Further, we enable our system to handle spelling variability, including now-obsolete shorthand systems used by printers. Our results show average relative character error reductions of 14% across a variety of historical texts. © 2015 Association for Computational Linguistics."
110,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Matching citation text and cited spans in biomedical literature: A search-oriented approach,"Citation sentences (citances) to a reference article have been extensively studied for summarization tasks. However, citances might not accurately represent the content of the cited article, as they often fail to capture the context of the reported findings and can be affected by epistemic value drift. Following the intuition behind the TAC (Text Analysis Conference) 2014 Biomedical Summarization track, we propose a system that identifies text spans in the reference article that are related to a given citance. We refer to this problem as citance-reference spans matching. We approach the problem as a retrieval task; in this paper, we detail a comparison of different citance reformulation methods and their combinations. While our results show improvement over the baseline (up to 25.9%), their absolute magnitude implies that there is ample room for future improvement. © 2015 Association for Computational Linguistics."
111,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Effective feature integration for automated short answer scoring,"A major opportunity for NLP to have a real-world impact is in helping educators score student writing, particularly content-based writing (i.e., the task of automated short answer scoring). A major challenge in this enterprise is that scored responses to a particular question (i.e., labeled data) are valuable for modeling but limited in quantity. Additional information from the scoring guidelines for humans, such as exemplars for each score level and descriptions of key concepts, can also be used. Here, we explore methods for integrating scoring guidelines and labeled responses, and we find that stacked generalization (Wolpert, 1992) improves performance, especially for small training sets. © 2015 Association for Computational Linguistics."
112,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Socially-informed timeline generation for complex events,"Existing timeline generation systems for complex events consider only information from traditional media, ignoring the rich social context provided by user-generated content that reveals representative public interests or insightful opinions. We instead aim to generate socially-informed timelines that contain both news article summaries and selected user comments. We present an optimization framework designed to balance topical cohesion between the article and comment summaries along with their informativeness and coverage of the event. Automatic evaluations on real-world datasets that cover four complex events show that our system produces more informative timelines than state-of-the-art systems. In human evaluation, the associated comment summaries are furthermore rated more insightful than editor's picks and comments ranked highly by users. © 2015 Association for Computational Linguistics."
113,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Movie script summarization as graph-based scene extraction,"In this paper we study the task of movie script summarization, which we argue could enhance script browsing, give readers a rough idea of the script's plotline, and speed up reading time. We formalize the process of generating a shorter version of a screenplay as the task of finding an optimal chain of scenes. We develop a graph-based model that selects a chain by jointly optimizing its logical progression, diversity, and importance. Human evaluation based on a question-answering task shows that our model produces summaries which are more informative compared to competitive baselines. © 2015 Association for Computational Linguistics."
114,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Toward abstractive summarization using semantic representations,"We present a novel abstractive summarization framework that draws on the recent development of a treebank for the Abstract Meaning Representation (AMR). In this framework, the source text is parsed to a set of AMR graphs, the graphs are transformed into a summary graph, and then text is generated from the summary graph. We focus on the graph-to-graph transformation that reduces the source semantic graph into a summary graph, making use of an existing AMR parser and assuming the eventual availability of an AMR-to-text generator. The framework is data-driven, trainable, and not specifically designed for a particular domain. Experiments on gold-standard AMR annotations and system parses show promising results. Code is available at: https://github.com/summarization. © 2015 Association for Computational Linguistics."
115,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Encoding world knowledge in the evaluation of local coherence,"Previous work on text coherence was primarily based on matching multiple mentions of the same entity in different parts of the text; therefore, it misses the contribution from semantically related but not necessarily coreferential entities (e.g., Gates and Microsoft). In this paper, we capture such semantic relatedness by leveraging world knowledge (e.g., Gates is the person who created Microsoft), and use two existing evaluation frameworks. First, in the unsupervised framework, we introduce semantic relatedness as an enrichment to the original graph-based model of Guinaudeau and Strube (2013). In addition, we incorporate semantic relatedness as additional features into the popular entity-based model of Barzilay and Lapata (2008). Across both frameworks, our enriched model with semantic relatedness outperforms the original methods, especially on short documents. © 2015 Association for Computational Linguistics."
116,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Chinese event coreference resolution: An unsupervised probabilistic model rivaling supervised resolvers,"Recent work has successfully leveraged the semantic information extracted from lexical knowledge bases such as WordNet and FrameNet to improve English event coreference resolvers. The lack of comparable resources in other languages, however, has made the design of high-performance non-English event coreference resolvers, particularly those employing unsupervised models, very difficult. We propose a generative model for the under-studied task of Chinese event coreference resolution that rivals its supervised counterparts in performance when evaluated on the ACE 2005 corpus. © 2015 Association for Computational Linguistics."
117,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Removing the training wheels: A coreference dataset that entertains humans and challenges computers,"Coreference is a core nlp problem. However, newswire data, the primary source of existing coreference data, lack the richness necessary to truly solve coreference. We present a new domain with denser references - quiz bowl questions - that is challenging and enjoyable to humans, and we use the quiz bowl community to develop a new coreference dataset, together with an annotation framework that can tag any text data with coreferences and named entities. We also successfully integrate active learning into this annotation pipeline to collect documents maximally useful to coreference models. State-of-the-art coreference systems underperform a simple classifier on our new dataset, motivating non-newswire data for future coreference research. © 2015 Association for Computational Linguistics."
118,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Injecting logical background knowledge into embeddings for relation extraction,"Matrix factorization approaches to relation extraction provide several attractive features: they support distant supervision, handle open schemas, and leverage unlabeled data. Unfortunately, these methods share a shortcoming with all other distantly supervised approaches: they cannot learn to extract target relations without existing data in the knowledge base, and likewise, these models are inaccurate for relations with sparse data. Rule-based extractors, on the other hand, can be easily extended to novel relations and improved for existing but inaccurate relations, through first-order formulae that capture auxiliary domain knowledge. However, usually a large set of such formulae is necessary to achieve generalization. In this paper, we introduce a paradigm for learning low-dimensional embeddings of entity-pairs and relations that combine the advantages of matrix factorization with first-order logic domain knowledge. We introduce simple approaches for estimating such embeddings, as well as a novel training algorithm to jointly optimize over factual and first-order logic information. Our results show that this method is able to learn accurate extractors with little or no distant supervision alignments, while at the same time generalizing to textual patterns that do not appear in the formulae. © 2015 Association for Computational Linguistics."
119,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Unsupervised entity linking with abstract meaning representation,"Most successful Entity Linking (EL) methods aim to link mentions to their referent entities in a structured Knowledge Base (KB) by comparing their respective contexts, often using similarity measures. While the KB structure is given, current methods have suffered from impoverished information representations on the mention side. In this paper, we demonstrate the effectiveness of Abstract Meaning Representation (AMR) (Banarescu et al., 2013) to select high quality sets of entity ""collaborators"" to feed a simple similarity measure (Jaccard) to link entity mentions. Experimental results show that AMR captures contextual properties discriminative enough to make linking decisions, without the need for EL training data, and that system with AMR parsing output outperforms hand labeled traditional semantic roles as context representation for EL. Finally, we show promising preliminary results for using AMR to select sets of ""coherent"" entity mentions for collective entity linking. © 2015 Association for Computational Linguistics."
120,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,IDEST: Learning a distributed representation for event patterns,"This paper describes IDEST, a new method for learning paraphrases of event patterns. It is based on a new neural network architecture that only relies on the weak supervision signal that comes from the news published on the same day and mention the same real-world entities. It can generalize across extractions from different dates to produce a robust paraphrase model for event patterns that can also capture meaningful representations for rare patterns. We compare it with two state-of-the-art systems and show that it can attain comparable quality when trained on a small dataset. Its generalization capabilities also allow it to leverage much more data, leading to substantial quality improvements. © 2015 Association for Computational Linguistics."
121,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,High-order low-rank tensors for semantic role labeling,"This paper introduces a tensor-based approach to semantic role labeling (SRL). The motivation behind the approach is to automatically induce a compact feature representation for words and their relations, tailoring them to the task. In this sense, our dimensionality reduction method provides a clear alternative to the traditional feature engineering approach used in SRL. To capture meaningful interactions between the argument, predicate, their syntactic path and the corresponding role label, we compress each feature representation first to a lower dimensional space prior to assessing their interactions. This corresponds to using an overall cross-product feature representation and maintaining associated parameters as a four-way low-rank tensor. The tensor parameters are optimized for the SRL performance using standard online algorithms. Our tensor-based approach rivals the best performing system on the CoNLL-2009 shared task. In addition, we demonstrate that adding the representation tensor to a competitive tensorfree model yields 2% absolute increase in Fscore. © 2015 Association for Computational Linguistics."
122,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Lexical event ordering with an edge-factored model,"Extensive lexical knowledge is necessary for temporal analysis and planning tasks. We address in this paper a lexical setting that allows for the straightforward incorporation of rich features and structural constraints. We explore a lexical event ordering task, namely determining the likely temporal order of events based solely on the identity of their predicates and arguments. We propose an ""edgefactored"" model for the task that decomposes over the edges of the event graph. We learn it using the structured perceptron. As lexical tasks require large amounts of text, we do not attempt manual annotation and instead use the textual order of events in a domain where this order is aligned with their temporal order, namely cooking recipes. © 2015 Association for Computational Linguistics."
123,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Bag-of-words forced decoding for cross-lingual information retrieval,"Current approaches to cross-lingual information retrieval (CLIR) rely on standard retrieval models into which query translations by statistical machine translation (SMT) are integrated at varying degree. In this paper, we present an attempt to turn this situation on its head: Instead of the retrieval aspect, we emphasize the translation component in CLIR. We perform search by using an SMT decoder in forced decoding mode to produce a bag-ofwords representation of the target documents to be ranked. The SMT model is extended by retrieval-specific features that are optimized jointly with standard translation features for a ranking objective. We find significant gains over the state-of-the-art in a large-scale evaluation on cross-lingual search in the domains patents and Wikipedia. © 2015 Association for Computational Linguistics."
124,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Accurate evaluation of segment-level machine translation metrics,"Evaluation of segment-level machine translation metrics is currently hampered by: (1) low inter-annotator agreement levels in human assessments; (2) lack of an effective mechanism for evaluation of translations of equal quality; and (3) lack of methods of significance testing improvements over a baseline. In this paper, we provide solutions to each of these challenges and outline a new human evaluation methodology aimed specifically at assessment of segment-level metrics. We replicate the human evaluation component of WMT-13 and reveal that the current state-of-the-art performance of segment-level metrics is better than previously believed. Three segment-level metrics -METEOR, NLEPOR and SENTBLEUMOSES -are found to correlate with human assessment at a level not significantly outperformed by any other metric in both the individual language pair assessment for Spanish-to-English and the aggregated set of 9 language pairs. © 2015 Association for Computational Linguistics."
125,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Leveraging small multilingual corpora for SMT using many pivot languages,"We present our work on leveraging multilingual parallel corpora of small sizes for Statistical Machine Translation between Japanese and Hindi using multiple pivot languages. In our setting, the source and target part of the corpus remains the same, but we show that using several different pivot to extract phrase pairs from these source and target parts lead to large BLEU improvements. We focus on a variety of ways to exploit phrase tables generated using multiple pivots to support a direct source-target phrase table. Our main method uses the Multiple Decoding Paths (MDP) feature of Moses, which we empirically verify as the best compared to the other methods we used. We compare and contrast our various results to show that one can overcome the limitations of small corpora by using as many pivot languages as possible in a multilingual setting. Most importantly, we show that such pivoting aids in learning of additional phrase pairs which are not learned when the direct sourcetarget corpus is small. We obtained improvements of up to 3 BLEU points using multiple pivots for Japanese to Hindi translation compared to when only one pivot is used. To the best of our knowledge, this work is also the first of its kind to attempt the simultaneous utilization of 7 pivot languages at decoding time. © 2015 Association for Computational Linguistics."
126,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Why read if you can scan? Trigger scoping strategy for biographical fact extraction,"The rapid growth of information sources brings a unique challenge to biographical information extraction: how to find specific facts without having to read all the words. An effective solution is to follow the human scanning strategy which keeps a specific keyword in mind and searches within a specific scope. In this paper, we mimic a scanning process to extract biographical facts. We use event and relation triggers as keywords, identify their scopes and apply type constraints to extract answers within the scope of a trigger. Experiments demonstrate that our approach outperforms state-of-the-art methods up to 26% absolute gain in F-score without using any syntactic analysis or external knowledge bases. © 2015 Association for Computational Linguistics."
127,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Lachmannian archetype reconstruction for ancient manuscript corpora,"Two goals are targeted by computer philology for ancient manuscript corpora: firstly, making an edition, that is roughly speaking one text version representing the whole corpus, which contains variety induced through copy errors and other processes and secondly, producing a stemma. A stemma is a graphbased visualization of the copy history with manuscripts as nodes and copy events as edges. Its root, the so-called archetype, is the supposed original text or urtext from which all subsequent copies are made. Our main contribution is to present one of the first computational approaches to automatic archetype reconstruction and to introduce the first textbased evaluation for automatically produced archetypes. We compare a philologically generated archetype with one generated by bioinformatic software. © 2015 Association for Computational Linguistics."
128,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Distributed representations of words to guide bootstrapped entity classifiers,"Bootstrapped classifiers iteratively generalize from a few seed examples or prototypes to other examples of target labels. However, sparseness of language and limited supervision make the task difficult. We address this problem by using distributed vector representations of words to aid the generalization. We use the word vectors to expand entity sets used for training classifiers in a bootstrapped pattern-based entity extraction system. Our experiments show that the classifiers trained with the expanded sets perform better on entity extraction from four online forums, with 30% F1 improvement on one forum. The results suggest that distributed representations can provide good directions for generalization in a bootstrapping system. © 2015 Association for Computational Linguistics."
129,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Multi-task word alignment triangulation for low-resource languages,"We present a multi-task learning approach that jointly trains three word alignment models over disjoint bitexts of three languages: source, target and pivot. Our approach builds upon model triangulation, following Wang et al., which approximates a source-target model by combining source-pivot and pivot-target models. We develop a MAP-EM algorithm that uses triangulation as a prior, and show how to extend it to a multi-task setting. On a low-resource Czech-English corpus, using French as the pivot, our multi-task learning approach more than doubles the gains in both Fand Bleu scores compared to the interpolation approach of Wang et al. Further experiments reveal that the choice of pivot language does not significantly affect performance. © 2015 Association for Computational Linguistics."
130,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Automatic cognate identification with gap-weighted string subsequences,"In this paper, we describe the problem of cognate identification in NLP. We introduce the idea of gap-weighted subsequences for discriminating cognates from non-cognates. We also propose a scheme to integrate phonetic features into the feature vectors for cognate identification. We show that subsequence based features perform better than state-ofthe-art classifier for the purpose of cognate identification. The contribution of this paper is the use of subsequence features for cognate identification. © 2015 Association for Computational Linguistics."
131,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Short text understanding by leveraging knowledge into topic model,"In this paper, we investigate the challenging task of understanding short text (STU task) by jointly considering topic modeling and knowledge incorporation. Knowledge incorporation can solve the content sparsity problem effectively for topic modeling. Specifically, the phrase topic model is proposed to leverage the auto-mined knowledge, i.e., the phrases, to guide the generative process of short text. Experimental results illustrate the effectiveness of the mechanism that utilizes knowledge to improve topic modeling's performance. © 2015 Association for Computational Linguistics."
132,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,An iterative approach for unsupervised most frequent sense detection using WordNet and word embeddings,"Given a word, what is the most frequent sense in which it occurs in a given corpus? Most Frequent Sense (MFS) is a strong baseline for unsupervised word sense disambiguation. If we have large amounts of sense-annotated corpora, MFS can be trivially created. However, senseannotated corpora are a rarity. In this paper, we propose a method which can compute MFS from raw corpora. Our approach iteratively exploits the semantic congruity among related words in corpus. Our method performs better compared to another similar work. © 2018 University of Szeged. All rights reserved."
133,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Chain based RNN for relation classification,"We present a novel approach for relation classification, using a recursive neural network (RNN), based on the shortest path between two entities in a dependency graph. Previous works on RNN are based on constituencybased parsing because phrasal nodes in a parse tree can capture compositionality in a sentence. Compared with constituency-based parse trees, dependency graphs can represent relations more compactly. This is particularly important in sentences with distant entities, where the parse tree spans words that are not relevant to the relation. In such cases RNN cannot be trained effectively in a timely manner. However, due to the lack of phrasal nodes in dependency graphs, application of RNN is not straightforward. In order to tackle this problem, we utilize dependency constituent units called chains. Our experiments on two relation classification datasets show that Chain based RNN provides a shallower network, which performs considerably faster and achieves better classification results. © 2015 Association for Computational Linguistics."
134,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
135,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Mining for unambiguous instances to adapt part-of-speech taggers to new domains,"We present a simple, yet effective approach to adapt part-of-speech (POS) taggers to new domains. Our approach only requires a dictionary and large amounts of unlabeled target data. The idea is to use the dictionary to mine the unlabeled target data for unambiguous word sequences, thus effectively collecting labeled target data. We add the mined instances to available labeled newswire data to train a POS tagger for the target domain. The induced models significantly improve tagging accuracy on held-out test sets across three domains (Twitter, spoken language, and search queries). We also present results for Dutch, Spanish and Portuguese Twitter data, and provide two novel manually-annotated test sets. © 2015 Association for Computational Linguistics."
136,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
137,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Development of the multilingual semantic annotation system,"This paper reports on our research to generate multilingual semantic lexical resources and develop multilingual semantic annotation software, which assigns each word in running text to a semantic category based on a lexical semantic classification scheme. Such tools have an important role in developing intelligent multilingual NLP, text mining and ICT systems. In this work, we aim to extend an existing English semantic annotation tool to cover a range of languages, namely Italian, Chinese and Brazilian Portuguese, by bootstrapping new semantic lexical resources via automatically translating existing English semantic lexicons into these languages. We used a set of bilingual dictionaries and word lists for this purpose. In our experiment, with minor manual improvement of the automatically generated semantic lexicons, the prototype tools based on the new lexicons achieved an average lexical coverage of 79.86% and an average annotation precision of 71.42% (if only precise annotations are considered) or 84.64% (if partially correct annotations are included) on the three languages. Our experiment demonstrates that it is feasible to rapidly develop prototype semantic annotation tools for new languages by automatically bootstrapping new semantic lexicons based on existing ones. © 2015 Association for Computational Linguistics."
138,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Unsupervised sparse vector densification for short text similarity,"Sparse representations of text such as bag-ofwords models or extended explicit semantic analysis (ESA) representations are commonly used in many NLP applications. However, for short texts, the similarity between two such sparse vectors is not accurate due to the small term overlap. While there have been multiple proposals for dense representations of words, measuring similarity between short texts (sentences, snippets, paragraphs) requires combining these token level similarities. In this paper, we propose to combine ESA representations and word2vec representations as a way to generate denser representations and, consequently, a better similarity measure between short texts. We study three densification mechanisms that involve aligning sparse representation via many-to-many, many-to-one, and oneto-one mappings. We then show the effectiveness of these mechanisms on measuring similarity between short texts. © 2015 Association for Computational Linguistics."
139,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,"WhyIStayed, #WhyILeft: Microblogging to make sense of domestic abuse","In September 2014, Twitter users unequivocally reacted to the Ray Rice assault scandal by unleashing personal stories of domestic abuse via the hashtags #WhyIStayed or #WhyILeft. We explore at a macro-level firsthand accounts of domestic abuse from a substantial, balanced corpus of tweeted instances designated with these tags. To seek insights into the reasons victims give for staying in vs. leaving abusive relationships, we analyze the corpus using linguistically motivated methods. We also report on an annotation study for corpus assessment. We perform classification, contributing a classifier that discriminates between the two hashtags exceptionally well at 82% accuracy with a substantial error reduction over its baseline. © 2015 Association for Computational Linguistics."
140,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
141,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Recognizing social constructs from textual conversation,"In this paper we present our work on recognizing high level social constructs such as Leadership and Status from textual conversation using an approach that makes use of the background knowledge about social hierarchy and integrates statistical methods and symbolic logic based methods. We use a stratified approach in which we first detect lower level language constructs such as politeness, command and agreement that help us to infer intermediate constructs such as deference, closeness and authority that are observed between the parties engaged in conversation. These intermediate constructs in turn are used to determine the social constructs Leadership and Status. We have implemented this system successfully in both English and Korean languages and achieved considerable accuracy. © 2015 Association for Computational Linguistics."
142,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Two/too simple adaptations of Word2Vec for syntax problems,"We present two simple modifications to the models in the popular Word2Vec tool, in order to generate embeddings more suited to tasks involving syntax. The main issue with the original models is the fact that they are insensitive to word order. While order independence is useful for inducing semantic representations, this leads to suboptimal results when they are used to solve syntax-based problems. We show improvements in part-of-speech tagging and dependency parsing using our proposed models. © 2015 Association for Computational Linguistics."
143,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Estimating numerical attributes by bringing together fragmentary clues,"This work is an attempt to automatically obtain numerical attributes of physical objects. We propose representing each physical object as a feature vector and representing sizes as linear functions of feature vectors. We train the function in the framework of the combined regression and ranking with many types of fragmentary clues including absolute clues (e.g., A is 30cm long) and relative clues (e.g., A is larger than B). © 2015 Association for Computational Linguistics."
144,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Unsupervised POS induction with word embeddings,"Unsupervised word embeddings have been shown to be valuable as features in supervised learning problems; however, their role in unsupervised problems has been less thoroughly explored. In this paper, we show that embeddings can likewise add value to the problem of unsupervised POS induction. In two representative models of POS induction, we replace multinomial distributions over the vocabulary with multivariate Gaussian distributions over word embeddings and observe consistent improvements in eight languages. We also analyze the effect of various choices while inducing word embeddings on ""downstream"" POS induction results. © 2015 Association for Computational Linguistics."
145,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Improving update summarization via supervised ILP and sentence reranking,"Integer Linear Programming (ILP) based summarization methods have been widely adopted recently because of their state-of-the-art performance. This paper proposes two new modifications in this framework for update summarization. Our key idea is to use discriminative models with a set of features to measure both the salience and the novelty of words and sentences. First, these features are used in a supervised model to predict the weights of the concepts used in the ILP model. Second, we generate preliminary sentence candidates in the ILP model and then rerank them using sentence level features. We evaluate our method on different TAC update summarization data sets, and the results show that our system performs competitively compared to the best TAC systems based on the ROUGE evaluation metric. © 2015 Association for Computational Linguistics."
146,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
147,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Everyone likes shopping! Multi-class product categorization for e-Commerce,"Online shopping caters the needs of millions of users on a daily basis. To build an accurate system that can retrieve relevant products for a query like ""MB252 with travel bags"" one requires product and query categorization mechanisms, which classify the text as Home&Garden>Kitchen&Dining>Kitchen Appliances>Blenders. One of the biggest challenges in e-Commerce is that providers like Amazon, e-Bay, Google, Yahoo! and Walmart organize products into different product taxonomies making it hard and time-consuming for sellers to categorize goods for each shopping platform. To address this challenge, we propose an automatic product categorization mechanism, which for a given product title assigns the correct product category from a taxonomy. We conducted an empirical evaluation on 445, 408 product titles and used a rich product taxonomy of 319 categories organized into 6 levels. We compared performance against multiple algorithms and found that the best performing system reaches .88 f-score. © 2015 Association for Computational Linguistics."
148,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,GPU-friendly local regression for voice conversion,"Voice conversion is the task of transforming a source speaker's voice so that it sounds like a target speaker's voice. We present a GPU-friendly local regression model for voice conversion that is capable of converting speech in real-time and achieves state-of-the-art accuracy on this task. Our model uses a new approximation for computing local regression coefficients that is explicitly designed to preserve memory locality. As a result, our inference procedure is amenable to efficient implementation on the GPU. Our approach is more than 10X faster than a highly optimized CPU-based implementation, and is able to convert speech 2.7X faster than real-time. © 2015 Association for Computational Linguistics."
149,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Response-based learning for machine translation of open-domain database queries,"Response-based learning allows to adapt a statistical machine translation (SMT) system to an extrinsic task by extracting supervision signals from task-specific feedback. In this paper, we elicit response signals for SMT adaptation by executing semantic parses of translated queries against the Freebase database. The challenge of our work lies in scaling semantic parsers to the lexical diversity of opendomain databases. We find that parser performance on incorrect English sentences, which is standardly ignored in parser evaluation, is key in model selection. In our experiments, the biggest improvements in F1-score for returning the correct answer from a semantic parse for a translated query are achieved by selecting a parser that is carefully enhanced by paraphrases and synonyms. © 2015 Association for Computational Linguistics."
150,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Context-dependent automatic response generation using statistical machine translation techniques,"Developing a system that can automatically respond to a user's utterance has recently become a topic of research in natural language processing. However, most works on the topic take into account only a single preceding utterance to generate a response. Recent works demonstrate that the application of statistical machine translation (SMT) techniques towards monolingual dialogue setting, in which a response is treated as a translation of a stimulus, has a great potential, and we exploit the approach to tackle the context-dependent response generation task. We attempt to extract relevant and significant information from the wider contextual scope of the conversation, and incorporate it into the SMT techniques. We also discuss the advantages and limitations of this approach through our experimental results. © 2015 Association for Computational Linguistics."
151,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Multilingual open relation extraction using cross-lingual projection,"Open domain relation extraction systems identify relation and argument phrases in a sentence without relying on any underlying schema. However, current state-of-the-art relation extraction systems are available only for English because of their heavy reliance on linguistic tools such as part-of-speech taggers and dependency parsers. We present a cross-lingual annotation projection method for language independent relation extraction. We evaluate our method on a manually annotated test set and present results on three typologically different languages. We release these manual annotations and extracted relations in ten languages from Wikipedia. © 2015 Association for Computational Linguistics."
152,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Learning to parse with IAA-weighted loss,"Natural language processing (NLP) annotation projects employ guidelines to maximize inter-annotator agreement (IAA), and models are estimated assuming that there is one single ground truth. However, not all disagreement is noise, and in fact some of it may contain valuable linguistic information. We integrate such information in the training of a cost-sensitive dependency parser. We introduce five different factorizations of IAA and the corresponding loss functions, and evaluate these across six different languages. We obtain robust improvements across the board using a factorization that considers dependency labels and directionality. The best method-dataset combination reaches an average overall error reduction of 6.4% in labeled attachment score. © 2015 Association for Computational Linguistics."
153,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Exploiting text and network context for geolocation of social media users,"Research on automatically geolocating social media users has conventionally been based on the text content of posts from a given user or the social network of the user, with very little crossover between the two, and no benchmarking of the two approaches over comparable datasets. We bring the two threads of research together in first proposing a text-based method based on adaptive grids, followed by a hybrid network- and text-based method. Evaluating over three Twitter datasets, we show that the empirical difference between text-and network-based methods is not great, and that hybridisation of the two is superior to the component methods, especially in contexts where the user graph is not well connected. We achieve state-of-the-art results on all three datasets. © 2015 Association for Computational Linguistics."
154,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Discriminative phrase embedding for paraphrase identification,"This work, concerning paraphrase identification task, on one hand contributes to expanding deep learning embeddings to include continuous and discontinuous linguistic phrases. On the other hand, it comes up with a new scheme TF-KLD-KNN to learn the discriminative weights of words and phrases specific to paraphrase task, so that a weighted sum of embeddings can represent sentences more effectively. Based on these two innovations we get competitive state-of-the-art performance on paraphrase identification. © 2015 Association for Computational Linguistics."
155,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Combining word embeddings and feature embeddings for fine-grained relation extraction,"Compositional embedding models build a representation for a linguistic structure based on its component word embeddings. While recent work has combined these word embeddings with hand crafted features for improved performance, it was restricted to a small number of features due to model complexity, thus limiting its applicability. We propose a new model that conjoins features and word embeddings while maintaing a small number of parameters by learning feature embeddings jointly with the parameters of a compositional model. The result is a method that can scale to more features and more labels, while avoiding overfitting. We demonstrate that our model attains state-of-the-art results on ACE and ERE fine-grained relation extraction. © 2015 Association for Computational Linguistics."
156,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,CASSA: A context-aware synonym simplification algorithm(Open Access),"We present a new context-aware method for lexical simplification that uses two free language resources and real web frequencies. We compare it with the state-of-the-art method for lexical simplification in Spanish and the established simplification baseline, that is, the most frequent synonym. Our method improves upon the other methods in the detection of complex words, in meaning preservation, and in simplicity. Although we use Spanish, the method can be extended to other languages since it does not require alignment of parallel corpora. © 2015 Association for Computational Linguistics."
157,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Simple task-specific bilingual word embeddings,"We introduce a simple wrapper method that uses off-the-shelf word embedding algorithms to learn task-specific bilingual word embeddings. We use a small dictionary of easily-obtainable task-specific word equivalence classes to produce mixed context-target pairs that we use to train off-the-shelf embedding models. Our model has the advantage that it (a) is independent of the choice of embedding algorithm, (b) does not require parallel data, and (c) can be adapted to specific tasks by re-defining the equivalence classes. We show how our method outperforms off-the-shelf bilingual embeddings on the task of unsupervised cross-language part-of-speech (POS) tagging, as well as on the task of semi-supervised cross-language super sense (SuS) tagging. © 2015 Association for Computational Linguistics."
158,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Sampling techniques for streaming cross document coreference resolution,"We present the first truly streaming cross document coreference resolution (CDC) system. Processing infinite streams of mentions forces us to use a constant amount of memory and so we maintain a representative, fixed sized sample at all times. For the sample to be representative it should represent a large number of entities whilst taking into account both temporal recency and distant references. We introduce new sampling techniques that take into account a notion of streaming discourse (current mentions depend on previous mentions). Using the proposed sampling techniques we are able to get a CEAFe score within 5% of a non-streaming system while using only 30% of the memory. © 2015 Association for Computational Linguistics."
159,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
160,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Large-scale Native Language Identification with cross-corpus evaluation,"We present a large-scale Native Language Identification (NLI) experiment on new data, with a focus on cross-corpus evaluation to identify corpus- and genre-independent language transfer features. We test a new corpus and show it is comparable to other NLI corpora and suitable for this task. Cross-corpus evaluation on two large corpora achieves good accuracy and evidences the existence of reliable language transfer features, but lower performance also suggests that NLI models are not completely portable across corpora. Finally, we present a brief case study of features distinguishing Japanese learners' English writing, demonstrating the presence of cross-corpus and cross-genre language transfer features that are highly applicable to SLA and ESL research. © 2015 Association for Computational Linguistics."
161,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Unediting: Detecting disfluencies without careful transcripts,"Speech transcripts often only capture semantic content, omitting disfluencies that can be useful for analyzing social dynamics of a discussion. This work describes steps in building a model that can recover a large fraction of locations where disfluencies were present, by transforming carefully annotated text to match the standard transcription style, introducing a two-stage model for handling different types of disfluencies, and applying semi-supervised learning. Experiments show improvement in disfluency detection on Supreme Court oral arguments, nearly 23% improvement in F1. © 2015 Association for Computational Linguistics."
162,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Type-driven incremental semantic parsing with polymorphism,"Semantic parsing has made significant progress, but most current semantic parsers are extremely slow (CKY-based) and rather primitive in representation. We introduce three new techniques to tackle these problems. First, we design the first linear-time incremental shift-reduce-style semantic parsing algorithm which is more efficient than conventional cubic-time bottom-up semantic parsers. Second, our parser, being type-driven instead of syntax-driven, uses type-checking to decide the direction of reduction, which eliminates the need for a syntactic grammar such as CCG. Third, to fully exploit the power of type-driven semantic parsing beyond simple types (such as entities and truth values), we borrow from programming language theory the concepts of subtype polymorphism and parametric polymorphism to enrich the type system in order to better guide the parsing. Our system learns very accurate parses in GEOQUERY, JOBS and ATIS domains. © 2015 Association for Computational Linguistics."
163,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Template kernels for dependency parsing,"A common approach to dependency parsing is scoring a parse via a linear function of a set of indicator features. These features are typically manually constructed from templates that are applied to parts of the parse tree. The templates define which properties of a part should combine to create features. Existing approaches consider only a small subset of the possible combinations, due to statistical and computational efficiency considerations. In this work we present a novel kernel which facilitates efficient parsing with feature representations corresponding to a much larger set of combinations. We integrate the kernel into a parse reranking system and demonstrate its effectiveness on four languages from the CoNLL-X shared task.1 © 2015 Association for Computational Linguistics."
164,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Embedding a semantic network in a word space,"We present a framework for using continuous-space vector representations of word meaning to derive new vectors representing the meaning of senses listed in a semantic network. It is a post-processing approach that can be applied to several types of word vector representations. It uses two ideas: first, that vectors for polysemous words can be decomposed into a convex combination of sense vectors; secondly, that the vector for a sense is kept similar to those of its neighbors in the network. This leads to a constrained optimization problem, and we present an approximation for the case when the distance function is the squared Euclidean. We applied this algorithm on a Swedish semantic network, and we evaluate the quality of the resulting sense representations extrinsically by showing that they give large improvements when used in a classifier that creates lexical units for FrameNet frames. © 2015 Association for Computational Linguistics."
165,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Random walks and neural network language models on knowledge bases,"Random walks over large knowledge bases like WordNet have been successfully used in word similarity, relatedness and disambiguation tasks. Unfortunately, those algorithms are relatively slow for large repositories, with significant memory footprints. In this paper we present a novel algorithm which encodes the structure of a knowledge base in a continuous vector space, combining random walks and neural net language models in order to produce novel word representations. Evaluation in word relatedness and similarity datasets yields equal or better results than those of a random walk algorithm, using a dense representation (300 dimensions instead of 117K). Furthermore, the word representations are complementary to those of the random walk algorithm and to corpus-based continuous representations, improving the state-of-the-art in the similarity dataset. Our technique opens up exciting opportunities to combine distributional and knowledge-based word representations. © 2015 Association for Computational Linguistics."
166,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Identification and characterization of newsworthy verbs in world news,"We present a data-driven technique for acquiring domain-level importance of verbs from the analysis of abstract/article pairs of world news articles. We show that existing lexical resources capture some the semantic characteristics for important words in the domain. We develop a novel characterization of the association between verbs and personal story narratives, which is descriptive of verbs avoided in summaries for this domain. © 2015 Association for Computational Linguistics."
167,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Enhancing Sumerian lemmatization by unsupervised named-entity recognition,"Lemmatization for the Sumerian language, compared to the modern languages, is much more challenging due to that it is a long dead language, highly skilled language experts are extremely scarce and more and more Sumerian texts are coming out. This paper describes how our unsupervised Sumerian named-entity recognition (NER) system helps to improve the lemmatization of the Cuneiform Digital Library Initiative (CDLI), a specialist database of cuneiform texts, from the Ur III period. Experiments show that a promising improvement in personal name annotation in such texts and a substantial reduction in expert annotation effort can be achieved by leveraging our system with minimal seed annotation. © 2015 Association for Computational Linguistics."
168,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Extracting information about medication use from veterinary discussions,"Our research aims to extract information about medication use from veterinary discussion forums. We introduce the task of categorizing information about medication use to determine whether a doctor has prescribed medication, changed protocols, observed effects, or stopped use of a medication. First, we create a medication detector for informal veterinary texts and show that features derived from the Web can be very powerful. Second, we create classifiers to categorize each medication mention with respect to six categories. We demonstrate that this task benefits from a rich linguistic feature set, domain-specific semantic features produced by a weakly supervised semantic tagger, and balanced self-training. © 2015 Association for Computational Linguistics."
169,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Reserating the awesometastic: An automatic extension of the WordNet taxonomy for novel terms,"This paper presents CROWN, an automatically constructed extension of WordNet that augments its taxonomy with novel lemmas from Wiktionary. CROWN fills the important gap in WordNet's lexicon for slang, technical, and rare lemmas, and more than doubles its current size. In two evaluations, we demonstrate that the construction procedure is accurate and has a significant impact on aWordNet-based algorithm encountering novel lemmas. © 2015 Association for Computational Linguistics."
170,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Cross-lingual text classification using topic-dependent word probabilities,"Cross-lingual text classification is a major challenge in natural language processing, since often training data is available in only one language (target language), but not available for the language of the document we want to classify (source language). Here, we propose a method that only requires a bilingual dictionary to bridge the language gap. Our proposed probabilistic model allows us to estimate translation probabilities that are conditioned on the whole source document. The assumption of our probabilistic model is that each document can be characterized by a distribution over topics that help to solve the translation ambiguity of single words. Using the derived translation probabilities, we then calculate the expected word frequency of each word type in the target language. Finally, these expected word frequencies can be used to classify the source text with any classifier that was trained using only target language documents. Our experiments confirm the usefulness of our proposed method. © 2015 Association for Computational Linguistics."
171,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Testing and comparing computational approaches for identifying the language of framing in political news,"The subconscious influence of framing on perceptions of political issues is well-document in political science and communication research. A related line of work suggests that drawing attention to framing may help reduce such framing effects by enabling frame reflection, critical examination of the framing underlying an issue. However, definite guidance on how to identify framing does not exist. This paper presents a technique for identifying frame-invoking language. The paper first describes a human subjects pilot study that explores how individuals identify framing and informs the design of our technique. The paper then describes our data collection and annotation approach. Results show that the best performing classifiers achieve performance comparable to that of human annotators, and they indicate which aspects of language most pertain to framing. Both technical and theoretical implications are discussed. © 2015 Association for Computational Linguistics."
172,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Echoes of persuasion: The effect of euphony in persuasive communication,"While the effect of various lexical, syntactic, semantic and stylistic features have been addressed in persuasive language from a computational point of view, the persuasive effect of phonetics has received little attention. By modeling a notion of euphony and analyzing four datasets comprising persuasive and non-persuasive sentences in different domains (political speeches, movie quotes, slogans and tweets), we explore the impact of sounds on different forms of persuasiveness. We conduct a series of analyses and prediction experiments within and across datasets. Our results highlight the positive role of phonetic devices on persuasion. © 2015 Association for Computational Linguistics."
173,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Translating videos to natural language using deep recurrent neural networks,"Solving the visual symbol grounding problem has long been a goal of artificial intelligence. The field appears to be advancing closer to this goal with recent breakthroughs in deep learning for natural language grounding in static images. In this paper, we propose to translate videos directly to sentences using a unified deep neural network with both convolutional and recurrent structure. Described video datasets are scarce, and most existing methods have been applied to toy domains with a small vocabulary of possible words. By transferring knowledge from 1.2M+ images with category labels and 100,000+ images with captions, our method is able to create sentence descriptions of open-domain videos with large vocabularies. We compare our approach with recent work using language generation metrics, subject, verb, and object prediction accuracy, and a human evaluation. © 2015 Association for Computational Linguistics."
174,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Learning to interpret and describe abstract scenes,"Given a (static) scene, a human can effortlessly describe what is going on (who is doing what to whom, how, and why). The process requires knowledge about the world, how it is perceived, and described. In this paper we study the problem of interpreting and verbalizing visual information using abstract scenes created from collections of clip art images. We propose a model inspired by machine translation operating over a large parallel corpus of visual relations and linguistic descriptions. We demonstrate that this approach produces human-like scene descriptions which are both fluent and relevant, outperforming a number of competitive alternatives based on templates, sentence-based retrieval, and a multimodal neural language model. © 2015 Association for Computational Linguistics."
175,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,A comparison of update strategies for large-scale maximum expected BLEU training,"This work presents a flexible and efficient discriminative training approach for statistical machine translation. We propose to use the RPROP algorithm for optimizing a maximum expected BLEU objective and experimentally compare it to several other updating schemes. It proves to be more efficient and effective than the previously proposed growth transformation technique and also yields better results than stochastic gradient descent and AdaGrad. We also report strong empirical results on two large scale tasks, namely BOLT Chinese→English and WMT German→English, where our final systems outperform results reported by Setiawan and Zhou (2013) and on matrix.statmt.org. On the WMT task, discriminative training is performed on the full training data of 4M sentence pairs, which is unsurpassed in the literature. © 2015 Association for Computational Linguistics."
176,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Learning translation models from monolingual continuous representations,"Translation models often fail to generate good translations for infrequent words or phrases. Previous work attacked this problem by inducing new translation rules from monolingual data with a semi-supervised algorithm. However, this approach does not scale very well since it is very computationally expensive to generate new translation rules for only a few thousand sentences. We propose a much faster and simpler method that directly hallucinates translation rules for infrequent phrases based on phrases with similar continuous representations for which a translation is known. To speed up the retrieval of similar phrases, we investigate approximated nearest neighbor search with redundant bit vectors which we find to be three times faster and significantly more accurate than locality sensitive hashing. Our approach of learning new translation rules improves a phrase-based baseline by up to 1.6 BLEU on Arabic-English translation, it is three-orders of magnitudes faster than existing semi-supervised methods and 0.5 BLEU more accurate. © 2015 Association for Computational Linguistics."
177,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,A corpus and model integrating multiword expressions and supersenses,"This paper introduces a task of identifying and semantically classifying lexical expressions in running text. We investigate the online reviews genre, adding semantic supersense annotations to a 55,000 word English corpus that was previously annotated for multiword expressions. The noun and verb supersenses apply to full lexical expressions, whether single- or multiword. We then present a sequence tagging model that jointly infers lexical expressions and their supersenses. Results show that even with our relatively small training corpus in a noisy domain, the joint task can be performed to attain 70% class labeling F1. © 2015 Association for Computational Linguistics."
178,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Good news or bad news: Using Affect Control Theory to analyze readers' reaction towards news articles,"This paper proposes a novel approach to sentiment analysis that leverages work in sociology on symbolic interactionism. The proposed approach uses Affect Control Theory (ACT) to analyze readers' sentiment towards factual (objective) content and towards its entities (subject and object). ACT is a theory of affective reasoning that uses empirically derived equations to predict the sentiments and emotions that arise from events. This theory relies on several large lexicons of words with affective ratings in a three-dimensional space of evaluation, potency, and activity (EPA). The equations and lexicons of ACT were evaluated on a newly collected news-headlines corpus. ACT lexicon was expanded using a label propagation algorithm, resulting in 86,604 new words. The predicted emotions for each news headline was then computed using the augmented lexicon and ACT equations. The results had a precision of 82%, 79%, and 68% towards the event, the subject, and object, respectively. These results are significantly higher than those of standard sentiment analysis techniques. © 2015 Association for Computational Linguistics."
179,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Do we really need lexical information? Towards a top-down approach to sentiment analysis of product reviews,"Most of the current approaches to sentiment analysis of product reviews are dependent on lexical sentiment information and proceed in a bottom-up way, adding new layers of features to lexical data. In this paper, we maintain that a typical product review is not a bag of sentiments, but a narrative with an underlying structure and reoccurring patterns, which allows us to predict its sentiments knowing only its general polarity and discourse cues that occur in it. We hypothesize that knowing only the review's score and its discourse patterns would allow us to accurately predict the sentiments of its individual sentences. The experiments we conducted prove this hypothesis and show a substantial improvement over the lexical baseline. © 2015 Association for Computational Linguistics."
180,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,How to memorize a random 60-bit string,"User-generated passwords tend to be memorable, but not secure. A random, computer-generated 60-bit string is much more secure. However, users cannot memorize random 60-bit strings. In this paper, we investigate methods for converting arbitrary bit strings into English word sequences (both prose and poetry), and we study their memorability and other properties. © 2015 Association for Computational Linguistics."
181,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,A Bayesian model for joint learning of categories and their features,"Categories such as ANIMAL or FURNITURE are acquired at an early age and play an important role in processing, organizing, and conveying world knowledge. Theories of categorization largely agree that categories are characterized by features such as function or appearance and that feature and category acquisition go hand-in-hand, however previous work has considered these problems in isolation. We present the first model that jointly learns categories and their features. The set of features is shared across categories, and strength of association is inferred in a Bayesian framework. We approximate the learning environment with natural language text which allows us to evaluate performance on a large scale. Compared to highly engineered pattern-based approaches, our model is cognitively motivated, knowledge-lean, and learns categories and features which are perceived by humans as more meaningful. © 2015 Association for Computational Linguistics."
182,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Shared common ground influences information density in microblog texts,"If speakers use language rationally, they should structure their messages to achieve approximately uniform information density (UID), in order to optimize transmission via a noisy channel. Previous work identified a consistent increase in linguistic information across sentences in text as a signature of the UID hypothesis. This increase was derived from a predicted increase in context, but the context itself was not quantified. We use microblog texts from Twitter, tied to a single shared event (the baseball World Series), to quantify both linguistic and non-linguistic context. By tracking changes in contextual information, we predict and identify gradual and rapid changes in information content in response to in-game events. These findings lend further support to the UID hypothesis and highlights the importance of nonlinguistic common ground for language production and processing. © 2015 Association for Computational Linguistics."
183,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Hierarchic syntax improves reading time prediction,"Previous work has debated whether humans make use of hierarchic syntax when processing language (Frank and Bod, 2011; Fossum and Levy, 2012). This paper uses an eye-tracking corpus to demonstrate that hierarchic syntax significantly improves reading time prediction over a strong n-gram baseline. This study shows that an interpolated 5-gram baseline can be made stronger by combining n-gram statistics over entire eye-tracking regions rather than simply using the last n-gram in each region, but basic hierarchic syntactic measures are still able to achieve significant improvements over this improved baseline. © 2015 Association for Computational Linguistics."
184,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Retrofitting word vectors to semantic lexicons,"Vector space word representations are learned from distributional information of words in large corpora. Although such statistics are semantically informative, they disregard the valuable information that is contained in semantic lexicons such as WordNet, FrameNet, and the Paraphrase Database. This paper proposes a method for refining vector space representations using relational information from semantic lexicons by encouraging linked words to have similar vector representations, and it makes no assumptions about how the input vectors were constructed. Evaluated on a battery of standard lexical semantic evaluation tasks in several languages, we obtain substantial improvements starting with a variety of word vector models. Our refinement method outperforms prior techniques for incorporating semantic lexicons into word vector training algorithms. © 2015 Association for Computational Linguistics."
185,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
186,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
187,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
188,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
189,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
190,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
191,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
192,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
193,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
194,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
195,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
196,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
197,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
198,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
199,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
200,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
201,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
202,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
203,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
204,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
205,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
206,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
207,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
208,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
209,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
210,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
211,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
212,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
213,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
214,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
215,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
216,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
217,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
218,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
219,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
220,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
221,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
222,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
223,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
224,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
225,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
226,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
227,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
228,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
229,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
230,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
231,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
232,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
233,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
234,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
235,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
236,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
237,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
238,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,Social media and NLP tasks: Challenges in crowdsourcing linguistic information,"In the framework of the TraMOOC1(Translation for Massive Open Online Courses) research and innovation project, data collection tasks for parallel translation are implemented using a crowdsourcing platform. The educational genre (videolectures subtitles, forums discussions, course assignments), the type of text (segmentation, misspellings, syntax errors, specialized terminology, scientific formulas, limited knowledge on context) of the source data, and the multilingual approach of the involved activities (the focus is on a total of 12 European and BRIC languages) provides a challenging setting for the success of the project. Experimental trials reveal significant findings for the purposes of Language Technology research as well as limitations in crowdsourcing linguistic data collections for multilingual tasks. © 2016 IEEE."
239,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
240,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
241,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
242,Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),2015,None,None
